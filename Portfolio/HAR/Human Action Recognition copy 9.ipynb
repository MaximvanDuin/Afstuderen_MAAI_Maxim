{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmaction.apis import inference_recognizer, init_recognizer\n",
    "import mmcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad naar de config en checkpoint\n",
    "config_file = r'C:\\Users\\maxim\\OneDrive\\01-Opleidingen\\03-MAAI\\Afstuderen\\mmaction2\\configs\\recognition\\tsm\\tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_sthv2-rgb.py'\n",
    "checkpoint_file = r'C:\\Users\\maxim\\OneDrive\\01-Opleidingen\\03-MAAI\\Afstuderen\\mmaction2\\checkpoints\\tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_sthv2-rgb_20230317-be0fc26e.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model initialiseren\n",
    "model = init_recognizer(config_file, checkpoint_file, device='cuda:0')  # Gebruik 'cpu' als je geen GPU hebt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voer inferentie uit op een sample video\n",
    "video_path = r'C:\\Users\\maxim\\OneDrive\\01-Opleidingen\\03-MAAI\\Afstuderen\\Video zonder titel.mp4'  # Zorg ervoor dat je een video bestand hebt\n",
    "results = inference_recognizer(model, video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laad de labelmap\n",
    "labels = open('tools/data/sthv2/label_map.txt').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Converteer de tensor naar een Python lijst\n",
    "pred_labels = results.pred_label.cpu().numpy()  # Voorspelde labels\n",
    "pred_scores = results.pred_score.cpu().numpy()  # Bijbehorende scores\n",
    "\n",
    "# Sorteer en pak de top-5 voorspellingen\n",
    "top5_indices = torch.topk(results.pred_score, 5).indices.cpu().numpy()\n",
    "\n",
    "# Laad de labelmap\n",
    "with open('tools/data/sthv2/label_map.txt') as f:\n",
    "    labels = f.read().splitlines()\n",
    "\n",
    "# Converteer indices naar labels\n",
    "top5_labels = [labels[i] for i in top5_indices]\n",
    "\n",
    "print(f\"Top-5 voorspellingen: {top5_labels}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import mmcv\n",
    "import tempfile\n",
    "import numpy as np\n",
    "\n",
    "from mmaction.apis import inference_recognizer, init_recognizer\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config_file = r'C:\\Users\\maxim\\OneDrive\\01-Opleidingen\\03-MAAI\\Afstuderen\\mmaction2\\configs\\recognition\\tsm\\tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_sthv2-rgb.py'\n",
    "# checkpoint_file = r'C:\\Users\\maxim\\OneDrive\\01-Opleidingen\\03-MAAI\\Afstuderen\\mmaction2\\checkpoints\\tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_sthv2-rgb_20230317-be0fc26e.pth'\n",
    "config_file = r'C:\\Users\\maxim\\OneDrive\\01-Opleidingen\\03-MAAI\\Afstuderen\\mmaction2\\configs\\recognition\\tsm\\tsm_imagenet-pretrained-r101_8xb16-1x1x8-50e_sthv2-rgb.py'\n",
    "checkpoint_file = r'C:\\Users\\maxim\\OneDrive\\01-Opleidingen\\03-MAAI\\Afstuderen\\mmaction2\\checkpoints\\tsm_imagenet-pretrained-r101_8xb16-1x1x8-50e_sthv2-rgb_20230320-efcc0d1b.pth'\n",
    "video_path = r\"C:\\Users\\maxim\\OneDrive\\01-Opleidingen\\03-MAAI\\Afstuderen\\Data\\Video's\\machine cover.mp4\"\n",
    "label_map_path = 'tools/data/sthv2/label_map.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Initieer model ---\n",
    "model = init_recognizer(config_file, checkpoint_file, device=device)\n",
    "target_layers = [model.backbone.layer4[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Labels inladen ---\n",
    "with open(label_map_path, 'r') as f:\n",
    "    labels = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Functie om frames naar video te schrijven ---\n",
    "def frames_to_video_cv2(frames, out_path, fps=25):\n",
    "    if not frames:\n",
    "        return\n",
    "    height, width = frames[0].shape[:2]\n",
    "    writer = cv2.VideoWriter(out_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
    "    for frame in frames:\n",
    "        writer.write(frame)\n",
    "    writer.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from mmcv.transforms import Compose\n",
    "from mmengine import Config\n",
    "\n",
    "# def get_transforms_from_cfg(cfg_path):\n",
    "#     cfg = Config.fromfile(cfg_path)\n",
    "#     return Compose(cfg.test_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CAMWrapper(nn.Module):\n",
    "    def __init__(self, backbone, cls_head, num_segs=8):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.cls_head = cls_head\n",
    "        self.num_segs = num_segs\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 3, 224, 224)  # [N*T, C, H, W]\n",
    "        feat = self.backbone(x)     # [N*T, 2048]\n",
    "        out = self.cls_head(feat, self.num_segs)  # [N, num_classes]\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "# Hoofdfunctie om Grad-CAM + bounding box te genereren\n",
    "def generate_gradcam_heatmap(model, video_path, target_label, target_layers):\n",
    "    reader = mmcv.VideoReader(video_path)\n",
    "    frames = list(reader[:8])\n",
    "    if len(frames) < 8:\n",
    "        return None\n",
    "\n",
    "    # Originele resolutie opslaan\n",
    "    mid_frame = frames[4]\n",
    "    orig_h, orig_w = mid_frame.shape[:2]\n",
    "\n",
    "    # Preprocessing: resize + normaliseren (224x224)\n",
    "    transform = T.Compose([\n",
    "        T.ToPILImage(),\n",
    "        T.Resize((224, 224)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                    std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    processed_frames = [transform(f) for f in frames]  # [C,H,W] * 8\n",
    "    clip = torch.stack(processed_frames, dim=0)         # [T,C,H,W]\n",
    "    input_tensor = clip.to(device).float()              # [T,C,H,W]\n",
    "    input_tensor = input_tensor.reshape(-1, 3, 224, 224)  # [8,3,224,224]\n",
    "\n",
    "    # Model in wrapper voor Grad-CAM\n",
    "    cam_model = CAMWrapper(model.backbone, model.cls_head, num_segs=8).to(device)\n",
    "    cam = GradCAM(model=cam_model, target_layers=target_layers)\n",
    "\n",
    "    # Grad-CAM genereren\n",
    "    targets = [ClassifierOutputTarget(target_label)]\n",
    "    grayscale_cam = cam(input_tensor=input_tensor, targets=targets)[0]  # [224,224]\n",
    "\n",
    "    # CAM visualiseren op resized RGB frame\n",
    "    frame_resized = cv2.resize(mid_frame, (224, 224))\n",
    "    frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
    "    cam_image = show_cam_on_image(frame_rgb, grayscale_cam, use_rgb=True)\n",
    "\n",
    "    # Bounding box uit CAM\n",
    "    threshold = 0.5\n",
    "    cam_mask = (grayscale_cam > threshold).astype(np.uint8) * 255\n",
    "    contours, _ = cv2.findContours(cam_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    bounding_box_coords = None  # fallback\n",
    "\n",
    "    if contours:\n",
    "        largest = max(contours, key=cv2.contourArea)\n",
    "        x, y, w, h = cv2.boundingRect(largest)\n",
    "\n",
    "        # Schaal terug naar originele framegrootte\n",
    "        scale_x = orig_w / 224\n",
    "        scale_y = orig_h / 224\n",
    "        x_orig = int(x * scale_x)\n",
    "        y_orig = int(y * scale_y)\n",
    "        w_orig = int(w * scale_x)\n",
    "        h_orig = int(h * scale_y)\n",
    "\n",
    "        # Bounding box tekenen op originele frame (optioneel debug)\n",
    "        mid_frame_boxed = mid_frame.copy()\n",
    "        cv2.rectangle(mid_frame_boxed, (x_orig, y_orig), (x_orig + w_orig, y_orig + h_orig), (0, 255, 0), 2)\n",
    "\n",
    "        # Eventueel: bounding box opslaan\n",
    "        bounding_box_coords = {\n",
    "            \"x\": x_orig,\n",
    "            \"y\": y_orig,\n",
    "            \"w\": w_orig,\n",
    "            \"h\": h_orig,\n",
    "            \"frame_size\": (orig_w, orig_h)\n",
    "        }\n",
    "\n",
    "        print(\"Bounding box op origineel frame:\", bounding_box_coords)\n",
    "\n",
    "        # Box ook tekenen op CAM (resized)\n",
    "        cam_image = cv2.rectangle(cam_image, (x, y), (x + w, y + h), color=(0, 255, 0), thickness=2)\n",
    "\n",
    "    return cam_image, bounding_box_coords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Verwerk video in snippets ---\n",
    "video_reader = mmcv.VideoReader(video_path)\n",
    "fps = video_reader.fps\n",
    "total_frames = len(video_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snippet_length_sec = 0.5\n",
    "overlap_sec = 0.25\n",
    "snippet_length = int(snippet_length_sec * fps)\n",
    "overlap = int(overlap_sec * fps)\n",
    "step = snippet_length - overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_results = []\n",
    "temp_dir = tempfile.gettempdir()\n",
    "\n",
    "for start_frame in range(0, total_frames, step):\n",
    "    end_frame = start_frame + snippet_length\n",
    "    if end_frame > total_frames:\n",
    "        break\n",
    "\n",
    "    snippet_frames = video_reader[start_frame:end_frame]\n",
    "    if not snippet_frames:\n",
    "        continue\n",
    "\n",
    "    snippet_name = f\"temp_snippet_{start_frame}_{end_frame}.mp4\"\n",
    "    snippet_path = os.path.join(temp_dir, snippet_name)\n",
    "    frames_to_video_cv2(snippet_frames, snippet_path, fps=fps)\n",
    "\n",
    "    result = inference_recognizer(model, snippet_path)\n",
    "    pred_score = result.pred_score\n",
    "    pred_label = result.pred_label\n",
    "    top5 = torch.topk(pred_score, 5)\n",
    "    top5_indices = top5.indices.cpu().numpy()\n",
    "    top5_scores = top5.values.cpu().numpy()\n",
    "    top5_labels = [labels[idx] for idx in top5_indices]\n",
    "\n",
    "    best_label_idx = pred_label.cpu().item()\n",
    "    best_label = labels[best_label_idx]\n",
    "    best_score = pred_score[best_label_idx].cpu().item()\n",
    "    start_sec = start_frame / fps\n",
    "    end_sec = end_frame / fps\n",
    "\n",
    "    # --- Grad-CAM genereren ---\n",
    "    cam_img, bbox = generate_gradcam_heatmap(model, snippet_path, best_label_idx, target_layers)\n",
    "    if cam_img is not None:\n",
    "        output_img_path = os.path.join(temp_dir, f\"gradcam_{start_frame}_{end_frame}.jpg\")\n",
    "        cv2.imwrite(output_img_path, cam_img)\n",
    "        print(f\"Heatmap opgeslagen: {output_img_path}\")\n",
    "\n",
    "    # --- Segment opslaan ---\n",
    "    segment_results.append({\n",
    "        'start_time': start_sec,\n",
    "        'end_time': end_sec,\n",
    "        'best_label': best_label,\n",
    "        'best_score': best_score,\n",
    "        'top5_labels': top5_labels,\n",
    "        'top5_scores': top5_scores,\n",
    "        'bounding_box': bbox\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_segments = []\n",
    "current_label = None\n",
    "current_start_sec = None\n",
    "current_end_sec = None\n",
    "current_scores = []\n",
    "current_bboxes = []\n",
    "\n",
    "score_threshold = 0.6\n",
    "\n",
    "for seg in segment_results:\n",
    "    label = seg['best_label']\n",
    "    score = seg['best_score']\n",
    "    bbox = seg.get('bounding_box')  # kan None zijn\n",
    "\n",
    "    if score < score_threshold:\n",
    "        continue\n",
    "\n",
    "    if current_label is None:\n",
    "        current_label = label\n",
    "        current_start_sec = seg['start_time']\n",
    "        current_end_sec = seg['end_time']\n",
    "        current_scores.append(score)\n",
    "        if bbox:\n",
    "            current_bboxes.append(bbox)\n",
    "        continue\n",
    "\n",
    "    if label == current_label and seg['start_time'] <= current_end_sec:\n",
    "        current_end_sec = max(current_end_sec, seg['end_time'])\n",
    "        current_scores.append(score)\n",
    "        if bbox:\n",
    "            current_bboxes.append(bbox)\n",
    "    else:\n",
    "        avg_score = sum(current_scores) / len(current_scores)\n",
    "\n",
    "        # ➕ Gemiddelde bounding box berekenen (als er bboxen zijn)\n",
    "        if current_bboxes:\n",
    "            avg_bbox = {\n",
    "                'x': int(np.mean([b['x'] for b in current_bboxes])),\n",
    "                'y': int(np.mean([b['y'] for b in current_bboxes])),\n",
    "                'w': int(np.mean([b['w'] for b in current_bboxes])),\n",
    "                'h': int(np.mean([b['h'] for b in current_bboxes])),\n",
    "                'frame_size': current_bboxes[0]['frame_size']\n",
    "            }\n",
    "        else:\n",
    "            avg_bbox = None\n",
    "\n",
    "        final_segments.append({\n",
    "            'label': current_label,\n",
    "            'start': current_start_sec,\n",
    "            'end': current_end_sec,\n",
    "            'avg_score': avg_score,\n",
    "            'avg_bounding_box': avg_bbox\n",
    "        })\n",
    "\n",
    "        # Nieuw segment starten\n",
    "        current_label = label\n",
    "        current_start_sec = seg['start_time']\n",
    "        current_end_sec = seg['end_time']\n",
    "        current_scores = [score]\n",
    "        current_bboxes = [bbox] if bbox else []\n",
    "\n",
    "# Vergeet laatste segment niet\n",
    "if current_label is not None:\n",
    "    avg_score = sum(current_scores) / len(current_scores)\n",
    "\n",
    "    if current_bboxes:\n",
    "        avg_bbox = {\n",
    "            'x': int(np.mean([b['x'] for b in current_bboxes])),\n",
    "            'y': int(np.mean([b['y'] for b in current_bboxes])),\n",
    "            'w': int(np.mean([b['w'] for b in current_bboxes])),\n",
    "            'h': int(np.mean([b['h'] for b in current_bboxes])),\n",
    "            'frame_size': current_bboxes[0]['frame_size']\n",
    "        }\n",
    "    else:\n",
    "        avg_bbox = None\n",
    "\n",
    "    final_segments.append({\n",
    "        'label': current_label,\n",
    "        'start': current_start_sec,\n",
    "        'end': current_end_sec,\n",
    "        'avg_score': avg_score,\n",
    "        'avg_bounding_box': avg_bbox\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultaten printen\n",
    "for fs in final_segments:\n",
    "    print(f\"Actie '{fs['label']}' van {fs['start']:.2f}s tot {fs['end']:.2f}s (Gemiddelde score: {fs['avg_score']:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "output_json_path = os.path.join(r\"C:\\Users\\maxim\\OneDrive\\01-Opleidingen\\03-MAAI\\Afstuderen\\mmaction2\", \"final_segments_with_boxes_machine_cover_2.json\")\n",
    "\n",
    "with open(output_json_path, 'w') as f:\n",
    "    json.dump(final_segments, f, indent=4)\n",
    "\n",
    "print(f\"JSON-bestand opgeslagen: {output_json_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Totaal uitgevoerde tijd: {elapsed_time:.2f} seconden\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmcv import VideoReader\n",
    "import cv2\n",
    "\n",
    "def annotate_video_with_segments(video_path, segments, output_path, font_scale=0.6):\n",
    "    vr = VideoReader(video_path)\n",
    "    fps = vr.fps\n",
    "    width, height = vr.resolution\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "    for frame_idx, frame in enumerate(vr):\n",
    "        current_time = frame_idx / fps\n",
    "        annotated_frame = frame.copy()\n",
    "\n",
    "        for seg in segments:\n",
    "            if seg['start'] <= current_time <= seg['end']:\n",
    "                label = seg['label']\n",
    "                bbox = seg.get('avg_bounding_box')\n",
    "                if bbox:\n",
    "                    x, y, w, h = bbox['x'], bbox['y'], bbox['w'], bbox['h']\n",
    "                    cv2.rectangle(annotated_frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                    cv2.putText(\n",
    "                        annotated_frame,\n",
    "                        f\"{label}\",\n",
    "                        (x, y - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        font_scale,\n",
    "                        (0, 255, 0),\n",
    "                        2\n",
    "                    )\n",
    "        writer.write(annotated_frame)\n",
    "\n",
    "    writer.release()\n",
    "    print(f\"Annotated video opgeslagen: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_video_path = os.path.join(r\"C:\\Users\\maxim\\OneDrive\\01-Opleidingen\\03-MAAI\\Afstuderen\\mmaction2\", \"annotated_output_stabilizer_pressure_control.mp4\")\n",
    "annotate_video_with_segments(video_path, final_segments, annotated_video_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HAR_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
