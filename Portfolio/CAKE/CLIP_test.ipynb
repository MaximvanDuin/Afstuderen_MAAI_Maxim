{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d5f6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Paden instellen\n",
    "object_path = r\"C:\\Users\\maxim\\OneDrive\\01-Opleidingen\\03-MAAI\\Afstuderen\\Objectdetectie\\detections_with_tracking_YOLOv12mv8_stabilizer_pressure_control.json\"\n",
    "har_path = r\"C:\\Users\\maxim\\OneDrive\\01-Opleidingen\\03-MAAI\\Afstuderen\\mmaction2\\final_segments_with_boxes_stabilizer_pressure_control.json\"\n",
    "chunk_path = \"updated_chunks_with_segments_and_captions.json\"\n",
    "output_path = \"updated_chunks_with_clip_object_action_links.json\"\n",
    "\n",
    "# CLIP initialiseren\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "# JSON inladen\n",
    "with open(object_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    object_data = json.load(f)\n",
    "\n",
    "with open(har_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    action_data = json.load(f)\n",
    "\n",
    "with open(chunk_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    chunk_data = json.load(f)\n",
    "\n",
    "# IoU berekening\n",
    "def calculate_iou(box1, box2):\n",
    "    x1 = max(box1[\"x\"], box2[\"x\"])\n",
    "    y1 = max(box1[\"y\"], box2[\"y\"])\n",
    "    x2 = min(box1[\"x\"] + box1[\"width\"], box2[\"x\"] + box2[\"width\"])\n",
    "    y2 = min(box1[\"y\"] + box1[\"height\"], box2[\"y\"] + box2[\"height\"])\n",
    "    inter_area = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "    union_area = (\n",
    "        box1[\"width\"] * box1[\"height\"] + box2[\"width\"] * box2[\"height\"] - inter_area\n",
    "    )\n",
    "    return inter_area / union_area if union_area != 0 else 0.0\n",
    "\n",
    "# Crop image uit frame\n",
    "def crop_from_frame(frame_path, bbox):\n",
    "    try:\n",
    "        image = Image.open(frame_path).convert(\"RGB\")\n",
    "        x = int(bbox[\"x\"])\n",
    "        y = int(bbox[\"y\"])\n",
    "        w = int(bbox[\"width\"])\n",
    "        h = int(bbox[\"height\"])\n",
    "        return preprocess(image.crop((x, y, x + w, y + h))).unsqueeze(0).to(device)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Fout bij crop van {frame_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Filter objecten per chunk\n",
    "def match_objects_to_chunk(start, end):\n",
    "    return [\n",
    "        {**obj, \"object_id\": obj_id}\n",
    "        for obj_id, obj in object_data.items()\n",
    "        if obj[\"last_seen\"] >= start and obj[\"first_seen\"] <= end\n",
    "    ]\n",
    "\n",
    "# Filter acties per chunk\n",
    "def match_actions_to_chunk(start, end):\n",
    "    return [\n",
    "        act for act in action_data\n",
    "        if act[\"end\"] >= start and act[\"start\"] <= end\n",
    "    ]\n",
    "\n",
    "# Debug output vóór verwerking\n",
    "print(f\"\\nTotaal chunks: {len(chunk_data['chunks'])}\")\n",
    "print(f\"Totaal acties in har_path: {len(action_data)}\")\n",
    "print(f\"Totaal objecten in object_path: {len(object_data)}\\n\")\n",
    "\n",
    "# Start verwerking\n",
    "for chunk in tqdm(chunk_data[\"chunks\"], desc=\"CLIP object-actie matching\"):\n",
    "    start = chunk[\"start\"]\n",
    "    end = chunk[\"end\"]\n",
    "    frames = chunk.get(\"frames\", [])\n",
    "    objects = match_objects_to_chunk(start, end)\n",
    "    actions = match_actions_to_chunk(start, end)\n",
    "\n",
    "    print(f\"\\nChunk {start:.2f}s – {end:.2f}s\")\n",
    "    print(f\"Aantal frames: {len(frames)}\")\n",
    "    print(f\"Aantal objecten: {len(objects)}\")\n",
    "    print(f\"Aantal acties: {len(actions)}\")\n",
    "\n",
    "    if not objects:\n",
    "        print(\"Geen objecten gevonden\")\n",
    "    if not actions:\n",
    "        print(\"Geen acties gevonden\")\n",
    "\n",
    "    links = []\n",
    "\n",
    "    for obj in objects:\n",
    "        class_name = obj[\"class_name\"]\n",
    "        trajectory = obj[\"trajectory\"]\n",
    "\n",
    "        for act in actions:\n",
    "            act_box = {\n",
    "                \"x\": act[\"avg_bounding_box\"][\"x\"],\n",
    "                \"y\": act[\"avg_bounding_box\"][\"y\"],\n",
    "                \"width\": act[\"avg_bounding_box\"][\"w\"],\n",
    "                \"height\": act[\"avg_bounding_box\"][\"h\"]\n",
    "            }\n",
    "\n",
    "            traj_points = [\n",
    "                pt for pt in trajectory\n",
    "                if act[\"start\"] <= pt[\"time\"] <= act[\"end\"]\n",
    "            ]\n",
    "\n",
    "            for pt in traj_points:\n",
    "                iou = calculate_iou(pt[\"bbox\"], act_box)\n",
    "                if iou < 0.05:\n",
    "                    print(f\"IoU te laag ({iou:.3f}) tussen object en actie\")\n",
    "                    continue\n",
    "\n",
    "                if not frames:\n",
    "                    print(\"Geen frames beschikbaar\")\n",
    "                    continue\n",
    "\n",
    "                frame_path = frames[0][\"frame_path\"]\n",
    "                if not os.path.exists(frame_path):\n",
    "                    print(f\"Frame bestaat niet: {frame_path}\")\n",
    "                    continue\n",
    "\n",
    "                print(f\"Frame: {frame_path}\")\n",
    "                print(f\"Crop bbox: {pt['bbox']}\")\n",
    "\n",
    "                crop_tensor = crop_from_frame(frame_path, pt[\"bbox\"])\n",
    "                if crop_tensor is None:\n",
    "                    continue\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    image_feat = model.encode_image(crop_tensor)\n",
    "                    text_feat = model.encode_text(clip.tokenize([act[\"label\"]]).to(device))\n",
    "                    sim = torch.cosine_similarity(image_feat, text_feat)[0].item()\n",
    "\n",
    "                print(f\"Vergelijking met actie '{act['label']}': CLIP sim = {sim:.3f}\")\n",
    "\n",
    "                if sim >= 0.05:\n",
    "                    links.append({\n",
    "                        \"object_id\": obj[\"object_id\"],\n",
    "                        \"class_name\": class_name,\n",
    "                        \"matched_action\": act[\"label\"],\n",
    "                        \"iou\": iou,\n",
    "                        \"cosine_similarity\": sim,\n",
    "                        \"frame_path\": frame_path\n",
    "                    })\n",
    "                break\n",
    "\n",
    "    chunk[\"clip_object_action_links\"] = links\n",
    "    print(f\"Koppelingen gevonden: {len(links)}\")\n",
    "\n",
    "# Opslaan\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(chunk_data, f, indent=4)\n",
    "\n",
    "print(f\"\\nCLIP-koppelingen opgeslagen naar {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4251f471",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Pad naar bestand met CLIP-links\n",
    "json_path = \"updated_chunks_with_clip_object_action_links.json\"\n",
    "\n",
    "# Laad de JSON\n",
    "with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Print alle koppelingen per chunk\n",
    "totaal_links = 0\n",
    "for i, chunk in enumerate(data[\"chunks\"], start=1):\n",
    "    links = chunk.get(\"clip_object_action_links\", [])\n",
    "    if links:\n",
    "        print(f\"\\nChunk {i} ({chunk['start']:.2f}s – {chunk['end']:.2f}s): {len(links)} koppelingen\")\n",
    "        for link in links:\n",
    "            print(f\"Object '{link['class_name']}' ⟶ Actie '{link['matched_action']}' | Sim: {link['cosine_similarity']:.3f} | IoU: {link['iou']:.2f}\")\n",
    "        totaal_links += len(links)\n",
    "\n",
    "print(f\"\\nTotaal aantal CLIP-koppelingen: {totaal_links}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
