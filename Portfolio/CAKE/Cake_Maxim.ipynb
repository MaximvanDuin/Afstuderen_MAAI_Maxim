{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4cbc735",
   "metadata": {},
   "source": [
    "# CAKE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fe478d",
   "metadata": {},
   "source": [
    "## Audio bestand maken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963964aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47ccae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96be92e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mp4_to_wav(input_mp4_path, output_wav_path):\n",
    "    print(f\"Converting '{input_mp4_path}' to WAV format...\")\n",
    "    audio = AudioSegment.from_file(input_mp4_path, format=\"mp4\")\n",
    "    audio.export(output_wav_path, format=\"wav\")\n",
    "    print(f\"Conversion complete! WAV file saved to: {output_wav_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c36577",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = r\"C:\\Users\\maxim\\OneDrive\\01-Opleidingen\\03-MAAI\\Afstuderen\\Data\\Video's\\machine cover.mp4\"\n",
    "aud = r\"C:\\Users\\maxim\\OneDrive\\01-Opleidingen\\03-MAAI\\Afstuderen\\Cake\\Data_machine_cover\\machine_cover.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71613363",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_mp4_to_wav(vid, aud)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14d7bc5",
   "metadata": {},
   "source": [
    "## Transcribe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbc56d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisperx\n",
    "import gc\n",
    "import torch\n",
    "import json\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f3b654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "wav_folder = r\"C:\\Users\\maxim\\OneDrive\\01-Opleidingen\\03-MAAI\\Afstuderen\\Cake\\Data_machine_cover\"\n",
    "output_folder = \"transcriptions_machine_cover\"\n",
    "unsupported_folder = \"unsupported_language_machine_cover\"\n",
    "model_dir = \"whisper-models\"\n",
    "vad_model_path = r\"C:\\Users\\maxim\\OneDrive\\01-Opleidingen\\03-MAAI\\Afstuderen\\Cake\\CAKE\\VAD\\pytorch_model.bin\"\n",
    "audio_path = r\"C:\\Users\\maxim\\OneDrive\\01-Opleidingen\\03-MAAI\\Afstuderen\\Cake\\Data_machine_cover\\machine_cover.wav\"\n",
    "\n",
    "# Ensure output folders exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "os.makedirs(unsupported_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1ea35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe(audio_file):\n",
    "    # # Check system for compatibility\n",
    "    # if torch.cuda.is_available():\n",
    "    #     device = \"cuda\"\n",
    "    #     print(\"CUDA wordt gebruikt\")\n",
    "    #     compute_type = \"float16\"  # change to \"int8\" if low on GPU mem (may reduce accuracy)\n",
    "    #     batch_size = 16  # reduce if low on GPU mem\n",
    "    # elif torch.backends.mps.is_available():\n",
    "    #     device = \"cpu\"\n",
    "    #     print(\"MPS (Apple Silicon) gebruikt\")\n",
    "    #     compute_type = \"int8\"\n",
    "    #     batch_size = 8\n",
    "    # else:\n",
    "    #     print(\"CPU gebruikt\")\n",
    "    #     device = \"cpu\"\n",
    "    #     compute_type = \"int8\"\n",
    "    #     batch_size = 4\n",
    "    \n",
    "    print(\"CPU gebruikt\")\n",
    "    device = \"cpu\"\n",
    "    compute_type = \"int8\"\n",
    "    batch_size = 4\n",
    "\n",
    "    if not os.path.exists(model_dir):\n",
    "        model = whisperx.load_model(\"large-v2\", device, compute_type=compute_type, download_root=model_dir)\n",
    "    else:\n",
    "        model = whisperx.load_model(\"./whisper-models/models--Systran--faster-whisper-large-v2/snapshots/f0fe81560cb8b68660e564f55dd99207059c092e\", device, compute_type=compute_type, vad_model_fp=vad_model_path)\n",
    "\n",
    "    audio = whisperx.load_audio(audio_file)\n",
    "\n",
    "    # Perform transcription with automatic language detection\n",
    "    result = model.transcribe(audio, batch_size=batch_size)\n",
    "    detected_language = result.get(\"language\", \"en\")\n",
    "\n",
    "    # Check if detected language is supported, otherwise move file to unsupported folder\n",
    "    if detected_language not in [\"en\", \"fr\", \"de\", \"es\", \"nl\"]:\n",
    "        print(f\"Language detected as {detected_language}, moving to unsupported folder.\")\n",
    "        os.rename(audio_file, os.path.join(unsupported_folder, os.path.basename(audio_file)))\n",
    "        return\n",
    "\n",
    "    print(f\"Detected language: {detected_language}\")\n",
    "\n",
    "   \n",
    "    try:\n",
    "        model_a, metadata = whisperx.load_align_model(language_code=detected_language, device=device)\n",
    "        result = whisperx.align(result[\"segments\"], model_a, metadata, audio, device, return_char_alignments=False)\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        del model_a\n",
    "    except ValueError as e:\n",
    "        print(f\"Skipping alignment due to error: {e}\")\n",
    "\n",
    "    # Save as JSON\n",
    "    base_filename = os.path.splitext(os.path.basename(audio_file))[0]\n",
    "    output_json_path = os.path.join(output_folder, f\"{base_filename}.json\")\n",
    "    with open(output_json_path, 'w') as f:\n",
    "        json.dump(result, f, indent=2)\n",
    "\n",
    "    print(f\"Results saved to {output_json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2777f356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all WAV files in the folder\n",
    "for filename in os.listdir(wav_folder):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        audio_path = os.path.join(wav_folder, filename)\n",
    "        transcribe(audio_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0c9a07",
   "metadata": {},
   "source": [
    "## Full text of transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b8bc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Input directory containing JSON files\n",
    "json_folder = 'transcriptions_machine_cover'\n",
    "output_dir = 'individual_texts_machine_cover'\n",
    "\n",
    "# Maak output directory aan als deze niet bestaat\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(f\"Output directory '{output_dir}' is ready.\")\n",
    "\n",
    "# Process each JSON file individually\n",
    "for json_file in os.listdir(json_folder):\n",
    "    if json_file.endswith('.json'):\n",
    "        json_path = os.path.join(json_folder, json_file)\n",
    "        print(f\"Processing file: {json_file}\")\n",
    "\n",
    "        # Controleer of het JSON-bestand geldig is\n",
    "        try:\n",
    "            with open(json_path, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "        except (json.JSONDecodeError, FileNotFoundError) as e:\n",
    "            print(f\"Error: Failed to process '{json_file}'. Details: {e}\")\n",
    "            continue\n",
    "\n",
    "        segments = data.get('segments', [])\n",
    "        if not segments:\n",
    "            print(f\"Warning: No segments found in '{json_file}'.\")\n",
    "            continue\n",
    "\n",
    "        # Create output text file for the individual transcript\n",
    "        individual_output_path = os.path.join(output_dir, json_file.replace('.json', '.txt'))\n",
    "\n",
    "        with open(individual_output_path, 'w', encoding='utf-8') as individual_file:\n",
    "            for i, segment in enumerate(segments, start=1):\n",
    "                text = segment.get('text', '').strip()\n",
    "                if not text:\n",
    "                    print(f\"Warning: Segment {i} in '{json_file}' is empty.\")\n",
    "                    continue\n",
    "                individual_file.write(f\"{text} \")\n",
    "\n",
    "        print(f\"Transcript saved to '{individual_output_path}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94eeb94",
   "metadata": {},
   "source": [
    "## Output chonkie chunks with timestamp (in json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3f5861",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from chonkie import SDPMChunker\n",
    "\n",
    "def load_document(file_path: str) -> str:\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"The file '{file_path}' does not exist.\")\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "    return content\n",
    "\n",
    "def load_json(file_path: str) -> dict:\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"Error: The JSON file '{file_path}' does not exist.\")\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        try:\n",
    "            return json.load(f)\n",
    "        except json.JSONDecodeError as e:\n",
    "            raise ValueError(f\"Error: Failed to decode JSON file. Details: {e}\")\n",
    "\n",
    "def create_chunker(embedding_model=\"minishlab/potion-base-8M\", chunk_size=512, min_sentences=1):\n",
    "\n",
    "    return SDPMChunker(\n",
    "        embedding_model=embedding_model,\n",
    "        chunk_size=chunk_size,\n",
    "        min_sentences=min_sentences\n",
    "    )\n",
    "\n",
    "# def process_text_and_json(text_folder: str, json_folder: str, output_folder: str):\n",
    "\n",
    "#     if not os.path.exists(output_folder):\n",
    "#         os.makedirs(output_folder)\n",
    "\n",
    "#     for text_file in os.listdir(text_folder):\n",
    "#         if text_file.endswith(\".txt\"):\n",
    "#             base_name = os.path.splitext(text_file)[0]\n",
    "#             text_path = os.path.join(text_folder, text_file)\n",
    "#             json_path = os.path.join(json_folder, base_name + \".json\")\n",
    "\n",
    "#             if not os.path.exists(json_path):\n",
    "#                 print(f\"Warning: No matching JSON file for {text_file}\")\n",
    "#                 continue\n",
    "\n",
    "#             text_content = load_document(text_path)\n",
    "#             json_data = load_json(json_path)\n",
    "#             segments = json_data.get('word_segments', [])\n",
    "\n",
    "#             if not segments:\n",
    "#                 raise ValueError(f\"Error: No segments found in the JSON file {json_path}.\")\n",
    "\n",
    "#             word_list = [[seg.get('word', '').strip(), seg.get('start', ''), seg.get('end', '')] for seg in segments if seg.get('word', '').strip()]\n",
    "#             chunker = create_chunker()\n",
    "#             chunks = chunker.chunk(text_content)\n",
    "\n",
    "#             final_chunks = []\n",
    "#             current_word_index = 0\n",
    "#             for chunk in chunks:\n",
    "#                 chunk_text = chunk.text\n",
    "#                 chunk_words = chunk_text.split()\n",
    "#                 chunk_word_data = []\n",
    "#                 chunk_start = None\n",
    "#                 chunk_end = None\n",
    "\n",
    "#                 for chunk_word in chunk_words:\n",
    "#                     if current_word_index < len(word_list):\n",
    "#                         word_info = word_list[current_word_index]\n",
    "#                         if chunk_word == word_info[0]:\n",
    "#                             chunk_word_data.append({\n",
    "#                                 \"word\": word_info[0],\n",
    "#                                 \"start\": word_info[1],\n",
    "#                                 \"end\": word_info[2]\n",
    "#                             })\n",
    "#                             if chunk_start is None:\n",
    "#                                 chunk_start = word_info[1]\n",
    "#                             chunk_end = word_info[2]\n",
    "#                             current_word_index += 1\n",
    "#                         else:\n",
    "#                             raise ValueError(f\"Word mismatch at chunk '{chunk_text}': Expected '{word_info[0]}', found '{chunk_word}'.\")\n",
    "#                     else:\n",
    "#                         raise IndexError(\"Ran out of words in word_data to match with chunks.\")\n",
    "\n",
    "#                 final_chunks.append({\n",
    "#                     \"text\": chunk_text,\n",
    "#                     \"start\": chunk_start,\n",
    "#                     \"end\": chunk_end,\n",
    "#                     \"words\": chunk_word_data\n",
    "#                 })\n",
    "\n",
    "#             output_json_path = os.path.join(output_folder, base_name + \"_chunks.json\")\n",
    "#             with open(output_json_path, 'w', encoding='utf-8') as f:\n",
    "#                 json.dump({\"chunks\": final_chunks}, f, ensure_ascii=False, indent=4)\n",
    "#                 print(f\"Processed {text_file} and saved to {output_json_path}\")\n",
    "\n",
    "def is_valid_time(value):\n",
    "    try:\n",
    "        return value not in (None, '', ' ') and float(value) >= 0\n",
    "    except (ValueError, TypeError):\n",
    "        return False\n",
    "\n",
    "def process_text_and_json(text_folder: str, json_folder: str, output_folder: str):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for text_file in os.listdir(text_folder):\n",
    "        if text_file.endswith(\".txt\"):\n",
    "            base_name = os.path.splitext(text_file)[0]\n",
    "            text_path = os.path.join(text_folder, text_file)\n",
    "            json_path = os.path.join(json_folder, base_name + \".json\")\n",
    "\n",
    "            if not os.path.exists(json_path):\n",
    "                print(f\"Warning: No matching JSON file for {text_file}\")\n",
    "                continue\n",
    "\n",
    "            text_content = load_document(text_path)\n",
    "            json_data = load_json(json_path)\n",
    "            segments = json_data.get('word_segments', [])\n",
    "\n",
    "            if not segments:\n",
    "                raise ValueError(f\"Error: No segments found in the JSON file {json_path}.\")\n",
    "\n",
    "            word_list = [\n",
    "                [seg.get('word', '').strip(), seg.get('start'), seg.get('end')]\n",
    "                for seg in segments\n",
    "                if seg.get('word', '').strip()\n",
    "                and is_valid_time(seg.get('start'))\n",
    "                and is_valid_time(seg.get('end'))\n",
    "            ]\n",
    "\n",
    "            total_segments = len(segments)\n",
    "            valid_segments = len(word_list)\n",
    "            skipped_segments = total_segments - valid_segments\n",
    "            if skipped_segments > 0:\n",
    "                print(f\"Waarschuwing: {skipped_segments} ongeldige segmenten overgeslagen in {json_path}\")\n",
    "\n",
    "            chunker = create_chunker()\n",
    "            chunks = chunker.chunk(text_content)\n",
    "\n",
    "            final_chunks = []\n",
    "            current_word_index = 0\n",
    "            total_words = len(word_list)\n",
    "\n",
    "            for chunk in chunks:\n",
    "                chunk_text = chunk.text.strip()\n",
    "                approx_num_words = len(chunk_text.split())\n",
    "\n",
    "                chunk_word_data = []\n",
    "                chunk_start = None\n",
    "                chunk_end = None\n",
    "\n",
    "                for _ in range(approx_num_words):\n",
    "                    if current_word_index >= total_words:\n",
    "                        break\n",
    "                    word_info = word_list[current_word_index]\n",
    "                    chunk_word_data.append({\n",
    "                        \"word\": word_info[0],\n",
    "                        \"start\": word_info[1],\n",
    "                        \"end\": word_info[2]\n",
    "                    })\n",
    "                    if chunk_start is None:\n",
    "                        chunk_start = word_info[1]\n",
    "                    chunk_end = word_info[2]\n",
    "                    current_word_index += 1\n",
    "\n",
    "                final_chunks.append({\n",
    "                    \"text\": chunk_text,\n",
    "                    \"start\": chunk_start,\n",
    "                    \"end\": chunk_end,\n",
    "                    \"words\": chunk_word_data\n",
    "                })\n",
    "\n",
    "            output_json_path = os.path.join(output_folder, base_name + \"_chunks.json\")\n",
    "            with open(output_json_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump({\"chunks\": final_chunks}, f, ensure_ascii=False, indent=4)\n",
    "                print(f\"Processed {text_file} and saved to {output_json_path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    text_folder = 'individual_texts_machine_cover'\n",
    "    json_folder = 'transcriptions_machine_cover'\n",
    "    output_folder = 'processed_json_machine_cover'\n",
    "    process_text_and_json(text_folder, json_folder, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba9908b",
   "metadata": {},
   "source": [
    "## Video segmentation chonkie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5fb18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "def create_segments(video_file, result):\n",
    "\n",
    "    if not os.path.exists(result):\n",
    "        raise FileNotFoundError(f\"Error: The result file '{result}' does not exist.\")\n",
    "\n",
    "    with open(result, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    segments = data.get('chunks', [])\n",
    "    if not segments:\n",
    "        raise ValueError(\"No segments found in the JSON file.\")\n",
    "\n",
    "    video_name = os.path.splitext(os.path.basename(video_file))[0]\n",
    "    output_dir = os.path.join('video_segments_machine_cover', video_name)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"Output directory '{output_dir}' is ready.\")\n",
    "\n",
    "    for i, segment in enumerate(segments, start=1):\n",
    "        start = segment['start']\n",
    "        end = segment['end']\n",
    "        output_filename = f\"segment_{i}_{int(start)}_{int(end)}.mp4\"\n",
    "        output_path = os.path.join(output_dir, output_filename)\n",
    "\n",
    "        command = [\n",
    "            \"ffmpeg\",\n",
    "            \"-y\",\n",
    "            \"-i\", video_file,\n",
    "            \"-ss\", str(start),\n",
    "            \"-to\", str(end),\n",
    "            \"-c:v\", \"libx264\",\n",
    "            \"-c:a\", \"aac\",\n",
    "            output_path\n",
    "        ]\n",
    "        print(f\"Creating segment {i}: {start} to {end} seconds for {video_file}.\")\n",
    "        subprocess.run(command, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "        print(f\"Segment {i} saved as '{output_filename}'.\")\n",
    "\n",
    "    print(f\"All segments for {video_file} have been processed.\")\n",
    "\n",
    "def process_videos_in_directory(video_directory, json_directory):\n",
    "\n",
    "    if not os.path.isdir(video_directory):\n",
    "        raise NotADirectoryError(f\"Error: The directory '{video_directory}' does not exist.\")\n",
    "    if not os.path.isdir(json_directory):\n",
    "        raise NotADirectoryError(f\"Error: The directory '{json_directory}' does not exist.\")\n",
    "\n",
    "    video_files = sorted(f for f in os.listdir(video_directory) if f.endswith('.mp4'))\n",
    "    json_files = sorted(f for f in os.listdir(json_directory) if f.endswith('.json'))\n",
    "\n",
    "    for video_file, json_file in zip(video_files, json_files):\n",
    "        video_path = os.path.join(video_directory, video_file)\n",
    "        json_path = os.path.join(json_directory, json_file)\n",
    "        create_segments(video_path, json_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    video_directory = r\"C:\\Users\\maxim\\OneDrive\\01-Opleidingen\\03-MAAI\\Afstuderen\\Cake\\Video_machine_cover\"  # Replace with your video directory\n",
    "    json_directory = \"processed_json_machine_cover\"  # Replace with your JSON directory\n",
    "    process_videos_in_directory(video_directory, json_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f7f2dd",
   "metadata": {},
   "source": [
    "## Frame Extraction\n",
    "### 1 frame per 3 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dece0dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def extract_frames(video_path, output_dir, interval_seconds=3):\n",
    "    video_name = os.path.basename(video_path).replace(\".\", \"_\")\n",
    "    segment_output_dir = os.path.join(output_dir, *video_path.split(os.sep)[-2:])\n",
    "    os.makedirs(segment_output_dir, exist_ok=True)\n",
    "\n",
    "    vidcap = cv2.VideoCapture(video_path)\n",
    "    fps = vidcap.get(cv2.CAP_PROP_FPS)\n",
    "    if fps <= 0:\n",
    "        print(f\"Kan de FPS voor {video_path} niet ophalen.\")\n",
    "        return\n",
    "\n",
    "    frame_interval = int(fps * interval_seconds)\n",
    "    success, image = vidcap.read()\n",
    "    count = 0\n",
    "    frame_count = 0\n",
    "\n",
    "    while success:\n",
    "        if frame_count % frame_interval == 0:\n",
    "            frame_path = os.path.join(segment_output_dir, f\"{video_name}_frame_{count}.jpg\")\n",
    "            cv2.imwrite(frame_path, image)\n",
    "            count += 1\n",
    "        success, image = vidcap.read()\n",
    "        frame_count += 1\n",
    "\n",
    "    vidcap.release()\n",
    "    print(f\"Geëxtraheerd {count} frames uit {video_path} naar {segment_output_dir}\")\n",
    "\n",
    "def process_videos_in_directory(base_directory, output_directory, interval_seconds=3):\n",
    "    if not os.path.isdir(base_directory):\n",
    "        raise NotADirectoryError(f\"Error: De map '{base_directory}' bestaat niet.\")\n",
    "\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    print(f\"Output directory '{output_directory}' is gereed.\")\n",
    "\n",
    "    for subdir in sorted(os.listdir(base_directory)):\n",
    "        subdir_path = os.path.join(base_directory, subdir)\n",
    "        if os.path.isdir(subdir_path):\n",
    "            for filename in sorted(os.listdir(subdir_path)):\n",
    "                if filename.lower().endswith(('.mp4', '.avi', '.mov', '.mkv')):\n",
    "                    video_path = os.path.join(subdir_path, filename)\n",
    "                    extract_frames(video_path, output_directory, interval_seconds)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    video_directory = \"video_segments_machine_cover\"  # Vervang dit door jouw basisvideo-segmentenmap\n",
    "    output_directory = \"frames_machine_cover\"         # Map om geëxtraheerde frames op te slaan\n",
    "    process_videos_in_directory(video_directory, output_directory, interval_seconds=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7648e9f1",
   "metadata": {},
   "source": [
    "## Object segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d1caea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple\n",
    "from PIL import Image\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator\n",
    "\n",
    "@dataclass\n",
    "class BoxPrompt:\n",
    "    x1: float\n",
    "    y1: float\n",
    "    x2: float\n",
    "    y2: float\n",
    "\n",
    "class AdvancedAutoSAM:\n",
    "    def __init__(self, model_type=\"vit_l\", model_path=\"./models/sam_vit_l_0b3195.pth\"):\n",
    "        self.model_type = model_type\n",
    "        self.model_path = model_path\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self._load_model()\n",
    "\n",
    "    def _load_model(self):\n",
    "        print(f\"Loading SAM model: {self.model_type}...\")\n",
    "        self.sam = sam_model_registry[self.model_type](checkpoint=self.model_path)\n",
    "        self.sam.to(self.device)\n",
    "        self.mask_generator = SamAutomaticMaskGenerator(self.sam)\n",
    "        print(\"SAM model loaded.\")\n",
    "\n",
    "    def auto_generate_masks(self, image_path: str) -> List[np.ndarray]:\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            raise ValueError(f\"Failed to load {image_path}\")\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        masks = self.mask_generator.generate(image_rgb)\n",
    "        binary_masks = [m['segmentation'].astype(np.uint8) * 255 for m in masks]\n",
    "        print(f\"Generated {len(binary_masks)} masks.\")\n",
    "        return binary_masks\n",
    "\n",
    "    def save_masks_as_color_overlay(self, masks: List[np.ndarray], image_path: str, output_path: str):\n",
    "        image_bgr = cv2.imread(image_path)\n",
    "        overlay = image_bgr.copy()\n",
    "        for mask in masks:\n",
    "            color = np.random.randint(0, 255, size=3, dtype=np.uint8)\n",
    "            mask_indices = mask > 0\n",
    "            overlay[mask_indices] = (0.5 * overlay[mask_indices] + 0.5 * color).astype(np.uint8)\n",
    "        cv2.imwrite(output_path, overlay)\n",
    "        print(f\"Overlay saved to {output_path}\")\n",
    "\n",
    "    def save_masks_individually(self, masks: List[np.ndarray], output_folder: str, base_name: str = \"mask\"):\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        for idx, mask in enumerate(masks, 1):\n",
    "            path = os.path.join(output_folder, f\"{base_name}_{idx}.png\")\n",
    "            cv2.imwrite(path, mask)\n",
    "            print(f\"Saved mask to {path}\")\n",
    "\n",
    "    def save_segments_individually(self, masks: List[np.ndarray], image_path: str, output_folder: str, base_name: str = \"segment\"):\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        image = cv2.imread(image_path)\n",
    "        for idx, mask in enumerate(masks, 1):\n",
    "            segment = cv2.bitwise_and(image, image, mask=mask)\n",
    "            path = os.path.join(output_folder, f\"{base_name}_{idx}.png\")\n",
    "            cv2.imwrite(path, segment)\n",
    "            print(f\"Saved segment to {path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3e29d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    auto_sam = AdvancedAutoSAM()\n",
    "\n",
    "    input_dir = \"frames_machine_cover/machine_cover/\"\n",
    "    output_dir = \"generated_results_machine_cover\"\n",
    "    overlay_dir = os.path.join(output_dir, \"overlays\")\n",
    "    masks_dir = os.path.join(output_dir, \"masks\")\n",
    "    segments_dir = os.path.join(output_dir, \"segments\")\n",
    "\n",
    "    os.makedirs(overlay_dir, exist_ok=True)\n",
    "    os.makedirs(masks_dir, exist_ok=True)\n",
    "    os.makedirs(segments_dir, exist_ok=True)\n",
    "\n",
    "    supported_extensions = ('.jpg', '.jpeg', '.png', '.bmp')\n",
    "\n",
    "    for root, _, files in os.walk(input_dir):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(supported_extensions):\n",
    "                image_path = os.path.join(root, file)\n",
    "                base_name = os.path.splitext(file)[0]\n",
    "\n",
    "                print(f\"\\nProcessing {image_path}...\")\n",
    "                try:\n",
    "                    masks = auto_sam.auto_generate_masks(image_path)\n",
    "                    if not masks:\n",
    "                        continue\n",
    "                    auto_sam.save_masks_as_color_overlay(\n",
    "                        masks, image_path,\n",
    "                        os.path.join(overlay_dir, f\"{base_name}_overlay.png\")\n",
    "                    )\n",
    "                    auto_sam.save_masks_individually(\n",
    "                        masks,\n",
    "                        os.path.join(masks_dir, f\"{base_name}_masks\")\n",
    "                    )\n",
    "                    auto_sam.save_segments_individually(\n",
    "                        masks,\n",
    "                        image_path,\n",
    "                        os.path.join(segments_dir, f\"{base_name}_segments\")\n",
    "                    )\n",
    "                    torch.cuda.empty_cache()\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {file}: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce28c865",
   "metadata": {},
   "source": [
    "## Image captioning on the frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de38b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "from transformers import VisionEncoderDecoderModel, ViTImageProcessor, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "\n",
    "# Pad naar de hoofd directory met geëxtraheerde frames (alle video segmenten)\n",
    "frames_dir = \"frames_machine_cover/machine_cover/\"  # Pas dit aan naar jouw frames hoofd directory\n",
    "\n",
    "# Output JSON bestand\n",
    "output_json_path = \"combined_frames_machine_cover.json\"\n",
    "\n",
    "\n",
    "def initialize_captioning_model():\n",
    "\n",
    "    print(\"Initialiseren van het image captioning model...\")\n",
    "    model = VisionEncoderDecoderModel.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "    feature_extractor = ViTImageProcessor.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "    print(\"Model geïnitieerd.\")\n",
    "    return model, feature_extractor, tokenizer\n",
    "\n",
    "\n",
    "def generate_caption(image_path, model, feature_extractor, tokenizer, device):\n",
    "\n",
    "    try:\n",
    "        # print(f\"Generating caption for: {image_path}\")  # Optioneel: Kan veel output genereren\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        pixel_values = feature_extractor(images=image, return_tensors=\"pt\").pixel_values.to(device)\n",
    "\n",
    "        output_ids = model.generate(pixel_values, max_length=16, num_beams=4)\n",
    "        caption = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "        return caption\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating caption for {image_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def process_all_frames(frames_dir, model, feature_extractor, tokenizer, device):\n",
    "    combined_data = []\n",
    "    supported_extensions = ('.png', '.jpg', '.jpeg', '.bmp', '.tiff')\n",
    "\n",
    "    if not os.path.isdir(frames_dir):\n",
    "        print(f\"Error: Frames directory {frames_dir} bestaat niet.\")\n",
    "        return combined_data\n",
    "\n",
    "    # Itereer over alle subdirectories (video segmenten)\n",
    "    video_segments = [d for d in os.listdir(frames_dir) if os.path.isdir(os.path.join(frames_dir, d))]\n",
    "    total_segments = len(video_segments)\n",
    "    print(f\"Found {total_segments} video segments in '{frames_dir}'.\")\n",
    "\n",
    "    for seg_idx, segment in enumerate(sorted(video_segments), start=1):\n",
    "        segment_path = os.path.join(frames_dir, segment)\n",
    "        frame_files = [f for f in os.listdir(segment_path) if f.lower().endswith(supported_extensions)]\n",
    "\n",
    "        if not frame_files:\n",
    "            print(f\"error: Geen frames gevonden in segment '{segment}'.\")\n",
    "            continue\n",
    "\n",
    "        total_frames = len(frame_files)\n",
    "        print(f\"Processing segment {seg_idx}/{total_segments}: '{segment}' with {total_frames} frames.\")\n",
    "\n",
    "        for idx, frame_file in enumerate(sorted(frame_files), start=1):\n",
    "            frame_path = os.path.join(segment_path, frame_file)\n",
    "\n",
    "            # Genereer een caption voor het frame\n",
    "            caption = generate_caption(frame_path, model, feature_extractor, tokenizer, device)\n",
    "            # print(f\"Generated caption for {frame_file}: {caption}\")  # Optioneel: kan veel output genereren\n",
    "\n",
    "            # Voeg de gecombineerde data toe aan de lijst\n",
    "            combined_data.append({\n",
    "                \"video_segment\": segment,  # Naam van het video segment\n",
    "                \"frame_number\": idx - 1,  # Frames starten meestal bij 0\n",
    "                \"frame_filename\": frame_file,\n",
    "                \"caption\": caption\n",
    "            })\n",
    "\n",
    "            if idx % 100 == 0 or idx == total_frames:\n",
    "                print(f\"Segment '{segment}': Processed {idx}/{total_frames} frames.\")\n",
    "\n",
    "    return combined_data\n",
    "\n",
    "\n",
    "def save_combined_data(combined_data, output_json_path):\n",
    "\n",
    "    try:\n",
    "        with open(output_json_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(combined_data, f, indent=4)\n",
    "        print(f\"Combined JSON saved to '{output_json_path}'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving JSON file: {e}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Initialiseer het captioning model\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"Using device: {device}\")\n",
    "    model, feature_extractor, tokenizer = initialize_captioning_model()\n",
    "    model.to(device)\n",
    "\n",
    "    # Genereer captions voor alle frames\n",
    "    combined_data = process_all_frames(\n",
    "        frames_dir=frames_dir,\n",
    "        model=model,\n",
    "        feature_extractor=feature_extractor,\n",
    "        tokenizer=tokenizer,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    if not combined_data:\n",
    "        print(\"Geen gecombineerde data om op te slaan.\")\n",
    "        return\n",
    "\n",
    "    # Sla de gecombineerde data op als JSON\n",
    "    save_combined_data(combined_data, output_json_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516d3d94",
   "metadata": {},
   "source": [
    "## Connect segments and captions to chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d48c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "import re\n",
    "\n",
    "def load_json(file_path: str) -> Any:\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def save_json(data: Any, file_path: str):\n",
    "  \n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "    print(f\"JSON opgeslagen als '{file_path}'.\")\n",
    "\n",
    "def parse_segment_filename(filename: str) -> Dict[str, Any]:\n",
    "    pattern = r\"segment_(\\d+)_(\\d+)_(\\d+)\\.mp4\"\n",
    "    match = re.match(pattern, filename)\n",
    "    if match:\n",
    "        return {\n",
    "            \"index\": int(match.group(1)),\n",
    "            \"start\": float(match.group(2)),\n",
    "            \"end\": float(match.group(3))\n",
    "        }\n",
    "    else:\n",
    "        return {}\n",
    "\n",
    "def find_video_segments(chunks: List[Dict[str, Any]], video_segments_dir: str) -> Dict[tuple, str]:\n",
    " \n",
    "    video_segments = os.listdir(video_segments_dir)\n",
    "    segment_map = {}\n",
    "    for segment_file in video_segments:\n",
    "        parsed = parse_segment_filename(segment_file)\n",
    "        if not parsed:\n",
    "            print(f\" file '{segment_file}' not same as pattern\")\n",
    "            continue\n",
    "        key = (parsed['start'], parsed['end'])\n",
    "        segment_map[key] = os.path.join(video_segments_dir, segment_file)\n",
    "    return segment_map\n",
    "\n",
    "def find_frames_for_segment(frames_dir: str, segment_filename: str) -> List[str]:\n",
    "\n",
    "    segment_frame_dir = os.path.join(frames_dir, segment_filename)\n",
    "    if not os.path.isdir(segment_frame_dir):\n",
    "        print(f\"error: Frames directory '{segment_frame_dir}' not exist.\")\n",
    "        return []\n",
    "    frames = [os.path.join(segment_frame_dir, f) for f in os.listdir(segment_frame_dir) \n",
    "              if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff'))]\n",
    "    return sorted(frames)  # Sorteer frames op naam\n",
    "\n",
    "def find_object_segments_for_frame(generated_segments_dir: str, segment_filename: str, frame_filename: str) -> List[str]:\n",
    "    # Voorbeeld pad:\n",
    "    # generated_segments/segment_1_0_32.mp4/segment_1_0_32_mp4_frame_000003_segments/segment_1.png\n",
    "    frame_basename = os.path.splitext(os.path.basename(frame_filename))[0]  # segment_1_0_32_mp4_frame_000003\n",
    "    segments_folder = os.path.join(generated_segments_dir, f\"{frame_basename}_segments\")\n",
    "    if not os.path.isdir(segments_folder):\n",
    "        print(f\"Waarschuwing: Object segments directory '{segments_folder}' bestaat niet.\")\n",
    "        return []\n",
    "    object_segments = [os.path.join(segments_folder, f) for f in os.listdir(segments_folder) \n",
    "                       if f.lower().endswith('.png')]\n",
    "    return sorted(object_segments)  # Sorteer object segmenten op naam\n",
    "\n",
    "def load_captions(captions_json_path: str) -> Dict[str, str]:\n",
    "    captions_data = load_json(captions_json_path)\n",
    "    caption_map = {}\n",
    "    for entry in captions_data:\n",
    "        video_segment = entry.get('video_segment')\n",
    "        frame_filename = entry.get('frame_filename')\n",
    "        caption = entry.get('caption', \"\")\n",
    "        if video_segment and frame_filename:\n",
    "            key = f\"{video_segment}/{frame_filename}\"\n",
    "            caption_map[key] = caption\n",
    "    print(f\"Loaded captions for {len(caption_map)} frames.\")\n",
    "    return caption_map\n",
    "\n",
    "def update_chunks_with_segments_and_captions(original_chunks: List[Dict[str, Any]], \n",
    "                                segment_map: Dict[tuple, str],\n",
    "                                frames_dir: str,\n",
    "                                generated_segments_dir: str,\n",
    "                                captions_map: Dict[str, str]) -> List[Dict[str, Any]]:\n",
    "\n",
    "    updated_chunks = []\n",
    "    for chunk in original_chunks:\n",
    "        chunk_start = chunk['start']\n",
    "        chunk_end = chunk['end']\n",
    "        key = (int(chunk_start), int(chunk_end))\n",
    "        video_segment_path = segment_map.get(key)\n",
    "        if not video_segment_path:\n",
    "            print(f\"error: no video segment found for chunk start {chunk_start} and end {chunk_end}.\")\n",
    "            continue  # Of handle anders, afhankelijk van behoeften\n",
    "        \n",
    "        segment_filename = os.path.basename(video_segment_path)\n",
    "        frames = find_frames_for_segment(frames_dir, segment_filename)\n",
    "        frames_info = []\n",
    "        for frame_path in frames:\n",
    "            frame_filename = os.path.basename(frame_path)\n",
    "            object_segments = find_object_segments_for_frame(generated_segments_dir, segment_filename, frame_filename)\n",
    "            # Koppel de caption op basis van video_segment en frame_filename\n",
    "            caption_key = f\"{segment_filename}/{frame_filename}\"\n",
    "            caption = captions_map.get(caption_key, \"\")\n",
    "            frames_info.append({\n",
    "                \"frame_path\": frame_path,\n",
    "                \"object_segments\": object_segments,\n",
    "                \"caption\": caption\n",
    "            })\n",
    "        \n",
    "        # Voeg video segment en frames info toe aan de chunk\n",
    "        updated_chunk = {\n",
    "            \"text\": chunk['text'],\n",
    "            \"start\": chunk['start'],\n",
    "            \"end\": chunk['end'],\n",
    "            \"video_segment\": video_segment_path,\n",
    "            \"frames\": frames_info,\n",
    "            \"words\": chunk.get('words', [])\n",
    "        }\n",
    "        updated_chunks.append(updated_chunk)\n",
    "    \n",
    "    return updated_chunks\n",
    "\n",
    "def main():\n",
    "    # Definieer paden\n",
    "    original_json_path = \"processed_json_machine_cover/machine_cover_chunks.json\"  # Originele JSON met chunks\n",
    "    video_segments_dir = \"video_segments_machine_cover/machine_cover\"  # Map met video segmenten\n",
    "    frames_dir = \"frames_machine_cover/machine_cover\"  # Hoofd map met frames per segment\n",
    "    generated_segments_dir = \"generated_results_machine_cover/segments\"  # Map met object segmenten\n",
    "    captions_json_path = \"combined_frames_machine_cover.json\"  # JSON met image captions\n",
    "    new_json_path = \"updated_chunks_with_segments_and_captions_machine_cover.json\"  # Nieuwe JSON output\n",
    "\n",
    "    # Controleer of alle benodigde bestanden en directories bestaan\n",
    "    if not os.path.exists(original_json_path):\n",
    "        print(f\"Error: Originele JSON bestand '{original_json_path}' bestaat niet.\")\n",
    "        return\n",
    "    if not os.path.isdir(video_segments_dir):\n",
    "        print(f\"Error: Video segments directory '{video_segments_dir}' bestaat niet.\")\n",
    "        return\n",
    "    if not os.path.isdir(frames_dir):\n",
    "        print(f\"Error: Frames directory '{frames_dir}' bestaat niet.\")\n",
    "        return\n",
    "    if not os.path.isdir(generated_segments_dir):\n",
    "        print(f\"Error: Generated segments directory '{generated_segments_dir}' bestaat niet.\")\n",
    "        return\n",
    "    if not os.path.exists(captions_json_path):\n",
    "        print(f\"Error: Captions JSON bestand '{captions_json_path}' bestaat niet.\")\n",
    "        return\n",
    "\n",
    "    # Laad originele JSON\n",
    "    original_data = load_json(original_json_path)\n",
    "    chunks = original_data.get('chunks', [])\n",
    "    if not chunks:\n",
    "        print(\"Geen chunks gevonden in de originele JSON.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Loaded {len(chunks)} chunks from '{original_json_path}'.\")\n",
    "\n",
    "    # Maak een mapping van (start, end) tijden naar video segment paden\n",
    "    segment_map = find_video_segments(chunks, video_segments_dir)\n",
    "    print(f\"Found {len(segment_map)} video segments.\")\n",
    "\n",
    "    # Laad captions en maak een mapping\n",
    "    captions_map = load_captions(captions_json_path)\n",
    "\n",
    "    # Update chunks met video segmenten, frames, object segmenten en captions\n",
    "    updated_chunks = update_chunks_with_segments_and_captions(\n",
    "        chunks, \n",
    "        segment_map, \n",
    "        frames_dir, \n",
    "        generated_segments_dir, \n",
    "        captions_map\n",
    "    )\n",
    "\n",
    "    print(f\"Updated {len(updated_chunks)} chunks with segments and captions.\")\n",
    "\n",
    "    # Maak de nieuwe JSON structuur\n",
    "    new_data = {\n",
    "        \"chunks\": updated_chunks\n",
    "    }\n",
    "\n",
    "    # Sla de nieuwe JSON op\n",
    "    save_json(new_data, new_json_path)\n",
    "    print(f\"new JSON with connected segments and captions saved as '{new_json_path}'.\")\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9087a3b",
   "metadata": {},
   "source": [
    "## Sentence transformer captions linking to chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a57dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import List, Dict, Any\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "def load_json(file_path: str) -> Any:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def save_json(data: Any, file_path: str):\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "    print(f\"JSON opgeslagen als '{file_path}'.\")\n",
    "\n",
    "def preprocess_chunks(chunks: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "    processed_chunks = []\n",
    "    for chunk in chunks:\n",
    "        text = chunk.get('text', \"\")\n",
    "        if text:\n",
    "            # Gebruik zowel start als end tijden als float voor unieke identificatie\n",
    "            processed_chunks.append({\n",
    "                \"chunk_id\": f\"{chunk['start']}_{chunk['end']}\",\n",
    "                \"text\": text,\n",
    "                \"start\": chunk['start'],\n",
    "                \"end\": chunk['end']\n",
    "            })\n",
    "    return processed_chunks\n",
    "\n",
    "def preprocess_captions(captions: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "    processed_captions = []\n",
    "    for caption in captions:\n",
    "        text = caption.get('caption', \"\")\n",
    "        if text:\n",
    "            processed_captions.append({\n",
    "                \"video_segment\": caption.get('video_segment', \"\"),\n",
    "                \"frame_filename\": caption.get('frame_filename', \"\"),\n",
    "                \"caption\": text\n",
    "            })\n",
    "    return processed_captions\n",
    "\n",
    "def compute_embeddings(model: SentenceTransformer, texts: List[str], batch_size: int = 32) -> torch.Tensor:\n",
    "\n",
    "    embeddings = model.encode(texts, batch_size=batch_size, convert_to_tensor=True, show_progress_bar=True)\n",
    "    return embeddings\n",
    "\n",
    "def parse_segment_times(segment_name: str) -> tuple[int, int]:\n",
    "    match = re.search(r\"segment_\\d+_(\\d+)_(\\d+)\", segment_name)\n",
    "    if match:\n",
    "        return int(match.group(1)), int(match.group(2))\n",
    "    return (0, 0)\n",
    "\n",
    "# # Captions worden verkeerd gelinkt aan de chunks\n",
    "# def link_captions_to_chunks(\n",
    "#     chunks: List[Dict[str, Any]],\n",
    "#     captions: List[Dict[str, Any]],\n",
    "#     similarity_threshold: float = 0.3\n",
    "# ) -> List[Dict[str, Any]]:\n",
    "\n",
    "#     # Initialiseer het SentenceTransformer model\n",
    "#     model = SentenceTransformer('all-mpnet-base-v2')  # Een model dat langere teksten ondersteunt\n",
    "#     device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#     model = model.to(device)\n",
    "\n",
    "#     # Voorbereiden van teksten\n",
    "#     chunk_texts = [chunk['text'] for chunk in chunks]\n",
    "#     caption_texts = [caption['caption'] for caption in captions]\n",
    "\n",
    "#     # Compute embeddings\n",
    "#     print(\"Computing embeddings for chunks...\")\n",
    "#     chunk_embeddings = compute_embeddings(model, chunk_texts).to(device)\n",
    "#     print(\"Computing embeddings for captions...\")\n",
    "#     caption_embeddings = compute_embeddings(model, caption_texts).to(device)\n",
    "\n",
    "#     # Bereken cosine similarity tussen elke caption en alle chunks\n",
    "#     print(\"Calculating cosine similarities...\")\n",
    "#     cosine_similarities = util.cos_sim(caption_embeddings, chunk_embeddings)  # Shape: (num_captions, num_chunks)\n",
    "\n",
    "#     # Voor elke caption, vind de chunk met hoogste similarity\n",
    "#     print(\"Linking captions to chunks based on similarity...\")\n",
    "#     links = []\n",
    "#     for idx, caption in enumerate(tqdm(captions, desc=\"Linking Captions\")):\n",
    "#         sim_scores = cosine_similarities[idx]\n",
    "#         top_result = torch.argmax(sim_scores).item()\n",
    "#         top_score = sim_scores[top_result].item()\n",
    "#         if top_score >= similarity_threshold:\n",
    "#             linked_chunk = chunks[top_result]\n",
    "#             links.append({\n",
    "#                 \"caption_index\": idx,\n",
    "#                 \"frame_filename\": caption['frame_filename'],\n",
    "#                 \"video_segment\": caption['video_segment'],\n",
    "#                 \"caption\": caption['caption'],\n",
    "#                 \"linked_chunk_id\": linked_chunk['chunk_id'],\n",
    "#                 \"linked_chunk_text\": linked_chunk['text'],\n",
    "#                 \"similarity_score\": top_score\n",
    "#             })\n",
    "#         else:\n",
    "#             links.append({\n",
    "#                 \"caption_index\": idx,\n",
    "#                 \"frame_filename\": caption['frame_filename'],\n",
    "#                 \"video_segment\": caption['video_segment'],\n",
    "#                 \"caption\": caption['caption'],\n",
    "#                 \"linked_chunk_id\": None,\n",
    "#                 \"linked_chunk_text\": None,\n",
    "#                 \"similarity_score\": top_score\n",
    "#             })\n",
    "#     return links\n",
    "\n",
    "# def link_captions_to_chunks(\n",
    "#     chunks: List[Dict[str, Any]],\n",
    "#     captions: List[Dict[str, Any]],\n",
    "#     similarity_threshold: float = 0.00\n",
    "# ) -> List[Dict[str, Any]]:\n",
    "\n",
    "#     model = SentenceTransformer('all-mpnet-base-v2')\n",
    "#     device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#     model = model.to(device)\n",
    "\n",
    "#     links = []\n",
    "\n",
    "#     for idx, caption in enumerate(tqdm(captions, desc=\"Linking Captions\")):\n",
    "#         segment_name = caption.get(\"video_segment\", \"\")\n",
    "#         caption_text = caption.get(\"caption\", \"\").strip()\n",
    "\n",
    "#         if not caption_text or not segment_name:\n",
    "#             continue\n",
    "\n",
    "#         segment_start, segment_end = parse_segment_times(segment_name)\n",
    "\n",
    "#         # Filter relevante chunks op basis van segmenttijd\n",
    "#         candidate_chunks = [\n",
    "#             chunk for chunk in chunks\n",
    "#             if segment_start <= chunk[\"start\"] <= segment_end or\n",
    "#                segment_start <= chunk[\"end\"] <= segment_end\n",
    "#         ]\n",
    "\n",
    "#         if not candidate_chunks:\n",
    "#             print(f\"Geen chunks gevonden binnen tijdsframe {segment_start}–{segment_end} voor caption {idx}\")\n",
    "#             links.append({\n",
    "#                 \"caption_index\": idx,\n",
    "#                 \"frame_filename\": caption.get(\"frame_filename\", \"\"),\n",
    "#                 \"video_segment\": segment_name,\n",
    "#                 \"caption\": caption_text,\n",
    "#                 \"linked_chunk_id\": None,\n",
    "#                 \"linked_chunk_text\": None,\n",
    "#                 \"similarity_score\": None\n",
    "#             })\n",
    "#             continue\n",
    "\n",
    "#         # Bereken embeddings voor caption en chunks\n",
    "#         chunk_texts = [chunk[\"text\"] for chunk in candidate_chunks]\n",
    "#         chunk_embeddings = compute_embeddings(model, chunk_texts).to(device)\n",
    "#         caption_embedding = compute_embeddings(model, [caption_text]).to(device)[0]\n",
    "\n",
    "#         # Bereken cosine similarity\n",
    "#         similarities = util.cos_sim(caption_embedding, chunk_embeddings)[0]\n",
    "#         top_result = torch.argmax(similarities).item()\n",
    "#         top_score = similarities[top_result].item()\n",
    "\n",
    "#         if top_score >= similarity_threshold:\n",
    "#             best_chunk = candidate_chunks[top_result]\n",
    "#             links.append({\n",
    "#                 \"caption_index\": idx,\n",
    "#                 \"frame_filename\": caption.get(\"frame_filename\", \"\"),\n",
    "#                 \"video_segment\": segment_name,\n",
    "#                 \"caption\": caption_text,\n",
    "#                 \"linked_chunk_id\": best_chunk['chunk_id'],\n",
    "#                 \"linked_chunk_text\": best_chunk['text'],\n",
    "#                 \"similarity_score\": top_score\n",
    "#             })\n",
    "#         else:\n",
    "#             links.append({\n",
    "#                 \"caption_index\": idx,\n",
    "#                 \"frame_filename\": caption.get(\"frame_filename\", \"\"),\n",
    "#                 \"video_segment\": segment_name,\n",
    "#                 \"caption\": caption_text,\n",
    "#                 \"linked_chunk_id\": None,\n",
    "#                 \"linked_chunk_text\": None,\n",
    "#                 \"similarity_score\": top_score\n",
    "#             })\n",
    "\n",
    "#     return links\n",
    "\n",
    "def link_captions_to_chunks(\n",
    "    chunks: List[Dict[str, Any]],\n",
    "    captions: List[Dict[str, Any]],\n",
    "    similarity_threshold: float = 0.3\n",
    ") -> List[Dict[str, Any]]:\n",
    "\n",
    "    model = SentenceTransformer('all-mpnet-base-v2')\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model = model.to(device)\n",
    "\n",
    "    links = []\n",
    "\n",
    "    for idx, caption in enumerate(tqdm(captions, desc=\"Linking Captions\")):\n",
    "        segment_name = caption.get(\"video_segment\", \"\")\n",
    "        caption_text = caption.get(\"caption\", \"\").strip()\n",
    "\n",
    "        if not caption_text or not segment_name:\n",
    "            continue\n",
    "\n",
    "        segment_start, segment_end = parse_segment_times(segment_name)\n",
    "        \n",
    "        margin = 1\n",
    "        candidate_chunks = [\n",
    "            chunk for chunk in chunks\n",
    "                if chunk[\"start\"] >= segment_start - margin and chunk[\"end\"] <= segment_end + margin\n",
    "        ]\n",
    "\n",
    "        if not candidate_chunks:\n",
    "            links.append({\n",
    "                \"caption_index\": idx,\n",
    "                \"frame_filename\": caption.get(\"frame_filename\", \"\"),\n",
    "                \"video_segment\": segment_name,\n",
    "                \"caption\": caption_text,\n",
    "                \"linked_chunk_id\": None,\n",
    "                \"linked_chunk_text\": None,\n",
    "                \"similarity_score\": None\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        # Bereken caption embedding correct als tensor\n",
    "        caption_embedding = model.encode([caption_text], convert_to_tensor=True).to(device)\n",
    "\n",
    "        chunk_texts = [chunk[\"text\"] for chunk in candidate_chunks]\n",
    "        chunk_embeddings = model.encode(chunk_texts, convert_to_tensor=True).to(device)\n",
    "\n",
    "        similarities = util.cos_sim(caption_embedding, chunk_embeddings)[0]  # shape: (num_chunks,)\n",
    "        top_idx = torch.argmax(similarities).item()\n",
    "        top_score = similarities[top_idx].item()\n",
    "\n",
    "        print(f\"Caption {idx}: top_score = {top_score:.4f}, threshold = {similarity_threshold}\")\n",
    "\n",
    "\n",
    "        if top_score >= similarity_threshold:\n",
    "            linked_chunk = candidate_chunks[top_idx]\n",
    "            links.append({\n",
    "                \"caption_index\": idx,\n",
    "                \"frame_filename\": caption.get(\"frame_filename\", \"\"),\n",
    "                \"video_segment\": segment_name,\n",
    "                \"caption\": caption_text,\n",
    "                \"linked_chunk_id\": linked_chunk['chunk_id'],\n",
    "                \"linked_chunk_text\": linked_chunk['text'],\n",
    "                \"similarity_score\": top_score\n",
    "            })\n",
    "        else:\n",
    "            links.append({\n",
    "                \"caption_index\": idx,\n",
    "                \"frame_filename\": caption.get(\"frame_filename\", \"\"),\n",
    "                \"video_segment\": segment_name,\n",
    "                \"caption\": caption_text,\n",
    "                \"linked_chunk_id\": None,\n",
    "                \"linked_chunk_text\": None,\n",
    "                \"similarity_score\": top_score\n",
    "            })\n",
    "\n",
    "    return links\n",
    "\n",
    "\n",
    "def filter_linked_captions(links: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Filter de links om alleen de gekoppelde captions te behouden.\n",
    "    \"\"\"\n",
    "    filtered_links = [link for link in links if link['linked_chunk_id'] is not None]\n",
    "    print(f\"Filtered captions: {len(filtered_links)} out of {len(links)} were successfully linked.\")\n",
    "    return filtered_links\n",
    "\n",
    "def main():\n",
    "    # Definieer paden\n",
    "    chunks_json_path = \"processed_json_machine_cover/machine_cover_chunks.json\"        # Originele JSON met chunks\n",
    "    captions_json_path = \"combined_frames_machine_cover.json\"              # JSON met image captions\n",
    "    output_mapping_path = \"captions_to_chunks_mapping_machine_cover.json\" # Nieuwe JSON output (alle koppelingen)\n",
    "    filtered_output_path = \"filtered_captions_to_chunks_mapping_machine_cover.json\" # Nieuwe JSON output (gekoppelde captions)\n",
    "\n",
    "    # Controleer of alle benodigde bestanden bestaan\n",
    "    required_files = [chunks_json_path, captions_json_path]\n",
    "    for file in required_files:\n",
    "        if not os.path.exists(file):\n",
    "            print(f\"Error: Vereist bestand '{file}' bestaat niet.\")\n",
    "            return\n",
    "\n",
    "    # Laad de JSON-bestanden\n",
    "    print(\"Loading JSON files...\")\n",
    "    chunks_data = load_json(chunks_json_path)\n",
    "    captions_data = load_json(captions_json_path)\n",
    "\n",
    "    chunks = chunks_data.get('chunks', [])\n",
    "    captions = captions_data  # Verondersteld dat combined_frames.json een lijst is\n",
    "\n",
    "    if not chunks:\n",
    "        print(\"Geen chunks gevonden in de hoofd JSON.\")\n",
    "        return\n",
    "    if not captions:\n",
    "        print(\"Geen captions gevonden in de captions JSON.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Loaded {len(chunks)} chunks and {len(captions)} captions.\")\n",
    "\n",
    "    # Voorbereiden van data\n",
    "    processed_chunks = preprocess_chunks(chunks)\n",
    "    processed_captions = preprocess_captions(captions)\n",
    "\n",
    "    # Koppel captions aan chunks via Sentence Transformers\n",
    "    links = link_captions_to_chunks(processed_chunks, processed_captions, similarity_threshold=0.1)\n",
    "    print(f\"Generated {len(links)} caption links.\")\n",
    "\n",
    "    # Sla de volledige mapping op als een nieuwe JSON\n",
    "    save_json(links, output_mapping_path)\n",
    "    print(f\"Captions to chunks mapping saved to '{output_mapping_path}'.\")\n",
    "\n",
    "    # Filter de gekoppelde captions\n",
    "    filtered_links = filter_linked_captions(links)\n",
    "\n",
    "    # Sla de gefilterde mapping op als een nieuwe JSON\n",
    "    save_json(filtered_links, filtered_output_path)\n",
    "    print(f\"Filtered captions to chunks mapping saved to '{filtered_output_path}'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133ba0f5",
   "metadata": {},
   "source": [
    "# Cake\n",
    "## Download model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521cc115",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n",
    "\n",
    "llm = Llama.from_pretrained(\n",
    "    repo_id=\"bartowski/Qwen2.5-7B-Instruct-GGUF\",\n",
    "    filename=\"*Q4_K_M.gguf\",\n",
    "    verbose=False,\n",
    "    local_dir=\"models\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fd3c4b",
   "metadata": {},
   "source": [
    "## Knowledge extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c253f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import threading\n",
    "from llama_cpp import Llama\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "from json import JSONDecodeError\n",
    "\n",
    "# llama singleton to ensure one model is used for ram usage efficiency\n",
    "class LlamaSingleton:\n",
    "    _instance = None\n",
    "    _lock = threading.Lock()\n",
    "\n",
    "    def __new__(cls, model_path=\"models/Qwen2.5-7B-Instruct-Q4_K_M.gguf\", chat_format=\"chatml\"):\n",
    "        with cls._lock:\n",
    "            if cls._instance is None:\n",
    "                cls._instance = super(LlamaSingleton, cls).__new__(cls)\n",
    "                cls._instance.llm = Llama(model_path=model_path, chat_format=chat_format, n_ctx=2048)\n",
    "            return cls._instance\n",
    "\n",
    "# chatbot class to extract knowledge from chunks\n",
    "class Chatbot:\n",
    "    def __init__(self, \n",
    "                 messages_file='messages_machine_cover.json', \n",
    "                 knowledge_file='knowledge_machine_cover.json', \n",
    "                 faiss_index_file='faiss_index_machine_cover.pkl',\n",
    "                 model_name='all-MiniLM-L6-v2'):\n",
    "        self.messages_file = messages_file\n",
    "        self.knowledge_file = knowledge_file\n",
    "        self.faiss_index_file = faiss_index_file\n",
    "        self.llm = LlamaSingleton().llm\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.index = None\n",
    "        self.knowledge_data = []\n",
    "        self.initialize_files()\n",
    "        self.load_faiss_index()\n",
    "\n",
    "    def initialize_files(self):\n",
    "        for file in [self.messages_file, self.knowledge_file]:\n",
    "            if not os.path.exists(file):\n",
    "                with open(file, 'w') as f:\n",
    "                    json.dump([], f)\n",
    "\n",
    "    def load_json_data(self, file_path):\n",
    "        with open(file_path, 'r') as f:\n",
    "            return json.load(f)\n",
    "\n",
    "    def save_json_data(self, file_path, data):\n",
    "        with open(file_path, 'w') as f:\n",
    "            json.dump(data, f, indent=4)\n",
    "\n",
    "    # this function extracts the knowledge from the chunk text\n",
    "    def extract_valuable_knowledge(self, message):\n",
    "        \"\"\"\n",
    "        Sends the chunk text to the model and asks it to return JSON with\n",
    "        subject/predicate/object. No timestamps are generated by the model.\n",
    "        \"\"\"\n",
    "        response = self.llm.create_chat_completion(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": (\n",
    "                        \"You are a knowledge extractor. Try to extract any knowledge.\\n\"\n",
    "                        \"Return ONLY JSON with the following schema:\\n\"\n",
    "                        \"{\\n\"\n",
    "                        \"  \\\"valuable_knowledge\\\": [\\n\"\n",
    "                        \"    {\\n\"\n",
    "                        \"      \\\"subject\\\": \\\"...\\\",\\n\"\n",
    "                        \"      \\\"predicate\\\": \\\"...\\\",\\n\"\n",
    "                        \"      \\\"object\\\": \\\"...\\\"\\n\"\n",
    "                        \"    }\\n\"\n",
    "                        \"  ]\\n\"\n",
    "                        \"}\\n\"\n",
    "                        \"If no knowledge can be extracted, return:\\n\"\n",
    "                        \"{\\\"valuable_knowledge\\\": []}\"\n",
    "                    )\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": message},\n",
    "            ],\n",
    "            response_format={\n",
    "                \"type\": \"json\",\n",
    "                \"schema\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"valuable_knowledge\": {\n",
    "                            \"type\": \"array\",\n",
    "                            \"items\": {\n",
    "                                \"type\": \"object\",\n",
    "                                \"properties\": {\n",
    "                                    \"subject\": {\"type\": \"string\"},\n",
    "                                    \"predicate\": {\"type\": \"string\"},\n",
    "                                    \"object\": {\"type\": \"string\"}\n",
    "                                },\n",
    "                                \"required\": [\"subject\", \"predicate\", \"object\"]\n",
    "                            }\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"valuable_knowledge\"],\n",
    "                },\n",
    "            },\n",
    "            temperature=0.5,\n",
    "        )\n",
    "        try:\n",
    "            knowledge_data = json.loads(response['choices'][0]['message']['content'])\n",
    "            print(\"Extracted knowledge from a chunk:\", knowledge_data)\n",
    "            if \"valuable_knowledge\" not in knowledge_data:\n",
    "                knowledge_data[\"valuable_knowledge\"] = []\n",
    "            return knowledge_data[\"valuable_knowledge\"]\n",
    "        except (JSONDecodeError, KeyError):\n",
    "            return []\n",
    "\n",
    "    def save_knowledge(self, triplets):\n",
    "        \"\"\"\n",
    "        Persists triplets to `knowledge.json` and updates FAISS index if new triplets\n",
    "        are found. We do not add any timestamps here.\n",
    "        \"\"\"\n",
    "        if not triplets:\n",
    "            return\n",
    "        knowledge = self.load_json_data(self.knowledge_file)\n",
    "        existing_set = {(t['subject'], t['predicate'], t['object']) for t in knowledge}\n",
    "        new_triplets = []\n",
    "        for triplet in triplets:\n",
    "            key = (triplet['subject'], triplet['predicate'], triplet['object'])\n",
    "            if key not in existing_set:\n",
    "                knowledge.append(triplet)\n",
    "                new_triplets.append(triplet)\n",
    "                existing_set.add(key)\n",
    "        self.save_json_data(self.knowledge_file, knowledge)\n",
    "        if new_triplets:\n",
    "            self.update_faiss_index(new_triplets)\n",
    "\n",
    "    def update_faiss_index(self, triplets):\n",
    "        texts = [f\"{t['subject']} {t['predicate']} {t['object']}\" for t in triplets]\n",
    "        embeddings = self.model.encode(texts)\n",
    "        if self.index is None:\n",
    "            self.index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "        self.index.add(np.array(embeddings, dtype=np.float32))\n",
    "        self.knowledge_data.extend(triplets)\n",
    "        self.save_faiss_index()\n",
    "\n",
    "    def save_faiss_index(self):\n",
    "        with open(self.faiss_index_file, 'wb') as f:\n",
    "            pickle.dump((self.index, self.knowledge_data), f)\n",
    "\n",
    "    def load_faiss_index(self):\n",
    "        if os.path.exists(self.faiss_index_file):\n",
    "            with open(self.faiss_index_file, 'rb') as f:\n",
    "                self.index, self.knowledge_data = pickle.load(f)\n",
    "        else:\n",
    "            self.index = None\n",
    "            self.knowledge_data = []\n",
    "\n",
    "# def main():\n",
    "#     # Load the chunks from output_chunks.json\n",
    "#     with open('filtered_captions_to_chunks_mapping.json', 'r', encoding='utf-8') as file: # Misschien moet filterd hier in \n",
    "#         # updated_chunks_with_segments_and_captions.json\n",
    "\n",
    "#         data = json.load(file)\n",
    "#     chunks = data.get(\"chunks\", [])\n",
    "#     print(f\"Total chunks loaded: {len(chunks)}\")\n",
    "\n",
    "#     # Extract Knowledge from Each Chunk\n",
    "#     chatbot = Chatbot()\n",
    "\n",
    "#     for i, chunk in enumerate(chunks, start=1):\n",
    "#         text = chunk.get(\"text\", \"\")\n",
    "#         start_time = chunk.get(\"start\")\n",
    "#         end_time = chunk.get(\"end\")\n",
    "\n",
    "#         print(f\"\\nProcessing chunk {i} (Start: {start_time}, End: {end_time})\")\n",
    "\n",
    "#         # Extract valuable knowledge from the chunk text\n",
    "#         extracted_knowledge = chatbot.extract_valuable_knowledge(text)\n",
    "\n",
    "#         if extracted_knowledge:\n",
    "\n",
    "#             # Attach the chunk's start/end timestamps of video to each extracted item\n",
    "#             for triplet in extracted_knowledge:\n",
    "#                 triplet['start'] = start_time\n",
    "#                 triplet['end'] = end_time\n",
    "\n",
    "#             # Save the extracted knowledge\n",
    "#             chatbot.save_knowledge(extracted_knowledge)\n",
    "\n",
    "#     print(\"\\nKnowledge extraction complete.\")\n",
    "#     print(\"Please check 'knowledge.json' for the extracted valuable knowledge.\")\n",
    "\n",
    "# def main():\n",
    "#     # Laad het correcte JSON-bestand (lijst van items)\n",
    "#     with open('filtered_captions_to_chunks_mapping.json', 'r', encoding='utf-8') as file:\n",
    "#         links = json.load(file)\n",
    "\n",
    "#     print(f\"Totaal aantal gekoppelde captions: {len(links)}\")\n",
    "\n",
    "#     # Initialiseer de kennisextractor / chatbot\n",
    "#     chatbot = Chatbot()\n",
    "\n",
    "#     for i, item in enumerate(links, start=1):\n",
    "#         linked_text = item.get(\"linked_chunk_text\", \"\").strip()\n",
    "#         chunk_id = item.get(\"linked_chunk_id\", \"\")\n",
    "\n",
    "#         if not linked_text or not chunk_id:\n",
    "#             print(f\"Skipping item {i}: ontbrekende tekst of ID.\")\n",
    "#             continue\n",
    "\n",
    "#         # Haal start en end tijd uit linked_chunk_id\n",
    "#         try:\n",
    "#             start_str, end_str = chunk_id.split(\"_\")\n",
    "#             start_time = float(start_str)\n",
    "#             end_time = float(end_str)\n",
    "#         except ValueError:\n",
    "#             print(f\"Ongeldig chunk ID formaat in item {i}: '{chunk_id}'\")\n",
    "#             continue\n",
    "\n",
    "#         print(f\"\\n[{i}] Extracting knowledge (chunk {start_time:.2f}–{end_time:.2f})\")\n",
    "\n",
    "#         # Extract knowledge uit de chunktekst\n",
    "#         extracted_knowledge = chatbot.extract_valuable_knowledge(linked_text)\n",
    "\n",
    "#         if extracted_knowledge:\n",
    "#             for triplet in extracted_knowledge:\n",
    "#                 triplet[\"start\"] = start_time\n",
    "#                 triplet[\"end\"] = end_time\n",
    "#             chatbot.save_knowledge(extracted_knowledge)\n",
    "\n",
    "#     print(\"\\nKennisextractie afgerond. Bekijk 'knowledge.json' voor de resultaten.\")\n",
    "\n",
    "# Goed maar gebruikt niet alle audio\n",
    "# def main():\n",
    "#     # Laad het correcte JSON-bestand (lijst van items)\n",
    "#     with open('filtered_captions_to_chunks_mapping.json', 'r', encoding='utf-8') as file:\n",
    "#         links = json.load(file)\n",
    "\n",
    "#     print(f\"Totaal aantal gekoppelde captions: {len(links)}\")\n",
    "\n",
    "#     # Initialiseer de kennisextractor / chatbot\n",
    "#     chatbot = Chatbot()\n",
    "\n",
    "#     for i, item in enumerate(links, start=1):\n",
    "#         caption = item.get(\"caption\", \"\").strip()\n",
    "#         linked_text = item.get(\"linked_chunk_text\", \"\").strip()\n",
    "#         chunk_id = item.get(\"linked_chunk_id\", \"\")\n",
    "\n",
    "#         if not linked_text or not chunk_id:\n",
    "#             print(f\"Skipping item {i}: ontbrekende tekst of ID.\")\n",
    "#             continue\n",
    "\n",
    "#         # Haal start en end tijd uit chunk_id\n",
    "#         try:\n",
    "#             start_str, end_str = chunk_id.split(\"_\")\n",
    "#             start_time = float(start_str)\n",
    "#             end_time = float(end_str)\n",
    "#         except ValueError:\n",
    "#             print(f\"Ongeldig chunk ID formaat in item {i}: '{chunk_id}'\")\n",
    "#             continue\n",
    "\n",
    "#         print(f\"\\n[{i}] Extracting knowledge (chunk {start_time:.2f}–{end_time:.2f})\")\n",
    "\n",
    "#         # Combineer caption + transcripttekst als input voor de LLM\n",
    "#         combined_input = f\"Caption: {caption}\\nTranscript: {linked_text}\"\n",
    "\n",
    "#         # Stuur gecombineerde input naar LLM\n",
    "#         extracted_knowledge = chatbot.extract_valuable_knowledge(combined_input)\n",
    "\n",
    "#         if extracted_knowledge:\n",
    "#             for triplet in extracted_knowledge:\n",
    "#                 triplet[\"start\"] = start_time\n",
    "#                 triplet[\"end\"] = end_time\n",
    "#             chatbot.save_knowledge(extracted_knowledge)\n",
    "\n",
    "#     print(\"\\nKennisextractie afgerond. Bekijk 'knowledge.json' voor de resultaten.\")\n",
    "\n",
    "# Alle audio erbij\n",
    "def main():\n",
    "    # Bestanden\n",
    "    chunks_json_path = \"processed_json_machine_cover/machine_cover_chunks.json\"\n",
    "    captions_mapping_path = \"filtered_captions_to_chunks_mapping_machine_cover.json\"\n",
    "\n",
    "    # Controle\n",
    "    if not os.path.exists(chunks_json_path):\n",
    "        print(f\"Error: Bestand '{chunks_json_path}' bestaat niet.\")\n",
    "        return\n",
    "    if not os.path.exists(captions_mapping_path):\n",
    "        print(f\"Error: Bestand '{captions_mapping_path}' bestaat niet.\")\n",
    "        return\n",
    "\n",
    "    # Laad data\n",
    "    with open(chunks_json_path, 'r', encoding='utf-8') as f:\n",
    "        chunk_data = json.load(f)\n",
    "    all_chunks = chunk_data.get(\"chunks\", [])\n",
    "    print(f\"{len(all_chunks)} transcriptie-chunks geladen.\")\n",
    "\n",
    "    with open(captions_mapping_path, 'r', encoding='utf-8') as f:\n",
    "        caption_links = json.load(f)\n",
    "    print(f\"{len(caption_links)} gekoppelde captions geladen.\")\n",
    "\n",
    "    # Bouw een mapping: chunk_id → lijst van captions\n",
    "    from collections import defaultdict\n",
    "    caption_map = defaultdict(list)\n",
    "    for item in caption_links:\n",
    "        chunk_id = item.get(\"linked_chunk_id\")\n",
    "        caption = item.get(\"caption\")\n",
    "        if chunk_id and caption:\n",
    "            caption_map[chunk_id].append(caption)\n",
    "\n",
    "    # Initialiseer chatbot\n",
    "    chatbot = Chatbot()\n",
    "\n",
    "    # Verwerk alle chunks (met of zonder captions)\n",
    "    for i, chunk in enumerate(all_chunks, start=1):\n",
    "        chunk_text = chunk.get(\"text\", \"\").strip()\n",
    "        start = chunk.get(\"start\")\n",
    "        end = chunk.get(\"end\")\n",
    "        chunk_id = f\"{start}_{end}\"\n",
    "\n",
    "        if not chunk_text:\n",
    "            print(f\"Skipping lege chunk {chunk_id}\")\n",
    "            continue\n",
    "\n",
    "        captions = caption_map.get(chunk_id, [])\n",
    "        if captions:\n",
    "            caption_text = \"\\n\".join([f\"- {c}\" for c in captions])\n",
    "            combined_prompt = f\"Transcript: {chunk_text}\\nCaptions:\\n{caption_text}\"\n",
    "        else:\n",
    "            combined_prompt = f\"Transcript: {chunk_text}\"\n",
    "        \n",
    "\n",
    "        print(f\"\\n[{i}] Extracting knowledge for chunk {chunk_id}\")\n",
    "\n",
    "        print(combined_prompt)\n",
    "        extracted_knowledge = chatbot.extract_valuable_knowledge(combined_prompt)\n",
    "\n",
    "        if extracted_knowledge:\n",
    "            for triplet in extracted_knowledge:\n",
    "                triplet[\"start\"] = start\n",
    "                triplet[\"end\"] = end\n",
    "            chatbot.save_knowledge(extracted_knowledge)\n",
    "\n",
    "    print(\"\\nKennisextractie voltooid. Bekijk 'knowledge.json' voor de resultaten.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1916bbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Totaal uitgevoerde tijd: {elapsed_time:.2f} seconden\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feebab49",
   "metadata": {},
   "source": [
    "## Test generated knowledge base with LLM with the integrated knowledge base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d181ba83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from llama_cpp import Llama\n",
    "import threading\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "from json import JSONDecodeError\n",
    "\n",
    "class LlamaSingleton:\n",
    "    _instance = None\n",
    "    _lock = threading.Lock()\n",
    "\n",
    "    def __new__(cls, model_path=\"models/Qwen2.5-7B-Instruct-Q4_K_M.gguf\", chat_format=\"chatml\"):\n",
    "        with cls._lock:\n",
    "            if cls._instance is None:\n",
    "                cls._instance = super(LlamaSingleton, cls).__new__(cls)\n",
    "                cls._instance.llm = Llama(model_path=model_path, chat_format=chat_format, n_ctx=2048)\n",
    "            return cls._instance\n",
    "\n",
    "class Chatbot:\n",
    "    def __init__(self, \n",
    "                 messages_file='messages.json', \n",
    "                 knowledge_file='knowledge.json', \n",
    "                 faiss_index_file='faiss_index.pkl',\n",
    "                 model_name='all-MiniLM-L6-v2'):\n",
    "        self.messages_file = messages_file\n",
    "        self.knowledge_file = knowledge_file\n",
    "        self.faiss_index_file = faiss_index_file\n",
    "        self.llm = LlamaSingleton().llm\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.index = None\n",
    "        self.knowledge_data = []\n",
    "        self.initialize_files()\n",
    "        self.load_faiss_index()\n",
    "\n",
    "    def initialize_files(self):\n",
    "        for file in [self.messages_file, self.knowledge_file]:\n",
    "            if not os.path.exists(file):\n",
    "                with open(file, 'w') as f:\n",
    "                    json.dump([], f)\n",
    "\n",
    "    def load_json_data(self, file_path):\n",
    "        with open(file_path, 'r') as f:\n",
    "            return json.load(f)\n",
    "\n",
    "    def save_json_data(self, file_path, data):\n",
    "        with open(file_path, 'w') as f:\n",
    "            json.dump(data, f, indent=4)\n",
    "\n",
    "    def save_message(self, role, content):\n",
    "        messages = self.load_json_data(self.messages_file)\n",
    "        message = {\"role\": role, \"content\": content, \"timestamp\": datetime.utcnow().isoformat()}\n",
    "        messages.append(message)\n",
    "        self.save_json_data(self.messages_file, messages)\n",
    "\n",
    "    def save_knowledge(self, triplets):\n",
    "        if not triplets:\n",
    "            return\n",
    "        knowledge = self.load_json_data(self.knowledge_file)\n",
    "        existing_set = {(t['subject'], t['predicate'], t['object']) for t in knowledge}\n",
    "        new_triplets = []\n",
    "        for triplet in triplets:\n",
    "            triplet['timestamp'] = datetime.utcnow().isoformat()\n",
    "            key = (triplet['subject'], triplet['predicate'], triplet['object'])\n",
    "            if key not in existing_set:\n",
    "                knowledge.append(triplet)\n",
    "                new_triplets.append(triplet)\n",
    "                existing_set.add(key)\n",
    "        self.save_json_data(self.knowledge_file, knowledge)\n",
    "        if new_triplets:\n",
    "            self.update_faiss_index(new_triplets)\n",
    "\n",
    "    def update_faiss_index(self, triplets):\n",
    "        texts = [f\"{t['subject']} {t['predicate']} {t['object']}\" for t in triplets]\n",
    "        embeddings = self.model.encode(texts)\n",
    "        if self.index is None:\n",
    "            self.index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "        self.index.add(np.array(embeddings, dtype=np.float32))\n",
    "        self.knowledge_data.extend(triplets)\n",
    "        self.save_faiss_index()\n",
    "\n",
    "    def save_faiss_index(self):\n",
    "        with open(self.faiss_index_file, 'wb') as f:\n",
    "            pickle.dump((self.index, self.knowledge_data), f)\n",
    "\n",
    "    def load_faiss_index(self):\n",
    "        if os.path.exists(self.faiss_index_file):\n",
    "            with open(self.faiss_index_file, 'rb') as f:\n",
    "                self.index, self.knowledge_data = pickle.load(f)\n",
    "        else:\n",
    "            self.index = None\n",
    "            self.knowledge_data = []\n",
    "\n",
    "    def search_knowledge(self, query, top_k=5):\n",
    "        if self.index is None or len(self.knowledge_data) == 0:\n",
    "            return []\n",
    "        query_embedding = self.model.encode([query])\n",
    "        distances, indices = self.index.search(np.array(query_embedding, dtype=np.float32), top_k)\n",
    "        results = []\n",
    "        for idx in indices[0]:\n",
    "            if idx == -1:\n",
    "                continue\n",
    "            results.append(self.knowledge_data[idx])\n",
    "        return results\n",
    "\n",
    "    # this function generates a response based on the conversation history and user message and the knowledge top k 5 matches\n",
    "    def generate_response(self, conversation_history, user_message):\n",
    "        knowledge_matches = self.search_knowledge(user_message, top_k=5)\n",
    "        current_time = datetime.utcnow().isoformat()\n",
    "        system_message = f\"Current date and time: {current_time}\\n\"\n",
    "        if knowledge_matches:\n",
    "            system_message += \"Answer based on retrieved knowledge:\\n\"\n",
    "            for t in knowledge_matches:\n",
    "                system_message += f\"- {t['subject']} {t['predicate']} {t['object']} (Videotimestamps: start: {t['start']}, end: {t['end']})\\n\"\n",
    "            \n",
    "        else:\n",
    "            system_message += \"No direct related knowledge found. Proceeding with general reasoning.\\n\"\n",
    "        enriched_history = [{\"role\": \"system\", \"content\": f\"You are a helpful assistent; {system_message}\"}] #+ conversation_history\n",
    "        enriched_history.append({\"role\": \"user\", \"content\": user_message})\n",
    "        print(enriched_history)\n",
    "        response = self.llm.create_chat_completion(\n",
    "            messages=enriched_history,\n",
    "            temperature=0.7,\n",
    "        )['choices'][0]['message']['content']\n",
    "        return response\n",
    "\n",
    "    def chat(self):\n",
    "        print(\"Chatbot is ready! Type 'exit' to end the conversation.\")\n",
    "        while True:\n",
    "            user_message = input(\"You: \")\n",
    "            if user_message.lower().strip() in ['exit', 'quit']:\n",
    "                print(\"Chatbot: Goodbye!\")\n",
    "                break\n",
    "            self.save_message(role='user', content=user_message)\n",
    "            conversation = self.load_json_data(self.messages_file)[-3:]\n",
    "            assistant_response = self.generate_response(conversation, user_message)\n",
    "            print(f\"Assistant: {assistant_response}\")\n",
    "            self.save_message(role='assistant', content=assistant_response)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    chatbot = Chatbot()\n",
    "    chatbot.chat()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Cake_4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
