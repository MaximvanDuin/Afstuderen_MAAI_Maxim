{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4cbc735",
   "metadata": {},
   "source": [
    "# CAKE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fe478d",
   "metadata": {},
   "source": [
    "## Audio bestand maken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab160c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47ccae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96be92e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mp4_to_wav(input_mp4_path, output_wav_path):\n",
    "    print(f\"Converting '{input_mp4_path}' to WAV format...\")\n",
    "    audio = AudioSegment.from_file(input_mp4_path, format=\"mp4\")\n",
    "    audio.export(output_wav_path, format=\"wav\")\n",
    "    print(f\"Conversion complete! WAV file saved to: {output_wav_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c36577",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = r\"C:\\Users\\maxim\\OneDrive\\01-Opleidingen\\03-MAAI\\Afstuderen\\Data\\Video's\\machine cover.mp4\"\n",
    "aud = r\"C:\\Users\\maxim\\OneDrive\\01-Opleidingen\\03-MAAI\\Afstuderen\\Cake\\Data_machine_cover_2\\machine_cover_2.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71613363",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_mp4_to_wav(vid, aud)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14d7bc5",
   "metadata": {},
   "source": [
    "## Transcribe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbc56d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisperx\n",
    "import gc\n",
    "import torch\n",
    "import json\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f3b654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "wav_folder = r\"C:\\Users\\maxim\\OneDrive\\01-Opleidingen\\03-MAAI\\Afstuderen\\Cake\\Data_machine_cover_2\"\n",
    "output_folder = \"transcriptions_machine_cover_2\"\n",
    "unsupported_folder = \"unsupported_language_machine_cover_2\"\n",
    "model_dir = \"whisper-models\"\n",
    "vad_model_path = r\"C:\\Users\\maxim\\OneDrive\\01-Opleidingen\\03-MAAI\\Afstuderen\\Cake\\CAKE\\VAD\\pytorch_model.bin\"\n",
    "audio_path = r\"C:\\Users\\maxim\\OneDrive\\01-Opleidingen\\03-MAAI\\Afstuderen\\Cake\\Data_machine_cover_2\\machine_cover_2.wav\"\n",
    "\n",
    "# Ensure output folders exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "os.makedirs(unsupported_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1ea35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe(audio_file):\n",
    "    # # Check system for compatibility\n",
    "    # if torch.cuda.is_available():\n",
    "    #     device = \"cuda\"\n",
    "    #     print(\"CUDA wordt gebruikt\")\n",
    "    #     compute_type = \"float16\"  # change to \"int8\" if low on GPU mem (may reduce accuracy)\n",
    "    #     batch_size = 16  # reduce if low on GPU mem\n",
    "    # elif torch.backends.mps.is_available():\n",
    "    #     device = \"cpu\"\n",
    "    #     print(\"MPS (Apple Silicon) gebruikt\")\n",
    "    #     compute_type = \"int8\"\n",
    "    #     batch_size = 8\n",
    "    # else:\n",
    "    #     print(\"CPU gebruikt\")\n",
    "    #     device = \"cpu\"\n",
    "    #     compute_type = \"int8\"\n",
    "    #     batch_size = 4\n",
    "    \n",
    "    print(\"CPU gebruikt\")\n",
    "    device = \"cpu\"\n",
    "    compute_type = \"float32\"\n",
    "    batch_size = 4\n",
    "\n",
    "    if not os.path.exists(model_dir):\n",
    "        model = whisperx.load_model(\"large-v2\", device, compute_type=compute_type, download_root=model_dir)\n",
    "    else:\n",
    "        model = whisperx.load_model(\"./whisper-models/models--Systran--faster-whisper-large-v2/snapshots/f0fe81560cb8b68660e564f55dd99207059c092e\", device, compute_type=compute_type, vad_model_fp=vad_model_path)\n",
    "\n",
    "    audio = whisperx.load_audio(audio_file)\n",
    "\n",
    "    # Perform transcription with automatic language detection\n",
    "    result = model.transcribe(audio, batch_size=batch_size)\n",
    "    detected_language = result.get(\"language\", \"en\")\n",
    "\n",
    "    # Check if detected language is supported, otherwise move file to unsupported folder\n",
    "    if detected_language not in [\"en\", \"fr\", \"de\", \"es\", \"nl\"]:\n",
    "        print(f\"Language detected as {detected_language}, moving to unsupported folder.\")\n",
    "        os.rename(audio_file, os.path.join(unsupported_folder, os.path.basename(audio_file)))\n",
    "        return\n",
    "\n",
    "    print(f\"Detected language: {detected_language}\")\n",
    "\n",
    "   \n",
    "    try:\n",
    "        model_a, metadata = whisperx.load_align_model(language_code=detected_language, device=device)\n",
    "        result = whisperx.align(result[\"segments\"], model_a, metadata, audio, device, return_char_alignments=False)\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        del model_a\n",
    "    except ValueError as e:\n",
    "        print(f\"Skipping alignment due to error: {e}\")\n",
    "\n",
    "    # Save as JSON\n",
    "    base_filename = os.path.splitext(os.path.basename(audio_file))[0]\n",
    "    output_json_path = os.path.join(output_folder, f\"{base_filename}.json\")\n",
    "    with open(output_json_path, 'w') as f:\n",
    "        json.dump(result, f, indent=2)\n",
    "\n",
    "    print(f\"Results saved to {output_json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2777f356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all WAV files in the folder\n",
    "for filename in os.listdir(wav_folder):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        audio_path = os.path.join(wav_folder, filename)\n",
    "        transcribe(audio_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0c9a07",
   "metadata": {},
   "source": [
    "## Full text of transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b8bc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Input directory containing JSON files\n",
    "json_folder = 'transcriptions_machine_cover_2'\n",
    "output_dir = 'individual_texts_machine_cover_2'\n",
    "\n",
    "# Maak output directory aan als deze niet bestaat\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(f\"Output directory '{output_dir}' is ready.\")\n",
    "\n",
    "# Process each JSON file individually\n",
    "for json_file in os.listdir(json_folder):\n",
    "    if json_file.endswith('.json'):\n",
    "        json_path = os.path.join(json_folder, json_file)\n",
    "        print(f\"Processing file: {json_file}\")\n",
    "\n",
    "        # Controleer of het JSON-bestand geldig is\n",
    "        try:\n",
    "            with open(json_path, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "        except (json.JSONDecodeError, FileNotFoundError) as e:\n",
    "            print(f\"Error: Failed to process '{json_file}'. Details: {e}\")\n",
    "            continue\n",
    "\n",
    "        segments = data.get('segments', [])\n",
    "        if not segments:\n",
    "            print(f\"Warning: No segments found in '{json_file}'.\")\n",
    "            continue\n",
    "\n",
    "        # Create output text file for the individual transcript\n",
    "        individual_output_path = os.path.join(output_dir, json_file.replace('.json', '.txt'))\n",
    "\n",
    "        with open(individual_output_path, 'w', encoding='utf-8') as individual_file:\n",
    "            for i, segment in enumerate(segments, start=1):\n",
    "                text = segment.get('text', '').strip()\n",
    "                if not text:\n",
    "                    print(f\"Warning: Segment {i} in '{json_file}' is empty.\")\n",
    "                    continue\n",
    "                individual_file.write(f\"{text} \")\n",
    "\n",
    "        print(f\"Transcript saved to '{individual_output_path}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94eeb94",
   "metadata": {},
   "source": [
    "## Output chonkie chunks with timestamp (in json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3f5861",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from chonkie import SDPMChunker\n",
    "\n",
    "def load_document(file_path: str) -> str:\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"The file '{file_path}' does not exist.\")\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "    return content\n",
    "\n",
    "def load_json(file_path: str) -> dict:\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"Error: The JSON file '{file_path}' does not exist.\")\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        try:\n",
    "            return json.load(f)\n",
    "        except json.JSONDecodeError as e:\n",
    "            raise ValueError(f\"Error: Failed to decode JSON file. Details: {e}\")\n",
    "\n",
    "def create_chunker(embedding_model=\"minishlab/potion-base-8M\", chunk_size=512, min_sentences=1):\n",
    "\n",
    "    return SDPMChunker(\n",
    "        embedding_model=embedding_model,\n",
    "        chunk_size=chunk_size,\n",
    "        min_sentences=min_sentences\n",
    "    )\n",
    "\n",
    "# def process_text_and_json(text_folder: str, json_folder: str, output_folder: str):\n",
    "\n",
    "#     if not os.path.exists(output_folder):\n",
    "#         os.makedirs(output_folder)\n",
    "\n",
    "#     for text_file in os.listdir(text_folder):\n",
    "#         if text_file.endswith(\".txt\"):\n",
    "#             base_name = os.path.splitext(text_file)[0]\n",
    "#             text_path = os.path.join(text_folder, text_file)\n",
    "#             json_path = os.path.join(json_folder, base_name + \".json\")\n",
    "\n",
    "#             if not os.path.exists(json_path):\n",
    "#                 print(f\"Warning: No matching JSON file for {text_file}\")\n",
    "#                 continue\n",
    "\n",
    "#             text_content = load_document(text_path)\n",
    "#             json_data = load_json(json_path)\n",
    "#             segments = json_data.get('word_segments', [])\n",
    "\n",
    "#             if not segments:\n",
    "#                 raise ValueError(f\"Error: No segments found in the JSON file {json_path}.\")\n",
    "\n",
    "#             word_list = [[seg.get('word', '').strip(), seg.get('start', ''), seg.get('end', '')] for seg in segments if seg.get('word', '').strip()]\n",
    "#             chunker = create_chunker()\n",
    "#             chunks = chunker.chunk(text_content)\n",
    "\n",
    "#             final_chunks = []\n",
    "#             current_word_index = 0\n",
    "#             for chunk in chunks:\n",
    "#                 chunk_text = chunk.text\n",
    "#                 chunk_words = chunk_text.split()\n",
    "#                 chunk_word_data = []\n",
    "#                 chunk_start = None\n",
    "#                 chunk_end = None\n",
    "\n",
    "#                 for chunk_word in chunk_words:\n",
    "#                     if current_word_index < len(word_list):\n",
    "#                         word_info = word_list[current_word_index]\n",
    "#                         if chunk_word == word_info[0]:\n",
    "#                             chunk_word_data.append({\n",
    "#                                 \"word\": word_info[0],\n",
    "#                                 \"start\": word_info[1],\n",
    "#                                 \"end\": word_info[2]\n",
    "#                             })\n",
    "#                             if chunk_start is None:\n",
    "#                                 chunk_start = word_info[1]\n",
    "#                             chunk_end = word_info[2]\n",
    "#                             current_word_index += 1\n",
    "#                         else:\n",
    "#                             raise ValueError(f\"Word mismatch at chunk '{chunk_text}': Expected '{word_info[0]}', found '{chunk_word}'.\")\n",
    "#                     else:\n",
    "#                         raise IndexError(\"Ran out of words in word_data to match with chunks.\")\n",
    "\n",
    "#                 final_chunks.append({\n",
    "#                     \"text\": chunk_text,\n",
    "#                     \"start\": chunk_start,\n",
    "#                     \"end\": chunk_end,\n",
    "#                     \"words\": chunk_word_data\n",
    "#                 })\n",
    "\n",
    "#             output_json_path = os.path.join(output_folder, base_name + \"_chunks.json\")\n",
    "#             with open(output_json_path, 'w', encoding='utf-8') as f:\n",
    "#                 json.dump({\"chunks\": final_chunks}, f, ensure_ascii=False, indent=4)\n",
    "#                 print(f\"Processed {text_file} and saved to {output_json_path}\")\n",
    "\n",
    "def is_valid_time(value):\n",
    "    try:\n",
    "        return value not in (None, '', ' ') and float(value) >= 0\n",
    "    except (ValueError, TypeError):\n",
    "        return False\n",
    "\n",
    "def process_text_and_json(text_folder: str, json_folder: str, output_folder: str):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for text_file in os.listdir(text_folder):\n",
    "        if text_file.endswith(\".txt\"):\n",
    "            base_name = os.path.splitext(text_file)[0]\n",
    "            text_path = os.path.join(text_folder, text_file)\n",
    "            json_path = os.path.join(json_folder, base_name + \".json\")\n",
    "\n",
    "            if not os.path.exists(json_path):\n",
    "                print(f\"Warning: No matching JSON file for {text_file}\")\n",
    "                continue\n",
    "\n",
    "            text_content = load_document(text_path)\n",
    "            json_data = load_json(json_path)\n",
    "            segments = json_data.get('word_segments', [])\n",
    "\n",
    "            if not segments:\n",
    "                raise ValueError(f\"Error: No segments found in the JSON file {json_path}.\")\n",
    "\n",
    "            word_list = [\n",
    "                [seg.get('word', '').strip(), seg.get('start'), seg.get('end')]\n",
    "                for seg in segments\n",
    "                if seg.get('word', '').strip()\n",
    "                and is_valid_time(seg.get('start'))\n",
    "                and is_valid_time(seg.get('end'))\n",
    "            ]\n",
    "\n",
    "            total_segments = len(segments)\n",
    "            valid_segments = len(word_list)\n",
    "            skipped_segments = total_segments - valid_segments\n",
    "            if skipped_segments > 0:\n",
    "                print(f\"Waarschuwing: {skipped_segments} ongeldige segmenten overgeslagen in {json_path}\")\n",
    "\n",
    "            chunker = create_chunker()\n",
    "            chunks = chunker.chunk(text_content)\n",
    "\n",
    "            final_chunks = []\n",
    "            current_word_index = 0\n",
    "            total_words = len(word_list)\n",
    "\n",
    "            for chunk in chunks:\n",
    "                chunk_text = chunk.text.strip()\n",
    "                approx_num_words = len(chunk_text.split())\n",
    "\n",
    "                chunk_word_data = []\n",
    "                chunk_start = None\n",
    "                chunk_end = None\n",
    "\n",
    "                for _ in range(approx_num_words):\n",
    "                    if current_word_index >= total_words:\n",
    "                        break\n",
    "                    word_info = word_list[current_word_index]\n",
    "                    chunk_word_data.append({\n",
    "                        \"word\": word_info[0],\n",
    "                        \"start\": word_info[1],\n",
    "                        \"end\": word_info[2]\n",
    "                    })\n",
    "                    if chunk_start is None:\n",
    "                        chunk_start = word_info[1]\n",
    "                    chunk_end = word_info[2]\n",
    "                    current_word_index += 1\n",
    "\n",
    "                final_chunks.append({\n",
    "                    \"text\": chunk_text,\n",
    "                    \"start\": chunk_start,\n",
    "                    \"end\": chunk_end,\n",
    "                    \"words\": chunk_word_data\n",
    "                })\n",
    "\n",
    "            output_json_path = os.path.join(output_folder, base_name + \"_chunks.json\")\n",
    "            with open(output_json_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump({\"chunks\": final_chunks}, f, ensure_ascii=False, indent=4)\n",
    "                print(f\"Processed {text_file} and saved to {output_json_path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    text_folder = 'individual_texts_machine_cover_2'\n",
    "    json_folder = 'transcriptions_machine_cover_2'\n",
    "    output_folder = 'processed_json_machine_cover_2'\n",
    "    process_text_and_json(text_folder, json_folder, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba9908b",
   "metadata": {},
   "source": [
    "## Video segmentation chonkie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5fb18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "def create_segments(video_file, result):\n",
    "\n",
    "    if not os.path.exists(result):\n",
    "        raise FileNotFoundError(f\"Error: The result file '{result}' does not exist.\")\n",
    "\n",
    "    with open(result, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    segments = data.get('chunks', [])\n",
    "    if not segments:\n",
    "        raise ValueError(\"No segments found in the JSON file.\")\n",
    "\n",
    "    video_name = os.path.splitext(os.path.basename(video_file))[0]\n",
    "    output_dir = os.path.join('video_segments_machine_cover_2', video_name)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"Output directory '{output_dir}' is ready.\")\n",
    "\n",
    "    for i, segment in enumerate(segments, start=1):\n",
    "        start = segment['start']\n",
    "        end = segment['end']\n",
    "        output_filename = f\"segment_{i}_{int(start)}_{int(end)}.mp4\"\n",
    "        output_path = os.path.join(output_dir, output_filename)\n",
    "\n",
    "        command = [\n",
    "            \"ffmpeg\",\n",
    "            \"-y\",\n",
    "            \"-i\", video_file,\n",
    "            \"-ss\", str(start),\n",
    "            \"-to\", str(end),\n",
    "            \"-c:v\", \"libx264\",\n",
    "            \"-c:a\", \"aac\",\n",
    "            output_path\n",
    "        ]\n",
    "        print(f\"Creating segment {i}: {start} to {end} seconds for {video_file}.\")\n",
    "        subprocess.run(command, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "        print(f\"Segment {i} saved as '{output_filename}'.\")\n",
    "\n",
    "    print(f\"All segments for {video_file} have been processed.\")\n",
    "\n",
    "def process_videos_in_directory(video_directory, json_directory):\n",
    "\n",
    "    if not os.path.isdir(video_directory):\n",
    "        raise NotADirectoryError(f\"Error: The directory '{video_directory}' does not exist.\")\n",
    "    if not os.path.isdir(json_directory):\n",
    "        raise NotADirectoryError(f\"Error: The directory '{json_directory}' does not exist.\")\n",
    "\n",
    "    video_files = sorted(f for f in os.listdir(video_directory) if f.endswith('.mp4'))\n",
    "    json_files = sorted(f for f in os.listdir(json_directory) if f.endswith('.json'))\n",
    "\n",
    "    for video_file, json_file in zip(video_files, json_files):\n",
    "        video_path = os.path.join(video_directory, video_file)\n",
    "        json_path = os.path.join(json_directory, json_file)\n",
    "        create_segments(video_path, json_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    video_directory = r\"C:\\Users\\maxim\\OneDrive\\01-Opleidingen\\03-MAAI\\Afstuderen\\Cake\\Video_machine_cover_2\"  # Replace with your video directory\n",
    "    json_directory = \"processed_json_machine_cover_2\"  # Replace with your JSON directory\n",
    "    process_videos_in_directory(video_directory, json_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f7f2dd",
   "metadata": {},
   "source": [
    "## Frame Extraction\n",
    "### 1 frame per 3 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dece0dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def extract_frames(video_path, output_dir, interval_seconds=3):\n",
    "    video_name = os.path.basename(video_path).replace(\".\", \"_\")\n",
    "    segment_output_dir = os.path.join(output_dir, *video_path.split(os.sep)[-2:])\n",
    "    os.makedirs(segment_output_dir, exist_ok=True)\n",
    "\n",
    "    vidcap = cv2.VideoCapture(video_path)\n",
    "    fps = vidcap.get(cv2.CAP_PROP_FPS)\n",
    "    if fps <= 0:\n",
    "        print(f\"Kan de FPS voor {video_path} niet ophalen.\")\n",
    "        return\n",
    "\n",
    "    frame_interval = int(fps * interval_seconds)\n",
    "    success, image = vidcap.read()\n",
    "    count = 0\n",
    "    frame_count = 0\n",
    "\n",
    "    while success:\n",
    "        if frame_count % frame_interval == 0:\n",
    "            frame_path = os.path.join(segment_output_dir, f\"{video_name}_frame_{count}.jpg\")\n",
    "            cv2.imwrite(frame_path, image)\n",
    "            count += 1\n",
    "        success, image = vidcap.read()\n",
    "        frame_count += 1\n",
    "\n",
    "    vidcap.release()\n",
    "    print(f\"Geëxtraheerd {count} frames uit {video_path} naar {segment_output_dir}\")\n",
    "\n",
    "def process_videos_in_directory(base_directory, output_directory, interval_seconds=3):\n",
    "    if not os.path.isdir(base_directory):\n",
    "        raise NotADirectoryError(f\"Error: De map '{base_directory}' bestaat niet.\")\n",
    "\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    print(f\"Output directory '{output_directory}' is gereed.\")\n",
    "\n",
    "    for subdir in sorted(os.listdir(base_directory)):\n",
    "        subdir_path = os.path.join(base_directory, subdir)\n",
    "        if os.path.isdir(subdir_path):\n",
    "            for filename in sorted(os.listdir(subdir_path)):\n",
    "                if filename.lower().endswith(('.mp4', '.avi', '.mov', '.mkv')):\n",
    "                    video_path = os.path.join(subdir_path, filename)\n",
    "                    extract_frames(video_path, output_directory, interval_seconds)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    video_directory = \"video_segments_machine_cover_2\"  # Vervang dit door jouw basisvideo-segmentenmap\n",
    "    output_directory = \"frames_machine_cover_2\"         # Map om geëxtraheerde frames op te slaan\n",
    "    process_videos_in_directory(video_directory, output_directory, interval_seconds=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7648e9f1",
   "metadata": {},
   "source": [
    "## Object segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d1caea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple\n",
    "from PIL import Image\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator\n",
    "\n",
    "@dataclass\n",
    "class BoxPrompt:\n",
    "    x1: float\n",
    "    y1: float\n",
    "    x2: float\n",
    "    y2: float\n",
    "\n",
    "class AdvancedAutoSAM:\n",
    "    def __init__(self, model_type=\"vit_l\", model_path=\"./models/sam_vit_l_0b3195.pth\"):\n",
    "        self.model_type = model_type\n",
    "        self.model_path = model_path\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self._load_model()\n",
    "\n",
    "    def _load_model(self):\n",
    "        print(f\"Loading SAM model: {self.model_type}...\")\n",
    "        self.sam = sam_model_registry[self.model_type](checkpoint=self.model_path)\n",
    "        self.sam.to(self.device)\n",
    "        self.mask_generator = SamAutomaticMaskGenerator(self.sam)\n",
    "        print(\"SAM model loaded.\")\n",
    "\n",
    "    def auto_generate_masks(self, image_path: str) -> List[np.ndarray]:\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            raise ValueError(f\"Failed to load {image_path}\")\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        masks = self.mask_generator.generate(image_rgb)\n",
    "        binary_masks = [m['segmentation'].astype(np.uint8) * 255 for m in masks]\n",
    "        print(f\"Generated {len(binary_masks)} masks.\")\n",
    "        return binary_masks\n",
    "\n",
    "    def save_masks_as_color_overlay(self, masks: List[np.ndarray], image_path: str, output_path: str):\n",
    "        image_bgr = cv2.imread(image_path)\n",
    "        overlay = image_bgr.copy()\n",
    "        for mask in masks:\n",
    "            color = np.random.randint(0, 255, size=3, dtype=np.uint8)\n",
    "            mask_indices = mask > 0\n",
    "            overlay[mask_indices] = (0.5 * overlay[mask_indices] + 0.5 * color).astype(np.uint8)\n",
    "        cv2.imwrite(output_path, overlay)\n",
    "        print(f\"Overlay saved to {output_path}\")\n",
    "\n",
    "    def save_masks_individually(self, masks: List[np.ndarray], output_folder: str, base_name: str = \"mask\"):\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        for idx, mask in enumerate(masks, 1):\n",
    "            path = os.path.join(output_folder, f\"{base_name}_{idx}.png\")\n",
    "            cv2.imwrite(path, mask)\n",
    "            print(f\"Saved mask to {path}\")\n",
    "\n",
    "    def save_segments_individually(self, masks: List[np.ndarray], image_path: str, output_folder: str, base_name: str = \"segment\"):\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        image = cv2.imread(image_path)\n",
    "        for idx, mask in enumerate(masks, 1):\n",
    "            segment = cv2.bitwise_and(image, image, mask=mask)\n",
    "            path = os.path.join(output_folder, f\"{base_name}_{idx}.png\")\n",
    "            cv2.imwrite(path, segment)\n",
    "            print(f\"Saved segment to {path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3e29d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    auto_sam = AdvancedAutoSAM()\n",
    "\n",
    "    input_dir = \"frames_machine_cover_2/machine_cover_2/\"\n",
    "    output_dir = \"generated_results_machine_cover_2\"\n",
    "    overlay_dir = os.path.join(output_dir, \"overlays\")\n",
    "    masks_dir = os.path.join(output_dir, \"masks\")\n",
    "    segments_dir = os.path.join(output_dir, \"segments\")\n",
    "\n",
    "    os.makedirs(overlay_dir, exist_ok=True)\n",
    "    os.makedirs(masks_dir, exist_ok=True)\n",
    "    os.makedirs(segments_dir, exist_ok=True)\n",
    "\n",
    "    supported_extensions = ('.jpg', '.jpeg', '.png', '.bmp')\n",
    "\n",
    "    for root, _, files in os.walk(input_dir):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(supported_extensions):\n",
    "                image_path = os.path.join(root, file)\n",
    "                base_name = os.path.splitext(file)[0]\n",
    "\n",
    "                print(f\"\\nProcessing {image_path}...\")\n",
    "                try:\n",
    "                    masks = auto_sam.auto_generate_masks(image_path)\n",
    "                    if not masks:\n",
    "                        continue\n",
    "                    auto_sam.save_masks_as_color_overlay(\n",
    "                        masks, image_path,\n",
    "                        os.path.join(overlay_dir, f\"{base_name}_overlay.png\")\n",
    "                    )\n",
    "                    auto_sam.save_masks_individually(\n",
    "                        masks,\n",
    "                        os.path.join(masks_dir, f\"{base_name}_masks\")\n",
    "                    )\n",
    "                    auto_sam.save_segments_individually(\n",
    "                        masks,\n",
    "                        image_path,\n",
    "                        os.path.join(segments_dir, f\"{base_name}_segments\")\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {file}: {e}\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"SAM is uitgeschakeld. Lege segment-map wordt aangemaakt...\")\n",
    "    os.makedirs(\"generated_results_machine_cover_2/segments\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce28c865",
   "metadata": {},
   "source": [
    "## Image captioning on the frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de38b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "from transformers import VisionEncoderDecoderModel, ViTImageProcessor, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "\n",
    "# Pad naar de hoofd directory met geëxtraheerde frames (alle video segmenten)\n",
    "frames_dir = \"frames_machine_cover_2/machine_cover_2/\"  # Pas dit aan naar jouw frames hoofd directory\n",
    "\n",
    "# Output JSON bestand\n",
    "output_json_path = \"combined_frames_machine_cover_2.json\"\n",
    "\n",
    "\n",
    "def initialize_captioning_model():\n",
    "\n",
    "    print(\"Initialiseren van het image captioning model...\")\n",
    "    model = VisionEncoderDecoderModel.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "    feature_extractor = ViTImageProcessor.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "    print(\"Model geïnitieerd.\")\n",
    "    return model, feature_extractor, tokenizer\n",
    "\n",
    "\n",
    "def generate_caption(image_path, model, feature_extractor, tokenizer, device):\n",
    "\n",
    "    try:\n",
    "        # print(f\"Generating caption for: {image_path}\")  # Optioneel: Kan veel output genereren\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        pixel_values = feature_extractor(images=image, return_tensors=\"pt\").pixel_values.to(device)\n",
    "\n",
    "        output_ids = model.generate(pixel_values, max_length=16, num_beams=4)\n",
    "        caption = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "        return caption\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating caption for {image_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def process_all_frames(frames_dir, model, feature_extractor, tokenizer, device):\n",
    "    combined_data = []\n",
    "    supported_extensions = ('.png', '.jpg', '.jpeg', '.bmp', '.tiff')\n",
    "\n",
    "    if not os.path.isdir(frames_dir):\n",
    "        print(f\"Error: Frames directory {frames_dir} bestaat niet.\")\n",
    "        return combined_data\n",
    "\n",
    "    # Itereer over alle subdirectories (video segmenten)\n",
    "    video_segments = [d for d in os.listdir(frames_dir) if os.path.isdir(os.path.join(frames_dir, d))]\n",
    "    total_segments = len(video_segments)\n",
    "    print(f\"Found {total_segments} video segments in '{frames_dir}'.\")\n",
    "\n",
    "    for seg_idx, segment in enumerate(sorted(video_segments), start=1):\n",
    "        segment_path = os.path.join(frames_dir, segment)\n",
    "        frame_files = [f for f in os.listdir(segment_path) if f.lower().endswith(supported_extensions)]\n",
    "\n",
    "        if not frame_files:\n",
    "            print(f\"error: Geen frames gevonden in segment '{segment}'.\")\n",
    "            continue\n",
    "\n",
    "        total_frames = len(frame_files)\n",
    "        print(f\"Processing segment {seg_idx}/{total_segments}: '{segment}' with {total_frames} frames.\")\n",
    "\n",
    "        for idx, frame_file in enumerate(sorted(frame_files), start=1):\n",
    "            frame_path = os.path.join(segment_path, frame_file)\n",
    "\n",
    "            # Genereer een caption voor het frame\n",
    "            caption = generate_caption(frame_path, model, feature_extractor, tokenizer, device)\n",
    "            # print(f\"Generated caption for {frame_file}: {caption}\")  # Optioneel: kan veel output genereren\n",
    "\n",
    "            # Voeg de gecombineerde data toe aan de lijst\n",
    "            combined_data.append({\n",
    "                \"video_segment\": segment,  # Naam van het video segment\n",
    "                \"frame_number\": idx - 1,  # Frames starten meestal bij 0\n",
    "                \"frame_filename\": frame_file,\n",
    "                \"caption\": caption\n",
    "            })\n",
    "\n",
    "            if idx % 100 == 0 or idx == total_frames:\n",
    "                print(f\"Segment '{segment}': Processed {idx}/{total_frames} frames.\")\n",
    "\n",
    "    return combined_data\n",
    "\n",
    "\n",
    "def save_combined_data(combined_data, output_json_path):\n",
    "\n",
    "    try:\n",
    "        with open(output_json_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(combined_data, f, indent=4)\n",
    "        print(f\"Combined JSON saved to '{output_json_path}'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving JSON file: {e}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Initialiseer het captioning model\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"Using device: {device}\")\n",
    "    model, feature_extractor, tokenizer = initialize_captioning_model()\n",
    "    model.to(device)\n",
    "\n",
    "    # Genereer captions voor alle frames\n",
    "    combined_data = process_all_frames(\n",
    "        frames_dir=frames_dir,\n",
    "        model=model,\n",
    "        feature_extractor=feature_extractor,\n",
    "        tokenizer=tokenizer,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    if not combined_data:\n",
    "        print(\"Geen gecombineerde data om op te slaan.\")\n",
    "        return\n",
    "\n",
    "    # Sla de gecombineerde data op als JSON\n",
    "    save_combined_data(combined_data, output_json_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "# if __name__ == \"__main__\":\n",
    "#     print(\"Captioning is uitgeschakeld. Leeg combined_frames.json wordt aangemaakt...\")\n",
    "#     empty_json = []\n",
    "#     with open(\"combined_frames_machine_cover_2.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "#         json.dump(empty_json, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516d3d94",
   "metadata": {},
   "source": [
    "## Connect segments and captions to chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d48c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "import re\n",
    "\n",
    "def load_json(file_path: str) -> Any:\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def save_json(data: Any, file_path: str):\n",
    "  \n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "    print(f\"JSON opgeslagen als '{file_path}'.\")\n",
    "\n",
    "def parse_segment_filename(filename: str) -> Dict[str, Any]:\n",
    "    pattern = r\"segment_(\\d+)_(\\d+)_(\\d+)\\.mp4\"\n",
    "    match = re.match(pattern, filename)\n",
    "    if match:\n",
    "        return {\n",
    "            \"index\": int(match.group(1)),\n",
    "            \"start\": float(match.group(2)),\n",
    "            \"end\": float(match.group(3))\n",
    "        }\n",
    "    else:\n",
    "        return {}\n",
    "\n",
    "def find_video_segments(chunks: List[Dict[str, Any]], video_segments_dir: str) -> Dict[tuple, str]:\n",
    " \n",
    "    video_segments = os.listdir(video_segments_dir)\n",
    "    segment_map = {}\n",
    "    for segment_file in video_segments:\n",
    "        parsed = parse_segment_filename(segment_file)\n",
    "        if not parsed:\n",
    "            print(f\" file '{segment_file}' not same as pattern\")\n",
    "            continue\n",
    "        key = (parsed['start'], parsed['end'])\n",
    "        segment_map[key] = os.path.join(video_segments_dir, segment_file)\n",
    "    return segment_map\n",
    "\n",
    "def find_frames_for_segment(frames_dir: str, segment_filename: str) -> List[str]:\n",
    "\n",
    "    segment_frame_dir = os.path.join(frames_dir, segment_filename)\n",
    "    if not os.path.isdir(segment_frame_dir):\n",
    "        print(f\"error: Frames directory '{segment_frame_dir}' not exist.\")\n",
    "        return []\n",
    "    frames = [os.path.join(segment_frame_dir, f) for f in os.listdir(segment_frame_dir) \n",
    "              if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff'))]\n",
    "    return sorted(frames)  # Sorteer frames op naam\n",
    "\n",
    "def find_object_segments_for_frame(generated_segments_dir: str, segment_filename: str, frame_filename: str) -> List[str]:\n",
    "    # Voorbeeld pad:\n",
    "    # generated_segments/segment_1_0_32.mp4/segment_1_0_32_mp4_frame_000003_segments/segment_1.png\n",
    "    frame_basename = os.path.splitext(os.path.basename(frame_filename))[0]  # segment_1_0_32_mp4_frame_000003\n",
    "    segments_folder = os.path.join(generated_segments_dir, f\"{frame_basename}_segments\")\n",
    "    if not os.path.isdir(segments_folder):\n",
    "        print(f\"Waarschuwing: Object segments directory '{segments_folder}' bestaat niet.\")\n",
    "        return []\n",
    "    object_segments = [os.path.join(segments_folder, f) for f in os.listdir(segments_folder) \n",
    "                       if f.lower().endswith('.png')]\n",
    "    return sorted(object_segments)  # Sorteer object segmenten op naam\n",
    "\n",
    "def load_captions(captions_json_path: str) -> Dict[str, str]:\n",
    "    captions_data = load_json(captions_json_path)\n",
    "    caption_map = {}\n",
    "    for entry in captions_data:\n",
    "        video_segment = entry.get('video_segment')\n",
    "        frame_filename = entry.get('frame_filename')\n",
    "        caption = entry.get('caption', \"\")\n",
    "        if video_segment and frame_filename:\n",
    "            key = f\"{video_segment}/{frame_filename}\"\n",
    "            caption_map[key] = caption\n",
    "    print(f\"Loaded captions for {len(caption_map)} frames.\")\n",
    "    return caption_map\n",
    "\n",
    "def update_chunks_with_segments_and_captions(original_chunks: List[Dict[str, Any]], \n",
    "                                segment_map: Dict[tuple, str],\n",
    "                                frames_dir: str,\n",
    "                                generated_segments_dir: str,\n",
    "                                captions_map: Dict[str, str]) -> List[Dict[str, Any]]:\n",
    "\n",
    "    updated_chunks = []\n",
    "    for chunk in original_chunks:\n",
    "        chunk_start = chunk['start']\n",
    "        chunk_end = chunk['end']\n",
    "        key = (int(chunk_start), int(chunk_end))\n",
    "        video_segment_path = segment_map.get(key)\n",
    "        if not video_segment_path:\n",
    "            print(f\"error: no video segment found for chunk start {chunk_start} and end {chunk_end}.\")\n",
    "            continue  # Of handle anders, afhankelijk van behoeften\n",
    "        \n",
    "        segment_filename = os.path.basename(video_segment_path)\n",
    "        frames = find_frames_for_segment(frames_dir, segment_filename)\n",
    "        frames_info = []\n",
    "        for frame_path in frames:\n",
    "            frame_filename = os.path.basename(frame_path)\n",
    "            # object_segments = find_object_segments_for_frame(generated_segments_dir, segment_filename, frame_filename)\n",
    "            object_segments = []\n",
    "            if os.path.isdir(generated_segments_dir):\n",
    "                object_segments = find_object_segments_for_frame(generated_segments_dir, segment_filename, frame_filename)\n",
    "            # Koppel de caption op basis van video_segment en frame_filename\n",
    "            caption_key = f\"{segment_filename}/{frame_filename}\"\n",
    "            caption = captions_map.get(caption_key, \"\")\n",
    "            frames_info.append({\n",
    "                \"frame_path\": frame_path,\n",
    "                \"object_segments\": object_segments,\n",
    "                \"caption\": caption\n",
    "            })\n",
    "        \n",
    "        # Voeg video segment en frames info toe aan de chunk\n",
    "        updated_chunk = {\n",
    "            \"text\": chunk['text'],\n",
    "            \"start\": chunk['start'],\n",
    "            \"end\": chunk['end'],\n",
    "            \"video_segment\": video_segment_path,\n",
    "            \"frames\": frames_info,\n",
    "            \"words\": chunk.get('words', [])\n",
    "        }\n",
    "        updated_chunks.append(updated_chunk)\n",
    "    \n",
    "    return updated_chunks\n",
    "\n",
    "def main():\n",
    "    # Definieer paden\n",
    "    original_json_path = \"processed_json_machine_cover_2/machine_cover_2_chunks.json\"  # Originele JSON met chunks\n",
    "    video_segments_dir = \"video_segments_machine_cover_2/machine_cover_2\"  # Map met video segmenten\n",
    "    frames_dir = \"frames_machine_cover_2/machine_cover_2\"  # Hoofd map met frames per segment\n",
    "    generated_segments_dir = \"generated_results_machine_cover_2/segments\"  # Map met object segmenten\n",
    "    captions_json_path = \"combined_frames_machine_cover_2.json\"  # JSON met image captions\n",
    "    new_json_path = \"updated_chunks_with_segments_and_captions_machine_cover_2.json\"  # Nieuwe JSON output\n",
    "\n",
    "    # Controleer of alle benodigde bestanden en directories bestaan\n",
    "    if not os.path.exists(original_json_path):\n",
    "        print(f\"Error: Originele JSON bestand '{original_json_path}' bestaat niet.\")\n",
    "        return\n",
    "    if not os.path.isdir(video_segments_dir):\n",
    "        print(f\"Error: Video segments directory '{video_segments_dir}' bestaat niet.\")\n",
    "        return\n",
    "    if not os.path.isdir(frames_dir):\n",
    "        print(f\"Error: Frames directory '{frames_dir}' bestaat niet.\")\n",
    "        return\n",
    "    if not os.path.isdir(generated_segments_dir):\n",
    "        print(f\"Error: Generated segments directory '{generated_segments_dir}' bestaat niet.\")\n",
    "        return\n",
    "    if not os.path.exists(captions_json_path):\n",
    "        print(f\"Error: Captions JSON bestand '{captions_json_path}' bestaat niet.\")\n",
    "        return\n",
    "\n",
    "    # Laad originele JSON\n",
    "    original_data = load_json(original_json_path)\n",
    "    chunks = original_data.get('chunks', [])\n",
    "    if not chunks:\n",
    "        print(\"Geen chunks gevonden in de originele JSON.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Loaded {len(chunks)} chunks from '{original_json_path}'.\")\n",
    "\n",
    "    # Maak een mapping van (start, end) tijden naar video segment paden\n",
    "    segment_map = find_video_segments(chunks, video_segments_dir)\n",
    "    print(f\"Found {len(segment_map)} video segments.\")\n",
    "\n",
    "    # Laad captions en maak een mapping\n",
    "    captions_map = load_captions(captions_json_path)\n",
    "\n",
    "    # Update chunks met video segmenten, frames, object segmenten en captions\n",
    "    updated_chunks = update_chunks_with_segments_and_captions(\n",
    "        chunks, \n",
    "        segment_map, \n",
    "        frames_dir, \n",
    "        generated_segments_dir, \n",
    "        captions_map\n",
    "    )\n",
    "\n",
    "    print(f\"Updated {len(updated_chunks)} chunks with segments and captions.\")\n",
    "\n",
    "    # Maak de nieuwe JSON structuur\n",
    "    new_data = {\n",
    "        \"chunks\": updated_chunks\n",
    "    }\n",
    "\n",
    "    # Sla de nieuwe JSON op\n",
    "    save_json(new_data, new_json_path)\n",
    "    print(f\"new JSON with connected segments and captions saved as '{new_json_path}'.\")\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0d4d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "object_path = r\"C:\\Users\\maxim\\OneDrive\\01-Opleidingen\\03-MAAI\\Afstuderen\\Objectdetectie\\detections_with_tracking_YOLOv12mv8_machine_cover_2.json\"\n",
    "har_path = r\"C:\\Users\\maxim\\OneDrive\\01-Opleidingen\\03-MAAI\\Afstuderen\\mmaction2\\final_segments_with_boxes_machine_cover_2.json\"\n",
    "\n",
    "with open(object_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    object_data = json.load(f)\n",
    "\n",
    "with open(har_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    action_data = json.load(f)\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f30884",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_objects_to_chunk(chunk_start, chunk_end, object_data):\n",
    "    relevant_objects = []\n",
    "    for obj_id, obj in object_data.items():\n",
    "        if obj[\"last_seen\"] >= chunk_start and obj[\"first_seen\"] <= chunk_end:\n",
    "            obj[\"object_id\"] = obj_id\n",
    "            relevant_objects.append(obj)\n",
    "    return relevant_objects\n",
    "\n",
    "def match_actions_to_chunk(chunk_start, chunk_end, actions):\n",
    "    return [\n",
    "        act for act in actions\n",
    "        if act[\"end\"] >= chunk_start and act[\"start\"] <= chunk_end\n",
    "    ]\n",
    "\n",
    "def calculate_iou(box1, box2):\n",
    "    x1 = max(box1[\"x\"], box2[\"x\"])\n",
    "    y1 = max(box1[\"y\"], box2[\"y\"])\n",
    "    x2 = min(box1[\"x\"] + box1[\"width\"], box2[\"x\"] + box2[\"width\"])\n",
    "    y2 = min(box1[\"y\"] + box1[\"height\"], box2[\"y\"] + box2[\"height\"])\n",
    "    inter_area = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "    union_area = (\n",
    "        box1[\"width\"] * box1[\"height\"] + box2[\"width\"] * box2[\"height\"] - inter_area\n",
    "    )\n",
    "    return inter_area / union_area if union_area != 0 else 0.0\n",
    "\n",
    "\n",
    "def semantic_similarity(text1, text2, model):\n",
    "    emb = model.encode([text1, text2], convert_to_tensor=True)\n",
    "    return util.pytorch_cos_sim(emb[0], emb[1]).item()\n",
    "\n",
    "\n",
    "def convert_action_box_to_bbox(action_box):\n",
    "    return {\n",
    "        \"x\": action_box[\"x\"],\n",
    "        \"y\": action_box[\"y\"],\n",
    "        \"width\": action_box[\"w\"],\n",
    "        \"height\": action_box[\"h\"]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c1e958",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"processed_json_machine_cover_2/machine_cover_2_chunks.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    chunks_json = json.load(f)\n",
    "\n",
    "enriched_chunks = []\n",
    "for chunk in chunks_json[\"chunks\"]:\n",
    "    start = chunk[\"start\"]\n",
    "    end = chunk[\"end\"]\n",
    "\n",
    "    objects = match_objects_to_chunk(start, end, object_data)\n",
    "    actions = match_actions_to_chunk(start, end, action_data)\n",
    "\n",
    "    links = []\n",
    "    for obj in objects:\n",
    "        for act in actions:\n",
    "            action_bbox = convert_action_box_to_bbox(act[\"avg_bounding_box\"])\n",
    "            ious = [\n",
    "                calculate_iou(f[\"bbox\"], action_bbox)\n",
    "                for f in obj[\"trajectory\"]\n",
    "                if act[\"start\"] <= f[\"time\"] <= act[\"end\"]\n",
    "            ]\n",
    "            avg_iou = np.mean(ious) if ious else 0.0\n",
    "            if avg_iou < 0.05:\n",
    "                continue\n",
    "            sim = semantic_similarity(obj[\"class_name\"], act[\"label\"], model)\n",
    "            # sim = semantic_similarity(f\"object: {obj['class_name']}\", f\"action: {act['label']}\", model)\n",
    "            # sim = semantic_similarity(\n",
    "            #     f\"This is a tool or item called {obj['class_name']}\", \n",
    "            #     f\"This is a human action: {act['label']}\", \n",
    "            #     model\n",
    "            # )\n",
    "\n",
    "            if sim < 0.05:\n",
    "                continue\n",
    "            links.append({\n",
    "                \"object_id\": obj[\"object_id\"],\n",
    "                \"class_name\": obj[\"class_name\"],\n",
    "                \"action_label\": act[\"label\"],\n",
    "                \"iou\": avg_iou,\n",
    "                \"cosine_similarity\": sim,\n",
    "                \"action_score\": act[\"avg_score\"]\n",
    "            })\n",
    "\n",
    "    chunk[\"object_detections\"] = objects\n",
    "    chunk[\"actions\"] = actions\n",
    "    chunk[\"object_action_links\"] = links\n",
    "    enriched_chunks.append(chunk)\n",
    "\n",
    "# Opslaan\n",
    "with open(\"chunks_with_objects_and_actions_machine_cover_2.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\"chunks\": enriched_chunks}, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeec3e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# JSON inladen\n",
    "with open(\"chunks_with_objects_and_actions_machine_cover_2.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "for i, chunk in enumerate(data[\"chunks\"]):\n",
    "    print(f\"Chunk {i+1} links:\")\n",
    "    for link in chunk.get(\"object_action_links\", []):\n",
    "        print(link)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78834a6",
   "metadata": {},
   "source": [
    "## Hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0396c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# # Pas dit pad aan\n",
    "# hand_detection_json_path = r\"C:\\Users\\maxim\\OneDrive\\01-Opleidingen\\03-MAAI\\Afstuderen\\handdetectie_resultaten_stabilizer pressure control.json\"\n",
    "\n",
    "# with open(hand_detection_json_path, 'r', encoding='utf-8') as f:\n",
    "#     hand_data_raw = json.load(f)\n",
    "\n",
    "# # Maak snelle lookup per frame-index\n",
    "# hand_data = {item[\"frame\"]: item for item in hand_data_raw}\n",
    "# print(f\"Handdata geladen voor {len(hand_data)} frames.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fbba9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def point_in_bbox(x, y, bbox):\n",
    "#     return bbox[\"x\"] <= x <= bbox[\"x\"] + bbox[\"width\"] and bbox[\"y\"] <= y <= bbox[\"y\"] + bbox[\"height\"]\n",
    "\n",
    "# def hand_touches_object(hand_keypoints, object_bbox, frame_width, frame_height):\n",
    "#     # converteer genormaliseerde coördinaten naar pixels\n",
    "#     keypoint_indices = [4, 8]  # duimtop en wijsvingertop\n",
    "#     for idx in keypoint_indices:\n",
    "#         kp = hand_keypoints[idx]\n",
    "#         x_px = int(kp[\"x\"] * frame_width)\n",
    "#         y_px = int(kp[\"y\"] * frame_height)\n",
    "#         if point_in_bbox(x_px, y_px, object_bbox):\n",
    "#             return True\n",
    "#     return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf7c7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_closest_hand_data(time_sec, hand_data_dict, tolerance=0.05):\n",
    "#     \"\"\"\n",
    "#     Zoek hand-data waarvan de tijd dicht bij 'time_sec' ligt (binnen tolerance).\n",
    "#     Verwacht hand_data_dict als: {frame_idx: {\"time\": ..., \"hands\": [...]}}\n",
    "#     \"\"\"\n",
    "#     closest = None\n",
    "#     min_diff = float('inf')\n",
    "#     for entry in hand_data_dict.values():  # <-- LET OP!\n",
    "#         diff = abs(entry[\"time\"] - time_sec)\n",
    "#         if diff < min_diff and diff <= tolerance:\n",
    "#             min_diff = diff\n",
    "#             closest = entry\n",
    "#     return closest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943de42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def link_hand_to_object(chunk_start, chunk_end, object_data, hand_data_list, frame_width, frame_height):\n",
    "#     links = []\n",
    "\n",
    "#     for obj_id, obj in object_data.items():\n",
    "#         for traj in obj[\"trajectory\"]:\n",
    "#             time_sec = traj[\"time\"]\n",
    "#             if not (chunk_start <= time_sec <= chunk_end):\n",
    "#                 continue\n",
    "\n",
    "#             bbox = traj[\"bbox\"]\n",
    "#             hand_entry = find_closest_hand_data(time_sec, hand_data_list)\n",
    "#             if not hand_entry:\n",
    "#                 continue\n",
    "\n",
    "#             for hand in hand_entry.get(\"hands\", []):\n",
    "#                 if hand_touches_object(hand, bbox, frame_width, frame_height):\n",
    "#                     links.append({\n",
    "#                         \"object_id\": obj_id,\n",
    "#                         \"class_name\": obj[\"class_name\"],\n",
    "#                         \"time\": time_sec,\n",
    "#                         \"contact_type\": \"touch\"\n",
    "#                     })\n",
    "#                     break\n",
    "#     return links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e34b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Laad bestaande chunks\n",
    "# with open(\"chunks_with_objects_and_actions.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "#     chunks_data = json.load(f)\n",
    "\n",
    "# # Laad object_data indien nog niet gedaan\n",
    "# with open(r\"C:\\Users\\maxim\\OneDrive\\01-Opleidingen\\03-MAAI\\Afstuderen\\Objectdetectie\\detections_with_tracking_YOLOv12mv8_stabilizer_pressure_control.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "#     object_data = json.load(f)  # pas pad aan\n",
    "\n",
    "# frame_width = 1920  # Pas aan naar jouw videoresolutie\n",
    "# frame_height = 1080\n",
    "\n",
    "# for chunk in chunks_data[\"chunks\"]:\n",
    "#     start = chunk[\"start\"]\n",
    "#     end = chunk[\"end\"]\n",
    "#     hand_links = link_hand_to_object(start, end, object_data, hand_data, frame_width, frame_height)\n",
    "#     chunk[\"hand_object_links\"] = hand_links\n",
    "\n",
    "# # Opslaan\n",
    "# with open(\"chunks_with_objects_actions_hands.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(chunks_data, f, indent=4)\n",
    "#     print(\"JSON met hand-object interacties opgeslagen als 'chunks_with_objects_actions_hands.json'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1626ae",
   "metadata": {},
   "source": [
    "## Hands v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e345f321",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "from shapely.geometry import LineString, box\n",
    "\n",
    "# Pad naar handdetectie-data\n",
    "hand_detection_json_path = r\"C:\\Users\\maxim\\OneDrive\\01-Opleidingen\\03-MAAI\\Afstuderen\\handdetectie_resultaten_machine_cover_2.json\"\n",
    "\n",
    "with open(hand_detection_json_path, 'r', encoding='utf-8') as f:\n",
    "    hand_data_raw = json.load(f)\n",
    "\n",
    "# Lookup per frame\n",
    "hand_data = {item[\"frame\"]: item for item in hand_data_raw}\n",
    "print(f\"Handdata geladen voor {len(hand_data)} frames.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b239a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functies voor interacties\n",
    "def point_in_bbox(x, y, bbox):\n",
    "    return bbox[\"x\"] <= x <= bbox[\"x\"] + bbox[\"width\"] and bbox[\"y\"] <= y <= bbox[\"y\"] + bbox[\"height\"]\n",
    "\n",
    "def hand_touches_object(hand_keypoints, object_bbox, frame_width, frame_height):\n",
    "    keypoint_indices = [4, 8]  # duimtop en wijsvingertop\n",
    "    for idx in keypoint_indices:\n",
    "        kp = hand_keypoints[idx]\n",
    "        x_px = int(kp[\"x\"] * frame_width)\n",
    "        y_px = int(kp[\"y\"] * frame_height)\n",
    "        if point_in_bbox(x_px, y_px, object_bbox):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def angle_between(p1, p2, p3):\n",
    "    a = math.hypot(p3[0] - p2[0], p3[1] - p2[1])\n",
    "    b = math.hypot(p1[0] - p2[0], p1[1] - p2[1])\n",
    "    c = math.hypot(p1[0] - p3[0], p1[1] - p3[1])\n",
    "    if a == 0 or b == 0:\n",
    "        return 180\n",
    "    cos_angle = (b**2 + a**2 - c**2) / (2 * a * b)\n",
    "    return math.degrees(math.acos(max(min(cos_angle, 1), -1)))\n",
    "\n",
    "def is_finger_straight(kp_a, kp_b, kp_c, frame_width, frame_height, max_angle=35):\n",
    "    pa = (kp_a[\"x\"] * frame_width, kp_a[\"y\"] * frame_height)\n",
    "    pb = (kp_b[\"x\"] * frame_width, kp_b[\"y\"] * frame_height)\n",
    "    pc = (kp_c[\"x\"] * frame_width, kp_c[\"y\"] * frame_height)\n",
    "    return angle_between(pa, pb, pc) < max_angle\n",
    "\n",
    "def is_index_finger_straight(hand_keypoints, frame_width, frame_height):\n",
    "    return (\n",
    "        is_finger_straight(hand_keypoints[5], hand_keypoints[6], hand_keypoints[7], frame_width, frame_height)\n",
    "        and is_finger_straight(hand_keypoints[6], hand_keypoints[7], hand_keypoints[8], frame_width, frame_height)\n",
    "    )\n",
    "\n",
    "def are_other_fingers_bent(hand_keypoints, frame_width, frame_height, min_angle=35):\n",
    "    finger_indices = [(9, 10, 11), (13, 14, 15), (17, 18, 19)]\n",
    "    for a, b, c in finger_indices:\n",
    "        if is_finger_straight(hand_keypoints[a], hand_keypoints[b], hand_keypoints[c], frame_width, frame_height, max_angle=min_angle):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def hand_points_to_object(hand_keypoints, object_bbox, frame_width, frame_height):\n",
    "    if not is_index_finger_straight(hand_keypoints, frame_width, frame_height):\n",
    "        return False\n",
    "    if not are_other_fingers_bent(hand_keypoints, frame_width, frame_height):\n",
    "        return False\n",
    "\n",
    "    kp5 = hand_keypoints[5]\n",
    "    kp8 = hand_keypoints[8]\n",
    "    x1, y1 = kp5[\"x\"] * frame_width, kp5[\"y\"] * frame_height\n",
    "    x2, y2 = kp8[\"x\"] * frame_width, kp8[\"y\"] * frame_height\n",
    "\n",
    "    dx = x2 - x1\n",
    "    dy = y2 - y1\n",
    "    if dx == 0 and dy == 0:\n",
    "        return False\n",
    "\n",
    "    x3 = x1 + dx * 10\n",
    "    y3 = y1 + dy * 10\n",
    "\n",
    "    pointing_line = LineString([(x1, y1), (x3, y3)])\n",
    "    bbox_shape = box(object_bbox[\"x\"], object_bbox[\"y\"],\n",
    "                     object_bbox[\"x\"] + object_bbox[\"width\"],\n",
    "                     object_bbox[\"y\"] + object_bbox[\"height\"])\n",
    "    return pointing_line.intersects(bbox_shape)\n",
    "\n",
    "def find_closest_hand_data(time_sec, hand_data_dict, tolerance=0.05):\n",
    "    closest = None\n",
    "    min_diff = float('inf')\n",
    "    for entry in hand_data_dict.values():\n",
    "        diff = abs(entry[\"time\"] - time_sec)\n",
    "        if diff < min_diff and diff <= tolerance:\n",
    "            min_diff = diff\n",
    "            closest = entry\n",
    "    return closest\n",
    "\n",
    "def link_hand_to_object(chunk_start, chunk_end, object_data, hand_data_list, frame_width, frame_height):\n",
    "    links = []\n",
    "    for obj_id, obj in object_data.items():\n",
    "        for traj in obj[\"trajectory\"]:\n",
    "            time_sec = traj[\"time\"]\n",
    "            if not (chunk_start <= time_sec <= chunk_end):\n",
    "                continue\n",
    "\n",
    "            bbox = traj[\"bbox\"]\n",
    "            hand_entry = find_closest_hand_data(time_sec, hand_data_list)\n",
    "            if not hand_entry:\n",
    "                continue\n",
    "\n",
    "            for hand in hand_entry.get(\"hands\", []):\n",
    "                if hand_touches_object(hand, bbox, frame_width, frame_height):\n",
    "                    contact_type = \"touch\"\n",
    "                elif hand_points_to_object(hand, bbox, frame_width, frame_height):\n",
    "                    contact_type = \"point\"\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "                links.append({\n",
    "                    \"object_id\": obj_id,\n",
    "                    \"class_name\": obj[\"class_name\"],\n",
    "                    \"time\": time_sec,\n",
    "                    \"contact_type\": contact_type\n",
    "                })\n",
    "                break\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d4711d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Videoresolutie\n",
    "frame_width = 1920\n",
    "frame_height = 1080\n",
    "\n",
    "# Laad objectdata\n",
    "with open(r\"C:\\Users\\maxim\\OneDrive\\01-Opleidingen\\03-MAAI\\Afstuderen\\Objectdetectie\\detections_with_tracking_YOLOv12mv8_machine_cover_2.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    object_data = json.load(f)\n",
    "\n",
    "# Laad chunks\n",
    "with open(\"chunks_with_objects_and_actions_machine_cover_2.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    chunks_data = json.load(f)\n",
    "\n",
    "# Verwerk alle chunks\n",
    "for chunk in chunks_data[\"chunks\"]:\n",
    "    start = chunk[\"start\"]\n",
    "    end = chunk[\"end\"]\n",
    "    hand_links = link_hand_to_object(start, end, object_data, hand_data, frame_width, frame_height)\n",
    "    chunk[\"hand_object_links\"] = hand_links\n",
    "\n",
    "# Opslaan\n",
    "with open(\"chunks_with_objects_actions_hands_machine_cover_2.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(chunks_data, f, indent=4)\n",
    "    print(\"JSON met hand-object interacties opgeslagen als 'chunks_with_objects_actions_handsv2.json'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9087a3b",
   "metadata": {},
   "source": [
    "## Sentence transformer captions linking to chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a57dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import List, Dict, Any\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "def load_json(file_path: str) -> Any:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def save_json(data: Any, file_path: str):\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "    print(f\"JSON opgeslagen als '{file_path}'.\")\n",
    "\n",
    "def preprocess_chunks(chunks: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "    processed_chunks = []\n",
    "    for chunk in chunks:\n",
    "        text = chunk.get('text', \"\")\n",
    "        if text:\n",
    "            # Gebruik zowel start als end tijden als float voor unieke identificatie\n",
    "            processed_chunks.append({\n",
    "                \"chunk_id\": f\"{chunk['start']}_{chunk['end']}\",\n",
    "                \"text\": text,\n",
    "                \"start\": chunk['start'],\n",
    "                \"end\": chunk['end']\n",
    "            })\n",
    "    return processed_chunks\n",
    "\n",
    "def preprocess_captions(captions: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "    processed_captions = []\n",
    "    for caption in captions:\n",
    "        text = caption.get('caption', \"\")\n",
    "        if text:\n",
    "            processed_captions.append({\n",
    "                \"video_segment\": caption.get('video_segment', \"\"),\n",
    "                \"frame_filename\": caption.get('frame_filename', \"\"),\n",
    "                \"caption\": text\n",
    "            })\n",
    "    return processed_captions\n",
    "\n",
    "def compute_embeddings(model: SentenceTransformer, texts: List[str], batch_size: int = 32) -> torch.Tensor:\n",
    "\n",
    "    embeddings = model.encode(texts, batch_size=batch_size, convert_to_tensor=True, show_progress_bar=True)\n",
    "    return embeddings\n",
    "\n",
    "def parse_segment_times(segment_name: str) -> tuple[int, int]:\n",
    "    match = re.search(r\"segment_\\d+_(\\d+)_(\\d+)\", segment_name)\n",
    "    if match:\n",
    "        return int(match.group(1)), int(match.group(2))\n",
    "    return (0, 0)\n",
    "\n",
    "def link_captions_to_chunks(\n",
    "    chunks: List[Dict[str, Any]],\n",
    "    captions: List[Dict[str, Any]],\n",
    "    similarity_threshold: float = 0.3\n",
    ") -> List[Dict[str, Any]]:\n",
    "\n",
    "    model = SentenceTransformer('all-mpnet-base-v2')\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model = model.to(device)\n",
    "\n",
    "    links = []\n",
    "\n",
    "    for idx, caption in enumerate(tqdm(captions, desc=\"Linking Captions\")):\n",
    "        segment_name = caption.get(\"video_segment\", \"\")\n",
    "        caption_text = caption.get(\"caption\", \"\").strip()\n",
    "\n",
    "        if not caption_text or not segment_name:\n",
    "            continue\n",
    "\n",
    "        segment_start, segment_end = parse_segment_times(segment_name)\n",
    "        \n",
    "        margin = 1\n",
    "        candidate_chunks = [\n",
    "            chunk for chunk in chunks\n",
    "                if chunk[\"start\"] >= segment_start - margin and chunk[\"end\"] <= segment_end + margin\n",
    "        ]\n",
    "\n",
    "        if not candidate_chunks:\n",
    "            links.append({\n",
    "                \"caption_index\": idx,\n",
    "                \"frame_filename\": caption.get(\"frame_filename\", \"\"),\n",
    "                \"video_segment\": segment_name,\n",
    "                \"caption\": caption_text,\n",
    "                \"linked_chunk_id\": None,\n",
    "                \"linked_chunk_text\": None,\n",
    "                \"similarity_score\": None\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        # Bereken caption embedding correct als tensor\n",
    "        caption_embedding = model.encode([caption_text], convert_to_tensor=True).to(device)\n",
    "\n",
    "        chunk_texts = [chunk[\"text\"] for chunk in candidate_chunks]\n",
    "        chunk_embeddings = model.encode(chunk_texts, convert_to_tensor=True).to(device)\n",
    "\n",
    "        similarities = util.cos_sim(caption_embedding, chunk_embeddings)[0]  # shape: (num_chunks,)\n",
    "        top_idx = torch.argmax(similarities).item()\n",
    "        top_score = similarities[top_idx].item()\n",
    "\n",
    "        print(f\"⏱ Caption {idx}: top_score = {top_score:.4f}, threshold = {similarity_threshold}\")\n",
    "\n",
    "\n",
    "        if top_score >= similarity_threshold:\n",
    "            linked_chunk = candidate_chunks[top_idx]\n",
    "            links.append({\n",
    "                \"caption_index\": idx,\n",
    "                \"frame_filename\": caption.get(\"frame_filename\", \"\"),\n",
    "                \"video_segment\": segment_name,\n",
    "                \"caption\": caption_text,\n",
    "                \"linked_chunk_id\": linked_chunk['chunk_id'],\n",
    "                \"linked_chunk_text\": linked_chunk['text'],\n",
    "                \"similarity_score\": top_score\n",
    "            })\n",
    "        else:\n",
    "            links.append({\n",
    "                \"caption_index\": idx,\n",
    "                \"frame_filename\": caption.get(\"frame_filename\", \"\"),\n",
    "                \"video_segment\": segment_name,\n",
    "                \"caption\": caption_text,\n",
    "                \"linked_chunk_id\": None,\n",
    "                \"linked_chunk_text\": None,\n",
    "                \"similarity_score\": top_score\n",
    "            })\n",
    "\n",
    "    return links\n",
    "\n",
    "\n",
    "def filter_linked_captions(links: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Filter de links om alleen de gekoppelde captions te behouden.\n",
    "    \"\"\"\n",
    "    filtered_links = [link for link in links if link['linked_chunk_id'] is not None]\n",
    "    print(f\"Filtered captions: {len(filtered_links)} out of {len(links)} were successfully linked.\")\n",
    "    return filtered_links\n",
    "\n",
    "def main():\n",
    "    # Definieer paden\n",
    "    chunks_json_path = \"processed_json_machine_cover_2/machine_cover_2_chunks.json\"        # Originele JSON met chunks\n",
    "    captions_json_path = \"combined_frames_machine_cover_2.json\"              # JSON met image captions\n",
    "    output_mapping_path = \"captions_to_chunks_mapping_machine_cover_2.json\" # Nieuwe JSON output (alle koppelingen)\n",
    "    filtered_output_path = \"filtered_captions_to_chunks_mapping_machine_cover_2.json\" # Nieuwe JSON output (gekoppelde captions)\n",
    "\n",
    "    # Controleer of alle benodigde bestanden bestaan\n",
    "    required_files = [chunks_json_path, captions_json_path]\n",
    "    for file in required_files:\n",
    "        if not os.path.exists(file):\n",
    "            print(f\"Error: Vereist bestand '{file}' bestaat niet.\")\n",
    "            return\n",
    "\n",
    "    # Laad de JSON-bestanden\n",
    "    print(\"Loading JSON files...\")\n",
    "    chunks_data = load_json(chunks_json_path)\n",
    "    captions_data = load_json(captions_json_path)\n",
    "\n",
    "    chunks = chunks_data.get('chunks', [])\n",
    "    captions = captions_data  # Verondersteld dat combined_frames.json een lijst is\n",
    "\n",
    "    if not chunks:\n",
    "        print(\"Geen chunks gevonden in de hoofd JSON.\")\n",
    "        return\n",
    "    if not captions:\n",
    "        print(\"Geen captions gevonden in de captions JSON.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Loaded {len(chunks)} chunks and {len(captions)} captions.\")\n",
    "\n",
    "    # Voorbereiden van data\n",
    "    processed_chunks = preprocess_chunks(chunks)\n",
    "    processed_captions = preprocess_captions(captions)\n",
    "\n",
    "    # Koppel captions aan chunks via Sentence Transformers\n",
    "    links = link_captions_to_chunks(processed_chunks, processed_captions, similarity_threshold=0.1)\n",
    "    print(f\"Generated {len(links)} caption links.\")\n",
    "\n",
    "    # Sla de volledige mapping op als een nieuwe JSON\n",
    "    save_json(links, output_mapping_path)\n",
    "    print(f\"Captions to chunks mapping saved to '{output_mapping_path}'.\")\n",
    "\n",
    "    # Filter de gekoppelde captions\n",
    "    filtered_links = filter_linked_captions(links)\n",
    "\n",
    "    # Sla de gefilterde mapping op als een nieuwe JSON\n",
    "    save_json(filtered_links, filtered_output_path)\n",
    "    print(f\"Filtered captions to chunks mapping saved to '{filtered_output_path}'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61c3c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Pad naar je bestanden\n",
    "filtered_links_path = \"filtered_captions_to_chunks_mapping_machine_cover_2.json\"\n",
    "enriched_chunks_path = \"chunks_with_objects_actions_hands_machine_cover_2.json\"  # <-- LET OP: met hand-object links nu\n",
    "output_path = \"enriched_filtered_captions_to_chunks_mapping_hands_machine_cover_2.json\"\n",
    "\n",
    "# 1. Laad beide JSON-bestanden\n",
    "with open(filtered_links_path, 'r', encoding='utf-8') as f:\n",
    "    filtered_links = json.load(f)\n",
    "\n",
    "with open(enriched_chunks_path, 'r', encoding='utf-8') as f:\n",
    "    enriched_chunks = json.load(f)[\"chunks\"]\n",
    "\n",
    "# 2. Bouw index: van \"start_end\" naar chunk\n",
    "chunk_index = {}\n",
    "for chunk in enriched_chunks:\n",
    "    key = f\"{chunk['start']}_{chunk['end']}\"\n",
    "    chunk_index[key] = chunk\n",
    "\n",
    "# 3. Verwerk de mappinglijst\n",
    "enriched_links = []\n",
    "for item in filtered_links:\n",
    "    chunk_id = item.get(\"linked_chunk_id\")\n",
    "    if not chunk_id:\n",
    "        enriched_links.append(item)\n",
    "        continue\n",
    "\n",
    "    matching_chunk = chunk_index.get(chunk_id)\n",
    "    if not matching_chunk:\n",
    "        print(f\"Waarschuwing: Geen match voor chunk ID {chunk_id}\")\n",
    "        enriched_links.append(item)\n",
    "        continue\n",
    "\n",
    "    # Voeg objecten/acties/hand-object links toe\n",
    "    item[\"object_detections\"] = matching_chunk.get(\"object_detections\", [])\n",
    "    item[\"actions\"] = matching_chunk.get(\"actions\", [])\n",
    "    item[\"object_action_links\"] = matching_chunk.get(\"object_action_links\", [])\n",
    "    item[\"hand_object_links\"] = matching_chunk.get(\"hand_object_links\", [])  # <-- Nieuw toegevoegd\n",
    "    enriched_links.append(item)\n",
    "\n",
    "# 4. Sla nieuwe lijst op\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(enriched_links, f, indent=4)\n",
    "\n",
    "print(f\"Verrijkte mapping opgeslagen in '{output_path}' inclusief hand-object links.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133ba0f5",
   "metadata": {},
   "source": [
    "# Cake\n",
    "## Download model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521cc115",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n",
    "\n",
    "llm = Llama.from_pretrained(\n",
    "    repo_id=\"bartowski/Qwen2.5-7B-Instruct-GGUF\",\n",
    "    filename=\"*Q4_K_M.gguf\",\n",
    "    verbose=False,\n",
    "    local_dir=\"models\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fd3c4b",
   "metadata": {},
   "source": [
    "## Knowledge extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c253f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import os\n",
    "# import pickle\n",
    "# import threading\n",
    "# from llama_cpp import Llama\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "# import faiss\n",
    "# import numpy as np\n",
    "# from json import JSONDecodeError\n",
    "\n",
    "# # llama singleton to ensure one model is used for ram usage efficiency\n",
    "# class LlamaSingleton:\n",
    "#     _instance = None\n",
    "#     _lock = threading.Lock()\n",
    "\n",
    "#     def __new__(cls, model_path=\"models/Qwen2.5-7B-Instruct-Q4_K_M.gguf\", chat_format=\"chatml\"):\n",
    "#         with cls._lock:\n",
    "#             if cls._instance is None:\n",
    "#                 cls._instance = super(LlamaSingleton, cls).__new__(cls)\n",
    "#                 cls._instance.llm = Llama(model_path=model_path, chat_format=chat_format, n_ctx=2048)\n",
    "#             return cls._instance\n",
    "\n",
    "# # chatbot class to extract knowledge from chunks\n",
    "# class Chatbot:\n",
    "#     def __init__(self, \n",
    "#                  messages_file='messages_machine_cover_2.json', \n",
    "#                  knowledge_file='knowledge_machine_cover_2.json', \n",
    "#                  faiss_index_file='faiss_index_machine_cover_2.pkl',\n",
    "#                  model_name='all-MiniLM-L6-v2'):\n",
    "#         self.messages_file = messages_file\n",
    "#         self.knowledge_file = knowledge_file\n",
    "#         self.faiss_index_file = faiss_index_file\n",
    "#         self.llm = LlamaSingleton().llm\n",
    "#         self.model = SentenceTransformer(model_name)\n",
    "#         self.index = None\n",
    "#         self.knowledge_data = []\n",
    "#         self.initialize_files()\n",
    "#         self.load_faiss_index()\n",
    "\n",
    "#     def initialize_files(self):\n",
    "#         for file in [self.messages_file, self.knowledge_file]:\n",
    "#             if not os.path.exists(file):\n",
    "#                 with open(file, 'w') as f:\n",
    "#                     json.dump([], f)\n",
    "\n",
    "#     def load_json_data(self, file_path):\n",
    "#         with open(file_path, 'r') as f:\n",
    "#             return json.load(f)\n",
    "\n",
    "#     def save_json_data(self, file_path, data):\n",
    "#         with open(file_path, 'w') as f:\n",
    "#             json.dump(data, f, indent=4)\n",
    "\n",
    "#     # this function extracts the knowledge from the chunk text\n",
    "#     def extract_valuable_knowledge(self, message):\n",
    "#         \"\"\"\n",
    "#         Sends the chunk text to the model and asks it to return JSON with\n",
    "#         subject/predicate/object. No timestamps are generated by the model.\n",
    "#         \"\"\"\n",
    "#         response = self.llm.create_chat_completion(\n",
    "#             messages=[\n",
    "#                 {\n",
    "#                     \"role\": \"system\",\n",
    "#                     \"content\": (\n",
    "#                         \"You are a knowledge extractor. Extract subject-predicate-object knowledge triplets \\n\" # WEGHALEN\n",
    "#                         \"from all the provided information: transcript, linked object-action pairs and hand-object interactions.\\n\" # WEGHALEN\n",
    "#                         \"\"\"Correct example: { \"subject\": \"person\", \"predicate\": \"holds\", \"object\": \"cup\" }Incorrect example: { \"subject\": \"he\", \"predicate\": \"does\", \"object\": \"it\" }\"\"\"\n",
    "#                         # \"Return ONLY JSON with the following schema:\\n\"\n",
    "#                         # \"{\\n\"\n",
    "#                         # \"  \\\"valuable_knowledge\\\": [\\n\"\n",
    "#                         # \"    {\\n\"\n",
    "#                         # \"      \\\"subject\\\": \\\"...\\\",\\n\"\n",
    "#                         # \"      \\\"predicate\\\": \\\"...\\\",\\n\"\n",
    "#                         # \"      \\\"object\\\": \\\"...\\\"\\n\"\n",
    "#                         # \"    }\\n\"\n",
    "#                         # \"  ]\\n\"\n",
    "#                         # \"}\\n\"\n",
    "#                         # \"If no knowledge can be extracted, return:\\n\"\n",
    "#                         # \"{\\\"valuable_knowledge\\\": []}\"\n",
    "#                     )\n",
    "#                 },\n",
    "#                 {\"role\": \"user\", \"content\": message},\n",
    "#             ],\n",
    "#             response_format={\n",
    "#                 \"type\": \"json\",\n",
    "#                 \"schema\": {\n",
    "#                     \"type\": \"object\",\n",
    "#                     \"properties\": {\n",
    "#                         \"valuable_knowledge\": {\n",
    "#                             \"type\": \"array\",\n",
    "#                             \"items\": {\n",
    "#                                 \"type\": \"object\",\n",
    "#                                 \"properties\": {\n",
    "#                                     \"subject\": {\"type\": \"string\"},\n",
    "#                                     \"predicate\": {\"type\": \"string\"},\n",
    "#                                     \"object\": {\"type\": \"string\"}\n",
    "#                                 },\n",
    "#                                 \"required\": [\"subject\", \"predicate\", \"object\"]\n",
    "#                             }\n",
    "#                         }\n",
    "#                     },\n",
    "#                     \"required\": [\"valuable_knowledge\"],\n",
    "#                 },\n",
    "#             },\n",
    "#             temperature=0.5,\n",
    "#         )\n",
    "#         try:\n",
    "#             response_content = response['choices'][0]['message']['content']\n",
    "\n",
    "#             # Strip ```json en ``` als ze aanwezig zijn\n",
    "#             if response_content.strip().startswith(\"```json\"):\n",
    "#                 response_content = response_content.strip()[7:]  # strip '```json\\n'\n",
    "#             if response_content.strip().endswith(\"```\"):\n",
    "#                 response_content = response_content.strip()[:-3]  # strip trailing '```'\n",
    "\n",
    "#             knowledge_data = json.loads(response_content) # Vervanging voor regel hier onder\n",
    "#             #knowledge_data = json.loads(response['choices'][0]['message']['content'])\n",
    "#             print(\"Extracted knowledge from a chunk:\", knowledge_data)\n",
    "#             if \"valuable_knowledge\" not in knowledge_data:\n",
    "#                 knowledge_data[\"valuable_knowledge\"] = []\n",
    "#             return knowledge_data[\"valuable_knowledge\"]\n",
    "#         except (JSONDecodeError, KeyError) as e:\n",
    "#             print(f\"Parsing error: {e}\")\n",
    "#             print(\"Volledige model response:\", response) # WEGHALEN WANNEER KLAAR\n",
    "#             return []\n",
    "\n",
    "#     def save_knowledge(self, triplets):\n",
    "#         \"\"\"\n",
    "#         Persists triplets to `knowledge.json` and updates FAISS index if new triplets\n",
    "#         are found. We do not add any timestamps here.\n",
    "#         \"\"\"\n",
    "#         if not triplets:\n",
    "#             return\n",
    "#         knowledge = self.load_json_data(self.knowledge_file)\n",
    "#         existing_set = {(t['subject'], t['predicate'], t['object']) for t in knowledge}\n",
    "#         new_triplets = []\n",
    "#         for triplet in triplets:\n",
    "#             key = (triplet['subject'], triplet['predicate'], triplet['object'])\n",
    "#             if key not in existing_set:\n",
    "#                 knowledge.append(triplet)\n",
    "#                 new_triplets.append(triplet)\n",
    "#                 existing_set.add(key)\n",
    "#         self.save_json_data(self.knowledge_file, knowledge)\n",
    "#         if new_triplets:\n",
    "#             self.update_faiss_index(new_triplets)\n",
    "\n",
    "#     def update_faiss_index(self, triplets):\n",
    "#         texts = [f\"{t['subject']} {t['predicate']} {t['object']}\" for t in triplets]\n",
    "#         embeddings = self.model.encode(texts)\n",
    "#         if self.index is None:\n",
    "#             self.index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "#         self.index.add(np.array(embeddings, dtype=np.float32))\n",
    "#         self.knowledge_data.extend(triplets)\n",
    "#         self.save_faiss_index()\n",
    "\n",
    "#     def save_faiss_index(self):\n",
    "#         with open(self.faiss_index_file, 'wb') as f:\n",
    "#             pickle.dump((self.index, self.knowledge_data), f)\n",
    "\n",
    "#     def load_faiss_index(self):\n",
    "#         if os.path.exists(self.faiss_index_file):\n",
    "#             with open(self.faiss_index_file, 'rb') as f:\n",
    "#                 self.index, self.knowledge_data = pickle.load(f)\n",
    "#         else:\n",
    "#             self.index = None\n",
    "#             self.knowledge_data = []\n",
    "\n",
    "\n",
    "# # Chats idee + audio altijd meenemen\n",
    "# def main():\n",
    "#     # Paden naar inputbestanden\n",
    "#     enriched_links_path = \"enriched_filtered_captions_to_chunks_mapping_hands_machine_cover_2json\"\n",
    "#     all_chunks_path = \"processed_json_machine_cover_2/machine_cover_2_chunks.json\"\n",
    "\n",
    "#     # Bestandscontrole\n",
    "#     if not os.path.exists(enriched_links_path):\n",
    "#         print(f\"Bestand '{enriched_links_path}' bestaat niet.\")\n",
    "#         return\n",
    "#     if not os.path.exists(all_chunks_path):\n",
    "#         print(f\"Bestand '{all_chunks_path}' bestaat niet.\")\n",
    "#         return\n",
    "\n",
    "#     # Laad verrijkte links en chunks\n",
    "#     with open(enriched_links_path, 'r', encoding='utf-8') as f:\n",
    "#         enriched_links = json.load(f)\n",
    "\n",
    "#     with open(all_chunks_path, 'r', encoding='utf-8') as f:\n",
    "#         chunk_data = json.load(f)\n",
    "#     all_chunks = chunk_data.get(\"chunks\", [])\n",
    "\n",
    "#     print(f\"{len(all_chunks)} chunks geladen.\")\n",
    "#     print(f\"{len(enriched_links)} verrijkte caption-links geladen.\")\n",
    "\n",
    "#     # Bouw een mapping van chunk_id → enrichment info\n",
    "#     from collections import defaultdict\n",
    "#     enrichment_map = {}\n",
    "#     for item in enriched_links:\n",
    "#         chunk_id = item.get(\"linked_chunk_id\", \"\")\n",
    "#         if chunk_id:\n",
    "#             enrichment_map[chunk_id] = item\n",
    "\n",
    "#     chatbot = Chatbot()\n",
    "\n",
    "#     for i, chunk in enumerate(all_chunks, start=1):\n",
    "#         chunk_text = chunk.get(\"text\", \"\").strip()\n",
    "#         start_time = chunk.get(\"start\")\n",
    "#         end_time = chunk.get(\"end\")\n",
    "#         chunk_id = f\"{start_time}_{end_time}\"\n",
    "\n",
    "#         if not chunk_text:\n",
    "#             print(f\"Skipping lege chunk {chunk_id}\")\n",
    "#             continue\n",
    "\n",
    "#         # Kijk of er enrichment bestaat\n",
    "#         enrichment = enrichment_map.get(chunk_id)\n",
    "\n",
    "#         # Bouw de prompt op\n",
    "#         if enrichment:\n",
    "#             caption = enrichment.get(\"caption\", \"\").strip()\n",
    "#             object_classes = [o.get(\"class_name\", \"\") for o in enrichment.get(\"object_detections\", [])]\n",
    "#             action_labels = [a.get(\"label\", \"\") for a in enrichment.get(\"actions\", [])]\n",
    "#             relations = [\n",
    "#                 f\"{l['class_name']} → {l['action_label']}\"\n",
    "#                 for l in enrichment.get(\"object_action_links\", [])\n",
    "#             ]\n",
    "            \n",
    "#             # Hand-object interactions: alleen unieke objectnamen zonder (contact_type)\n",
    "#             unique_hand_contacts = set(\n",
    "#                 h.get(\"class_name\", \"\").strip()\n",
    "#                 for h in enrichment.get(\"hand_object_links\", [])\n",
    "#                 if h.get(\"class_name\", \"\").strip()\n",
    "#             )\n",
    "#             hand_object_contacts = sorted(unique_hand_contacts)\n",
    "\n",
    "#             combined_input = (\n",
    "#                 f\"Transcript: {chunk_text}\\n\"\n",
    "#                 #f\"Caption: {caption}\\n\"\n",
    "#                 #f\"Objects in scene: {', '.join(object_classes)}\\n\"\n",
    "#                 #f\"Detected actions: {', '.join(action_labels)}\\n\"\n",
    "#                 f\"Linked object-action pairs: {', '.join(relations)}\\n\"\n",
    "#                 f\"Hand-object interactions: {', '.join(hand_object_contacts)}\"\n",
    "#             )\n",
    "#         else:\n",
    "#             combined_input = f\"Transcript: {chunk_text}\"\n",
    "\n",
    "\n",
    "#         print(f\"\\n[{i}] Extracting knowledge for chunk {chunk_id}\")\n",
    "\n",
    "#         print(combined_input)\n",
    "#         extracted_knowledge = chatbot.extract_valuable_knowledge(combined_input)\n",
    "\n",
    "#         if extracted_knowledge:\n",
    "#             for triplet in extracted_knowledge:\n",
    "#                 triplet[\"start\"] = start_time\n",
    "#                 triplet[\"end\"] = end_time\n",
    "#             chatbot.save_knowledge(extracted_knowledge)\n",
    "\n",
    "#     print(\"\\nKennisextractie afgerond. Bekijk 'knowledge.json' voor de resultaten.\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import threading\n",
    "from llama_cpp import Llama\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "from json import JSONDecodeError\n",
    "\n",
    "class LlamaSingleton:\n",
    "    _instance = None\n",
    "    _lock = threading.Lock()\n",
    "\n",
    "    def __new__(cls, model_path=\"models/Qwen2.5-7B-Instruct-Q4_K_M.gguf\", chat_format=\"chatml\"):\n",
    "        with cls._lock:\n",
    "            if cls._instance is None:\n",
    "                cls._instance = super(LlamaSingleton, cls).__new__(cls)\n",
    "                cls._instance.llm = Llama(model_path=model_path, chat_format=chat_format, n_ctx=2048)\n",
    "            return cls._instance\n",
    "\n",
    "class Chatbot:\n",
    "    def __init__(self, \n",
    "                 messages_file='messages_machine_cover_2_info.json', \n",
    "                 knowledge_file='knowledge_machine_cover_2_info.json', \n",
    "                 faiss_index_file='faiss_index_machine_cover_2_info.pkl',\n",
    "                 model_name='all-MiniLM-L6-v2'):\n",
    "        self.messages_file = messages_file\n",
    "        self.knowledge_file = knowledge_file\n",
    "        self.faiss_index_file = faiss_index_file\n",
    "        self.llm = LlamaSingleton().llm\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.index = None\n",
    "        self.knowledge_data = []\n",
    "        self.initialize_files()\n",
    "        self.load_faiss_index()\n",
    "\n",
    "    def initialize_files(self):\n",
    "        for file in [self.messages_file, self.knowledge_file]:\n",
    "            if not os.path.exists(file):\n",
    "                with open(file, 'w') as f:\n",
    "                    json.dump([], f)\n",
    "\n",
    "    def load_json_data(self, file_path):\n",
    "        with open(file_path, 'r') as f:\n",
    "            return json.load(f)\n",
    "\n",
    "    def save_json_data(self, file_path, data):\n",
    "        with open(file_path, 'w') as f:\n",
    "            json.dump(data, f, indent=4)\n",
    "\n",
    "    def extract_valuable_knowledge(self, message):\n",
    "        response = self.llm.create_chat_completion(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": (\n",
    "                        \"You are a knowledge extractor. Extract subject-predicate-object knowledge triplets \"\n",
    "                        \"from all the provided information: transcript, linked object-action pairs and hand-object interactions.\\n\"\n",
    "                        \"Correct example: { \\\"subject\\\": \\\"person\\\", \\\"predicate\\\": \\\"holds\\\", \\\"object\\\": \\\"cup\\\" }\\n\"\n",
    "                        \"Incorrect example: { \\\"subject\\\": \\\"he\\\", \\\"predicate\\\": \\\"does\\\", \\\"object\\\": \\\"it\\\" }\\n\"\n",
    "                        # \"Return ONLY a JSON object like: {\\\"valuable_knowledge\\\": [ ... ]}\\n\"\n",
    "                        \"If no knowledge can be extracted, return: {\\\"valuable_knowledge\\\": []}\"\n",
    "                        # \"You are a knowledge extractor. Extract subject-predicate-object knowledge triplets \\n\" # WEGHALEN\n",
    "                        # \"from all the provided information: transcript, linked object-action pairs and hand-object interactions.\\n\" # WEGHALEN\n",
    "                        # \"\"\"Correct example: { \"subject\": \"person\", \"predicate\": \"holds\", \"object\": \"cup\" }Incorrect example: { \"subject\": \"he\", \"predicate\": \"does\", \"object\": \"it\" }\"\"\"\n",
    "                        # # \"Return ONLY JSON with the following schema:\\n\"\n",
    "                        # # \"{\\n\"\n",
    "                        # # \"  \\\"valuable_knowledge\\\": [\\n\"\n",
    "                        # # \"    {\\n\"\n",
    "                        # # \"      \\\"subject\\\": \\\"...\\\",\\n\"\n",
    "                        # # \"      \\\"predicate\\\": \\\"...\\\",\\n\"\n",
    "                        # # \"      \\\"object\\\": \\\"...\\\"\\n\"\n",
    "                        # # \"    }\\n\"\n",
    "                        # # \"  ]\\n\"\n",
    "                        # # \"}\\n\"\n",
    "                        # \"If no knowledge can be extracted, return:\\n\"\n",
    "                        # \"{\\\"valuable_knowledge\\\": []}\"\n",
    "                    )\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": message},\n",
    "            ],\n",
    "            response_format={\n",
    "                \"type\": \"json\",\n",
    "                \"schema\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"valuable_knowledge\": {\n",
    "                            \"type\": \"array\",\n",
    "                            \"items\": {\n",
    "                                \"type\": \"object\",\n",
    "                                \"properties\": {\n",
    "                                    \"subject\": {\"type\": \"string\"},\n",
    "                                    \"predicate\": {\"type\": \"string\"},\n",
    "                                    \"object\": {\"type\": \"string\"}\n",
    "                                },\n",
    "                                \"required\": [\"subject\", \"predicate\", \"object\"]\n",
    "                            }\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"valuable_knowledge\"],\n",
    "                },\n",
    "            },\n",
    "            temperature=0.5,\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            response_content = response['choices'][0]['message']['content'].strip()\n",
    "\n",
    "            # Verwijder markdown-codeblokken\n",
    "            if response_content.startswith(\"```json\"):\n",
    "                response_content = response_content[7:]\n",
    "            if response_content.endswith(\"```\"):\n",
    "                response_content = response_content[:-3]\n",
    "\n",
    "            parsed = json.loads(response_content)\n",
    "\n",
    "            if isinstance(parsed, list):\n",
    "                print(\"Model returned a list instead of expected object. Wrapping it.\")\n",
    "                parsed = {\"valuable_knowledge\": parsed}\n",
    "\n",
    "            if \"valuable_knowledge\" not in parsed:\n",
    "                parsed[\"valuable_knowledge\"] = []\n",
    "\n",
    "            print(\"Extracted knowledge from a chunk:\", parsed)\n",
    "            return parsed[\"valuable_knowledge\"]\n",
    "\n",
    "        except (JSONDecodeError, KeyError, TypeError) as e:\n",
    "            print(f\"JSON parse error: {e}\")\n",
    "            print(\"Raw model response:\\n\", response)\n",
    "            return []\n",
    "\n",
    "    def save_knowledge(self, triplets):\n",
    "        if not triplets:\n",
    "            return\n",
    "        knowledge = self.load_json_data(self.knowledge_file)\n",
    "        existing_set = {(t['subject'], t['predicate'], t['object']) for t in knowledge}\n",
    "        new_triplets = []\n",
    "        for triplet in triplets:\n",
    "            key = (triplet['subject'], triplet['predicate'], triplet['object'])\n",
    "            if key not in existing_set:\n",
    "                knowledge.append(triplet)\n",
    "                new_triplets.append(triplet)\n",
    "                existing_set.add(key)\n",
    "        self.save_json_data(self.knowledge_file, knowledge)\n",
    "        if new_triplets:\n",
    "            self.update_faiss_index(new_triplets)\n",
    "\n",
    "    def update_faiss_index(self, triplets):\n",
    "        texts = [f\"{t['subject']} {t['predicate']} {t['object']}\" for t in triplets]\n",
    "        embeddings = self.model.encode(texts)\n",
    "        if self.index is None:\n",
    "            self.index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "        self.index.add(np.array(embeddings, dtype=np.float32))\n",
    "        self.knowledge_data.extend(triplets)\n",
    "        self.save_faiss_index()\n",
    "\n",
    "    def save_faiss_index(self):\n",
    "        with open(self.faiss_index_file, 'wb') as f:\n",
    "            pickle.dump((self.index, self.knowledge_data), f)\n",
    "\n",
    "    def load_faiss_index(self):\n",
    "        if os.path.exists(self.faiss_index_file):\n",
    "            with open(self.faiss_index_file, 'rb') as f:\n",
    "                self.index, self.knowledge_data = pickle.load(f)\n",
    "        else:\n",
    "            self.index = None\n",
    "            self.knowledge_data = []\n",
    "\n",
    "def main():\n",
    "    # enriched_links_path = \"enriched_filtered_captions_to_chunks_mapping_hands.json\"\n",
    "    # all_chunks_path = \"processed_json/stabilizer pressure control_chunks.json\"\n",
    "    enriched_links_path = \"enriched_filtered_captions_to_chunks_mapping_hands_machine_cover_2.json\"\n",
    "    all_chunks_path = \"processed_json_machine_cover_2/machine_cover_2_chunks.json\"\n",
    "\n",
    "    if not os.path.exists(enriched_links_path):\n",
    "        print(f\"Bestand '{enriched_links_path}' bestaat niet.\")\n",
    "        return\n",
    "    if not os.path.exists(all_chunks_path):\n",
    "        print(f\"Bestand '{all_chunks_path}' bestaat niet.\")\n",
    "        return\n",
    "\n",
    "    with open(enriched_links_path, 'r', encoding='utf-8') as f:\n",
    "        enriched_links = json.load(f)\n",
    "\n",
    "    with open(all_chunks_path, 'r', encoding='utf-8') as f:\n",
    "        chunk_data = json.load(f)\n",
    "    all_chunks = chunk_data.get(\"chunks\", [])\n",
    "\n",
    "    print(f\"{len(all_chunks)} chunks geladen.\")\n",
    "    print(f\"{len(enriched_links)} verrijkte caption-links geladen.\")\n",
    "\n",
    "    enrichment_map = {item.get(\"linked_chunk_id\", \"\"): item for item in enriched_links if item.get(\"linked_chunk_id\")}\n",
    "\n",
    "    chatbot = Chatbot()\n",
    "\n",
    "    for i, chunk in enumerate(all_chunks, start=1):\n",
    "        chunk_text = chunk.get(\"text\", \"\").strip()\n",
    "        start_time = chunk.get(\"start\")\n",
    "        end_time = chunk.get(\"end\")\n",
    "        chunk_id = f\"{start_time}_{end_time}\"\n",
    "\n",
    "        if not chunk_text:\n",
    "            print(f\"Skipping lege chunk {chunk_id}\")\n",
    "            continue\n",
    "\n",
    "        enrichment = enrichment_map.get(chunk_id)\n",
    "\n",
    "        if enrichment:\n",
    "            relations = [\n",
    "                f\"{l['class_name']} → {l['action_label']}\"\n",
    "                for l in enrichment.get(\"object_action_links\", [])\n",
    "            ]\n",
    "            unique_hand_contacts = set(\n",
    "                h.get(\"class_name\", \"\").strip()\n",
    "                for h in enrichment.get(\"hand_object_links\", [])\n",
    "                if h.get(\"class_name\", \"\").strip()\n",
    "            )\n",
    "            hand_object_contacts = sorted(unique_hand_contacts)\n",
    "\n",
    "            combined_input = (\n",
    "                f\"Transcript: {chunk_text}\\n\"\n",
    "                f\"Linked object-action pairs: {', '.join(relations)}\\n\"\n",
    "                f\"Hand-object interactions: {', '.join(hand_object_contacts)}\"\n",
    "            )\n",
    "        else:\n",
    "            combined_input = f\"Transcript: {chunk_text}\"\n",
    "\n",
    "        print(f\"\\n[{i}] Extracting knowledge for chunk {chunk_id}\")\n",
    "        print(combined_input)\n",
    "\n",
    "        extracted_knowledge = chatbot.extract_valuable_knowledge(combined_input)\n",
    "\n",
    "        if extracted_knowledge:\n",
    "            for triplet in extracted_knowledge:\n",
    "                triplet[\"start\"] = start_time\n",
    "                triplet[\"end\"] = end_time\n",
    "            chatbot.save_knowledge(extracted_knowledge)\n",
    "\n",
    "    print(\"\\nKennisextractie afgerond. Bekijk 'knowledge.json' voor de resultaten.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5826d378",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Totaal uitgevoerde tijd: {elapsed_time:.2f} seconden\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3d3dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"PyTorch versie: {torch.__version__}\")\n",
    "print(f\"CUDA beschikbaar: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA versie: {torch.version.cuda}\")\n",
    "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feebab49",
   "metadata": {},
   "source": [
    "## Test generated knowledge base with LLM with the integrated knowledge base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d181ba83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from llama_cpp import Llama\n",
    "import threading\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "from json import JSONDecodeError\n",
    "\n",
    "class LlamaSingleton:\n",
    "    _instance = None\n",
    "    _lock = threading.Lock()\n",
    "\n",
    "    def __new__(cls, model_path=\"models/Qwen2.5-7B-Instruct-Q4_K_M.gguf\", chat_format=\"chatml\"):\n",
    "        with cls._lock:\n",
    "            if cls._instance is None:\n",
    "                cls._instance = super(LlamaSingleton, cls).__new__(cls)\n",
    "                cls._instance.llm = Llama(model_path=model_path, chat_format=chat_format, n_ctx=2048)\n",
    "            return cls._instance\n",
    "\n",
    "class Chatbot:\n",
    "    def __init__(self, \n",
    "                 messages_file='messages.json', \n",
    "                 knowledge_file='knowledge.json', \n",
    "                 faiss_index_file='faiss_index.pkl',\n",
    "                 model_name='all-MiniLM-L6-v2'):\n",
    "        self.messages_file = messages_file\n",
    "        self.knowledge_file = knowledge_file\n",
    "        self.faiss_index_file = faiss_index_file\n",
    "        self.llm = LlamaSingleton().llm\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.index = None\n",
    "        self.knowledge_data = []\n",
    "        self.initialize_files()\n",
    "        self.load_faiss_index()\n",
    "\n",
    "    def initialize_files(self):\n",
    "        for file in [self.messages_file, self.knowledge_file]:\n",
    "            if not os.path.exists(file):\n",
    "                with open(file, 'w') as f:\n",
    "                    json.dump([], f)\n",
    "\n",
    "    def load_json_data(self, file_path):\n",
    "        with open(file_path, 'r') as f:\n",
    "            return json.load(f)\n",
    "\n",
    "    def save_json_data(self, file_path, data):\n",
    "        with open(file_path, 'w') as f:\n",
    "            json.dump(data, f, indent=4)\n",
    "\n",
    "    def save_message(self, role, content):\n",
    "        messages = self.load_json_data(self.messages_file)\n",
    "        message = {\"role\": role, \"content\": content, \"timestamp\": datetime.utcnow().isoformat()}\n",
    "        messages.append(message)\n",
    "        self.save_json_data(self.messages_file, messages)\n",
    "\n",
    "    def save_knowledge(self, triplets):\n",
    "        if not triplets:\n",
    "            return\n",
    "        knowledge = self.load_json_data(self.knowledge_file)\n",
    "        existing_set = {(t['subject'], t['predicate'], t['object']) for t in knowledge}\n",
    "        new_triplets = []\n",
    "        for triplet in triplets:\n",
    "            triplet['timestamp'] = datetime.utcnow().isoformat()\n",
    "            key = (triplet['subject'], triplet['predicate'], triplet['object'])\n",
    "            if key not in existing_set:\n",
    "                knowledge.append(triplet)\n",
    "                new_triplets.append(triplet)\n",
    "                existing_set.add(key)\n",
    "        self.save_json_data(self.knowledge_file, knowledge)\n",
    "        if new_triplets:\n",
    "            self.update_faiss_index(new_triplets)\n",
    "\n",
    "    def update_faiss_index(self, triplets):\n",
    "        texts = [f\"{t['subject']} {t['predicate']} {t['object']}\" for t in triplets]\n",
    "        embeddings = self.model.encode(texts)\n",
    "        if self.index is None:\n",
    "            self.index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "        self.index.add(np.array(embeddings, dtype=np.float32))\n",
    "        self.knowledge_data.extend(triplets)\n",
    "        self.save_faiss_index()\n",
    "\n",
    "    def save_faiss_index(self):\n",
    "        with open(self.faiss_index_file, 'wb') as f:\n",
    "            pickle.dump((self.index, self.knowledge_data), f)\n",
    "\n",
    "    def load_faiss_index(self):\n",
    "        if os.path.exists(self.faiss_index_file):\n",
    "            with open(self.faiss_index_file, 'rb') as f:\n",
    "                self.index, self.knowledge_data = pickle.load(f)\n",
    "        else:\n",
    "            self.index = None\n",
    "            self.knowledge_data = []\n",
    "\n",
    "    def search_knowledge(self, query, top_k=5):\n",
    "        if self.index is None or len(self.knowledge_data) == 0:\n",
    "            return []\n",
    "        query_embedding = self.model.encode([query])\n",
    "        distances, indices = self.index.search(np.array(query_embedding, dtype=np.float32), top_k)\n",
    "        results = []\n",
    "        for idx in indices[0]:\n",
    "            if idx == -1:\n",
    "                continue\n",
    "            results.append(self.knowledge_data[idx])\n",
    "        return results\n",
    "\n",
    "    # this function generates a response based on the conversation history and user message and the knowledge top k 5 matches\n",
    "    def generate_response(self, conversation_history, user_message):\n",
    "        knowledge_matches = self.search_knowledge(user_message, top_k=5)\n",
    "        current_time = datetime.utcnow().isoformat()\n",
    "        system_message = f\"Current date and time: {current_time}\\n\"\n",
    "        if knowledge_matches:\n",
    "            system_message += \"Answer based on retrieved knowledge:\\n\"\n",
    "            for t in knowledge_matches:\n",
    "                system_message += f\"- {t['subject']} {t['predicate']} {t['object']} (Videotimestamps: start: {t['start']}, end: {t['end']})\\n\"\n",
    "            \n",
    "        else:\n",
    "            system_message += \"No direct related knowledge found. Proceeding with general reasoning.\\n\"\n",
    "        enriched_history = [{\"role\": \"system\", \"content\": f\"You are a helpful assistent; {system_message}\"}] #+ conversation_history\n",
    "        enriched_history.append({\"role\": \"user\", \"content\": user_message})\n",
    "        print(enriched_history)\n",
    "        response = self.llm.create_chat_completion(\n",
    "            messages=enriched_history,\n",
    "            temperature=0.7,\n",
    "        )['choices'][0]['message']['content']\n",
    "        return response\n",
    "\n",
    "    def chat(self):\n",
    "        print(\"Chatbot is ready! Type 'exit' to end the conversation.\")\n",
    "        while True:\n",
    "            user_message = input(\"You: \")\n",
    "            if user_message.lower().strip() in ['exit', 'quit']:\n",
    "                print(\"Chatbot: Goodbye!\")\n",
    "                break\n",
    "            self.save_message(role='user', content=user_message)\n",
    "            conversation = self.load_json_data(self.messages_file)[-3:]\n",
    "            assistant_response = self.generate_response(conversation, user_message)\n",
    "            print(f\"Assistant: {assistant_response}\")\n",
    "            self.save_message(role='assistant', content=assistant_response)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    chatbot = Chatbot()\n",
    "    chatbot.chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629b00df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # somting\n",
    "# if enrichment:\n",
    "#             caption = enrichment.get(\"caption\", \"\").strip()\n",
    "#             object_classes = [o.get(\"class_name\", \"\") for o in enrichment.get(\"object_detections\", [])]\n",
    "#             action_labels = [a.get(\"label\", \"\") for a in enrichment.get(\"actions\", [])]\n",
    "            \n",
    "#             # Pas de linked object-action pairs correct aan\n",
    "#             relations = []\n",
    "#             for link in enrichment.get(\"object_action_links\", []):\n",
    "#                 object_name = link.get(\"class_name\", \"\").strip()\n",
    "#                 action_label = link.get(\"action_label\", \"\").strip()\n",
    "\n",
    "#                 # Check of de action_label eindigt op \"something\" en pas dan aan\n",
    "#                 if \"something\" in action_label.lower():\n",
    "#                     # Verwijder \"something\" uit de action label en voeg objectnaam toe\n",
    "#                     new_action = action_label.lower().replace(\"something\", object_name)\n",
    "#                     new_action = new_action.strip()\n",
    "#                     # Maak eerste letter hoofdletter als origineel dat ook was\n",
    "#                     if action_label and action_label[0].isupper():\n",
    "#                         new_action = new_action.capitalize()\n",
    "#                     relations.append(new_action)\n",
    "#                 else:\n",
    "#                     relations.append(f\"{object_name} → {action_label}\")\n",
    "\n",
    "#             unique_hand_contacts = set(\n",
    "#                 f\"{h['class_name']} ({h['contact_type']})\"\n",
    "#                 for h in enrichment.get(\"hand_object_links\", [])\n",
    "#             )\n",
    "#             hand_object_contacts = sorted(unique_hand_contacts)\n",
    "\n",
    "#             combined_input = (\n",
    "#                 f\"Transcript: {chunk_text}\\n\"\n",
    "#                 f\"Caption: {caption}\\n\"\n",
    "#                 #f\"Objects in scene: {', '.join(object_classes)}\\n\"\n",
    "#                 #f\"Detected actions: {', '.join(action_labels)}\\n\"\n",
    "#                 f\"Linked object-action pairs: {', '.join(relations)}\\n\"\n",
    "#                 f\"Hand-object interactions: {', '.join(hand_object_contacts)}\"\n",
    "#             )\n",
    "#         else:\n",
    "#             combined_input = f\"Transcript: {chunk_text}\"\n",
    "\n",
    "#         print(f\"\\n[{i}] Extracting knowledge for chunk {chunk_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caeaa990",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16bc8483",
   "metadata": {},
   "source": [
    "## Extra controls voor de triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702a598a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import threading\n",
    "from llama_cpp import Llama\n",
    "\n",
    "class LlamaSingleton:\n",
    "    _instance = None\n",
    "    _lock = threading.Lock()\n",
    "\n",
    "    def __new__(cls, model_path=\"models/Qwen2.5-7B-Instruct-Q4_K_M.gguf\", chat_format=\"chatml\"):\n",
    "        with cls._lock:\n",
    "            if cls._instance is None:\n",
    "                cls._instance = super().__new__(cls)\n",
    "                cls._instance.llm = Llama(model_path=model_path, chat_format=chat_format, n_ctx=2048)\n",
    "            return cls._instance\n",
    "\n",
    "\n",
    "class VIDAR:\n",
    "    def __init__(self, output_file=\"vidar_memory_machine_cover_2_prompt.json\"):\n",
    "        self.llm = LlamaSingleton().llm\n",
    "        self.output_file = output_file\n",
    "        self.memory = []\n",
    "        self._load_memory()\n",
    "\n",
    "    def _load_memory(self):\n",
    "        if os.path.exists(self.output_file):\n",
    "            with open(self.output_file, \"r\", encoding=\"utf-8\") as f:\n",
    "                self.memory = json.load(f)\n",
    "\n",
    "    def _save_memory(self):\n",
    "        with open(self.output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(self.memory, f, indent=2)\n",
    "\n",
    "    # def run_vidar_cycle(self, chunk_id, transcript, relations, hand_contacts):\n",
    "    #     observations = f\"Transcript: {transcript}\\n\" \\\n",
    "    #                    f\"Linked object-action pairs: {', '.join(relations)}\\n\" \\\n",
    "    #                    f\"Hand-object interactions: {', '.join(hand_contacts)}\"\n",
    "\n",
    "    #     messages = [\n",
    "    #         {\"role\": \"system\", \"content\": (\n",
    "    #             # \"You are VIDAR, a reasoning entity. Analyze the following observations from a scene. \"\n",
    "    #             # \"First, hypothesize what is happening, then reflect on what is uncertain. \"\n",
    "    #             # \"Return a JSON with keys: hypothesis, reasoning, doubts (list), knowledge (triplets). \"\n",
    "    #             # \"Each triplet has subject, predicate, object.\"\n",
    "    #             \"You are VIDAR, a reasoning entity. Analyze the following scene observations. \" \\\n",
    "    #             \"First, formulate a plausible hypothesis about what is occurring. \" \\\n",
    "    #             \"Then, reflect on uncertainties in the observations. \" \\\n",
    "    #             \"Respond in JSON format with the following keys: hypothesis (main interpretation), reasoning (explanation), doubts (list of unclear or ambiguous elements), knowledge (list of factual triplets). \" \\\n",
    "    #             \"Each triplet must be structured as: subject, predicate, object.\"\n",
    "    #         )},\n",
    "    #         {\"role\": \"user\", \"content\": observations}\n",
    "    #     ]\n",
    "\n",
    "    #     print(f\"\\nReasoning on chunk {chunk_id}...\")\n",
    "    #     print(observations)\n",
    "\n",
    "    #     try:\n",
    "    #         response = self.llm.create_chat_completion(\n",
    "    #             messages=messages,\n",
    "    #             temperature=0.6\n",
    "    #         )\n",
    "    #         content = response['choices'][0]['message']['content'].strip()\n",
    "\n",
    "    #         # Verwijder eventuele Markdown-codeblokken\n",
    "    #         if content.startswith(\"```json\"):\n",
    "    #             content = content[7:].strip()\n",
    "    #         if content.endswith(\"```\"):\n",
    "    #             content = content[:-3].strip()\n",
    "\n",
    "    #         # Escape line breaks binnen de \"reasoning\" waarde\n",
    "    #         import re\n",
    "    #         def escape_reasoning_block(match):\n",
    "    #             inner = match.group(2).replace('\\n', '\\\\n')\n",
    "    #             return f'{match.group(1)}{inner}\"'\n",
    "    #         content = re.sub(\n",
    "    #             r'(\"reasoning\"\\s*:\\s*\")([^\"]*?)(?<!\\\\)\"',\n",
    "    #             escape_reasoning_block,\n",
    "    #             content,\n",
    "    #             flags=re.DOTALL\n",
    "    #         )\n",
    "\n",
    "    #         try:\n",
    "    #             parsed = json.loads(content)\n",
    "    #         except json.JSONDecodeError as json_err:\n",
    "    #             print(f\"JSON decode error in chunk {chunk_id}: {json_err}\")\n",
    "    #             print(\"Response content was:\\n\", content)\n",
    "    #             return\n",
    "\n",
    "    #         self.memory.append({\n",
    "    #             \"chunk_id\": chunk_id,\n",
    "    #             \"observations\": observations,\n",
    "    #             \"hypothesis\": parsed.get(\"hypothesis\", \"\"),\n",
    "    #             \"reasoning\": parsed.get(\"reasoning\", \"\"),\n",
    "    #             \"doubts\": parsed.get(\"doubts\", []),\n",
    "    #             \"knowledge\": parsed.get(\"knowledge\", [])\n",
    "    #         })\n",
    "\n",
    "    #         self._save_memory()\n",
    "\n",
    "    #     except Exception as e:\n",
    "    #         print(f\"Failed to process chunk {chunk_id}: {e}\")\n",
    "\n",
    "    def run_vidar_cycle(self, chunk_id, transcript, relations, hand_contacts, caption_text):\n",
    "        observations = f\"Transcript: {transcript}\\n\" \\\n",
    "                        f\"Captions: {caption_text}\" \\\n",
    "                        # f\"Linked object-action pairs: {', '.join(relations)}\\n\" \\\n",
    "                        # f\"Hand-object interactions: {', '.join(hand_contacts)}\" \\\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": (\n",
    "                \"You are VIDAR, a reasoning entity. Analyze the following observations from a scene. \"\n",
    "                \"First, hypothesize what is happening, then reflect on what is uncertain. \"\n",
    "                \"Return a JSON with keys: hypothesis, reasoning, doubts (list), knowledge (triplets). \"\n",
    "                \"Each triplet has subject, predicate, object.\"\n",
    "            )},\n",
    "            {\"role\": \"user\", \"content\": observations}\n",
    "        ]\n",
    "\n",
    "        print(f\"\\nReasoning on chunk {chunk_id}...\")\n",
    "        print(observations)\n",
    "\n",
    "        try:\n",
    "            response = self.llm.create_chat_completion(\n",
    "                messages=messages,\n",
    "                response_format={\n",
    "                    \"type\": \"json\",\n",
    "                    \"schema\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"hypothesis\": {\"type\": \"string\"},\n",
    "                            \"reasoning\": {\"type\": \"string\"},\n",
    "                            \"doubts\": {\n",
    "                                \"type\": \"array\",\n",
    "                                \"items\": {\"type\": \"string\"}\n",
    "                            },\n",
    "                            \"knowledge\": {\n",
    "                                \"type\": \"array\",\n",
    "                                \"items\": {\n",
    "                                    \"type\": \"object\",\n",
    "                                    \"properties\": {\n",
    "                                        \"subject\": {\"type\": \"string\"},\n",
    "                                        \"predicate\": {\"type\": \"string\"},\n",
    "                                        \"object\": {\"type\": \"string\"}\n",
    "                                    },\n",
    "                                    \"required\": [\"subject\", \"predicate\", \"object\"]\n",
    "                                }\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"hypothesis\", \"reasoning\", \"doubts\", \"knowledge\"]\n",
    "                    }\n",
    "                },\n",
    "                temperature=0.6\n",
    "            )\n",
    "\n",
    "            content = response['choices'][0]['message']['content'].strip()\n",
    "\n",
    "            if content.startswith(\"```json\"):\n",
    "                content = content[7:].strip()\n",
    "            if content.endswith(\"```\"):\n",
    "                content = content[:-3].strip()\n",
    "\n",
    "            parsed = json.loads(content)\n",
    "\n",
    "            self.memory.append({\n",
    "                \"chunk_id\": chunk_id,\n",
    "                \"observations\": observations,\n",
    "                \"hypothesis\": parsed.get(\"hypothesis\", \"\"),\n",
    "                \"reasoning\": parsed.get(\"reasoning\", \"\"),\n",
    "                \"doubts\": parsed.get(\"doubts\", []),\n",
    "                \"knowledge\": parsed.get(\"knowledge\", [])\n",
    "            })\n",
    "            self._save_memory()\n",
    "\n",
    "        except (json.JSONDecodeError, KeyError) as e:\n",
    "            print(f\"JSON parsing error in chunk {chunk_id}: {e}\")\n",
    "            print(\"Model response:\\n\", response)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process chunk {chunk_id}: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    chunks_path = \"processed_json_machine_cover_2/machine_cover_2_chunks.json\"\n",
    "    enrichment_path = \"enriched_filtered_captions_to_chunks_mapping_hands_machine_cover_2.json\"\n",
    "\n",
    "    if not os.path.exists(chunks_path):\n",
    "        print(f\"Bestand '{chunks_path}' niet gevonden.\")\n",
    "        return\n",
    "\n",
    "    with open(chunks_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        chunks_data = json.load(f).get(\"chunks\", [])\n",
    "\n",
    "    enrichment_map = {}\n",
    "    if os.path.exists(enrichment_path):\n",
    "        with open(enrichment_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            enriched = json.load(f)\n",
    "        for item in enriched:\n",
    "            chunk_id = item.get(\"linked_chunk_id\")\n",
    "            if chunk_id:\n",
    "                # Bewaar alleen de eerste match per chunk_id\n",
    "                if chunk_id not in enrichment_map:\n",
    "                    enrichment_map[chunk_id] = item\n",
    "\n",
    "    caption_map = {}\n",
    "    with open(enrichment_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        enriched = json.load(f)\n",
    "    for item in enriched:\n",
    "        chunk_id = item.get(\"linked_chunk_id\")\n",
    "        caption = item.get(\"caption\")\n",
    "        if chunk_id and caption:\n",
    "            if chunk_id not in caption_map:\n",
    "                caption_map[chunk_id] = []\n",
    "            caption_map[chunk_id].append(caption)\n",
    "\n",
    "    vidar = VIDAR()\n",
    "\n",
    "    for chunk in chunks_data:\n",
    "        start = chunk.get(\"start\")\n",
    "        end = chunk.get(\"end\")\n",
    "        transcript = chunk.get(\"text\", \"\").strip()\n",
    "        chunk_id = f\"{start}_{end}\"\n",
    "\n",
    "        if not transcript:\n",
    "            print(f\"⏭ Skip: Lege transcript in chunk {chunk_id}\")\n",
    "            continue\n",
    "\n",
    "        enrichment = enrichment_map.get(chunk_id, {})\n",
    "        relations = [\n",
    "            f\"{l['class_name']} → {l['action_label']}\"\n",
    "            for l in enrichment.get(\"object_action_links\", [])\n",
    "        ]\n",
    "        hand_contacts = sorted({\n",
    "            h.get(\"class_name\", \"\").strip()\n",
    "            for h in enrichment.get(\"hand_object_links\", [])\n",
    "            if h.get(\"class_name\", \"\").strip()\n",
    "        })\n",
    "        captions = caption_map.get(chunk_id, [])\n",
    "        if captions:\n",
    "            caption_text = \"\\n\".join([f\"- {c}\" for c in captions])\n",
    "        else:\n",
    "            caption_text = \"\"\n",
    "        # hand_contacts = sorted({\n",
    "        #     f\"{h.get('class_name', '').strip()} ({h.get('contact_type')})\"\n",
    "        #     for h in enrichment.get(\"hand_object_links\", [])\n",
    "        #     if h.get(\"class_name\") and h.get(\"contact_type\")\n",
    "        # })\n",
    "\n",
    "        vidar.run_vidar_cycle(chunk_id, transcript, relations, hand_contacts, caption_text)\n",
    "\n",
    "    print(\"\\n Reasoning compleet. Resultaten in 'vidar_memory.json'.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed86c706",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a144143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import json\n",
    "# import threading\n",
    "# from llama_cpp import Llama\n",
    "\n",
    "# # Singleton voor je lokale LLaMA-model\n",
    "# class LlamaSingleton:\n",
    "#     _instance = None\n",
    "#     _lock = threading.Lock()\n",
    "\n",
    "#     def __new__(cls, model_path=\"models/Qwen2.5-7B-Instruct-Q4_K_M.gguf\", chat_format=\"chatml\"):\n",
    "#         with cls._lock:\n",
    "#             if cls._instance is None:\n",
    "#                 cls._instance = super().__new__(cls)\n",
    "#                 cls._instance.llm = Llama(model_path=model_path, chat_format=chat_format, n_ctx=2048)\n",
    "#             return cls._instance\n",
    "\n",
    "\n",
    "# class VIDAR:\n",
    "#     def __init__(self, output_file=\"vidar_memory.json\"):\n",
    "#         self.llm = LlamaSingleton().llm\n",
    "#         self.output_file = output_file\n",
    "#         self.memory = []\n",
    "#         self._load_memory()\n",
    "\n",
    "#     def _load_memory(self):\n",
    "#         if os.path.exists(self.output_file):\n",
    "#             with open(self.output_file, \"r\", encoding=\"utf-8\") as f:\n",
    "#                 self.memory = json.load(f)\n",
    "\n",
    "#     def _save_memory(self):\n",
    "#         with open(self.output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "#             json.dump(self.memory, f, indent=2)\n",
    "\n",
    "#     def run_vidar_cycle(self, chunk_id, transcript, relations, hand_contacts):\n",
    "#         observations = f\"Transcript: {transcript}\\n\" \\\n",
    "#                        f\"Linked object-action pairs: {', '.join(relations)}\\n\" \\\n",
    "#                        f\"Hand-object interactions: {', '.join(hand_contacts)}\"\n",
    "\n",
    "#         messages = [\n",
    "#             {\"role\": \"system\", \"content\": (\n",
    "#                 \"You are VIDAR, a reasoning entity. Analyze the following observations from a scene. \"\n",
    "#                 \"First, hypothesize what is happening, then reflect on what is uncertain. \"\n",
    "#                 \"Return a JSON with keys: hypothesis, reasoning, doubts (list), knowledge (triplets). \"\n",
    "#                 \"Each triplet has subject, predicate, object.\"\n",
    "#             )},\n",
    "#             {\"role\": \"user\", \"content\": observations}\n",
    "#         ]\n",
    "\n",
    "#         print(f\"\\nReasoning on chunk {chunk_id}...\")\n",
    "#         print(observations)\n",
    "\n",
    "#         try:\n",
    "#             response = self.llm.create_chat_completion(\n",
    "#                 messages=messages,\n",
    "#                 temperature=0.6\n",
    "#             )\n",
    "#             content = response['choices'][0]['message']['content'].strip()\n",
    "#             if content.startswith(\"```json\"):\n",
    "#                 content = content[7:]\n",
    "#             if content.endswith(\"```\"):\n",
    "#                 content = content[:-3]\n",
    "#             parsed = json.loads(content)\n",
    "\n",
    "#             self.memory.append({\n",
    "#                 \"chunk_id\": chunk_id,\n",
    "#                 \"observations\": observations,\n",
    "#                 \"hypothesis\": parsed.get(\"hypothesis\", \"\"),\n",
    "#                 \"reasoning\": parsed.get(\"reasoning\", \"\"),\n",
    "#                 \"doubts\": parsed.get(\"doubts\", []),\n",
    "#                 \"knowledge\": parsed.get(\"knowledge\", [])\n",
    "#             })\n",
    "\n",
    "#             self._save_memory()\n",
    "\n",
    "#         except Exception as e:\n",
    "#             print(f\"Failed to process chunk {chunk_id}: {e}\")\n",
    "\n",
    "\n",
    "# def main():\n",
    "#     input_file = \"enriched_filtered_captions_to_chunks_mapping_hands.json\"\n",
    "#     if not os.path.exists(input_file):\n",
    "#         print(f\"Inputbestand '{input_file}' niet gevonden.\")\n",
    "#         return\n",
    "\n",
    "#     with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "#         data = json.load(f)\n",
    "\n",
    "#     vidar = VIDAR()\n",
    "\n",
    "#     for i, item in enumerate(data, start=1):\n",
    "#         chunk_id = item.get(\"linked_chunk_id\")\n",
    "#         if not chunk_id:\n",
    "#             print(f\"⏭ Skip: geen chunk ID in item {i}\")\n",
    "#             continue\n",
    "\n",
    "#         transcript = item.get(\"linked_chunk_text\", \"\").strip()\n",
    "#         if not transcript:\n",
    "#             print(f\"⏭ Skip: lege transcript in chunk {chunk_id}\")\n",
    "#             continue\n",
    "\n",
    "#         relations = [\n",
    "#             f\"{l['class_name']} → {l['action_label']}\"\n",
    "#             for l in item.get(\"object_action_links\", [])\n",
    "#         ]\n",
    "#         hand_contacts = sorted({\n",
    "#             h.get(\"class_name\", \"\").strip()\n",
    "#             for h in item.get(\"hand_object_links\", [])\n",
    "#             if h.get(\"class_name\", \"\").strip()\n",
    "#         })\n",
    "\n",
    "#         vidar.run_vidar_cycle(chunk_id, transcript, relations, hand_contacts)\n",
    "\n",
    "#     print(\"\\nVIDAR reasoning voltooid. Resultaat opgeslagen in 'vidar_memory.json'.\")\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea4ea90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "def load_vidar_memory(path=\"vidar_memory_machine_cover_2_prompt.json\"):\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"Bestand '{path}' bestaat niet.\")\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def convert_to_knowledge_format(vidar_chunks):\n",
    "    knowledge_triplets = []\n",
    "    empty_count = 0\n",
    "\n",
    "    for entry in vidar_chunks:\n",
    "        chunk_id = entry.get(\"chunk_id\", \"\")\n",
    "        start, end = chunk_id.split(\"_\") if \"_\" in chunk_id else (None, None)\n",
    "\n",
    "        knowledge = entry.get(\"knowledge\", [])\n",
    "\n",
    "        # Case 1: dict with \"triplets\" key (correct VIDAR structure)\n",
    "        if isinstance(knowledge, dict) and \"triplets\" in knowledge:\n",
    "            triplets_raw = knowledge[\"triplets\"]\n",
    "        # Case 2: already a list of triplets\n",
    "        elif isinstance(knowledge, list):\n",
    "            triplets_raw = knowledge\n",
    "        else:\n",
    "            triplets_raw = []\n",
    "\n",
    "        if not triplets_raw:\n",
    "            empty_count += 1\n",
    "            continue\n",
    "\n",
    "        for triplet in triplets_raw:\n",
    "            if isinstance(triplet, list) and len(triplet) == 3:\n",
    "                subj, pred, obj = triplet\n",
    "            elif isinstance(triplet, dict) and all(k in triplet for k in [\"subject\", \"predicate\", \"object\"]):\n",
    "                subj, pred, obj = triplet[\"subject\"], triplet[\"predicate\"], triplet[\"object\"]\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            knowledge_triplets.append({\n",
    "                \"subject\": subj,\n",
    "                \"predicate\": pred,\n",
    "                \"object\": obj,\n",
    "                \"start\": float(start) if start else None,\n",
    "                \"end\": float(end) if end else None\n",
    "            })\n",
    "\n",
    "    print(f\"{len(vidar_chunks)} chunks gevonden.\")\n",
    "    print(f\"{empty_count} chunks bevatten GEEN knowledge-triplets.\")\n",
    "    print(f\"{len(knowledge_triplets)} triplets geëxtraheerd.\")\n",
    "    return knowledge_triplets\n",
    "\n",
    "\n",
    "\n",
    "def save_json(data, path):\n",
    "    with open(path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "    print(f\"JSON opgeslagen als '{path}'.\")\n",
    "\n",
    "def build_faiss_index(triplets, model_name='all-MiniLM-L6-v2', index_path='faiss_index.pkl'):\n",
    "    print(\"FAISS-index bouwen...\")\n",
    "    model = SentenceTransformer(model_name)\n",
    "    texts = [f\"{t['subject']} {t['predicate']} {t['object']}\" for t in triplets]\n",
    "    embeddings = model.encode(texts)\n",
    "\n",
    "    index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "    index.add(np.array(embeddings, dtype=np.float32))\n",
    "\n",
    "    with open(index_path, 'wb') as f:\n",
    "        pickle.dump((index, triplets), f)\n",
    "    print(f\"FAISS index opgeslagen als '{index_path}'.\")\n",
    "\n",
    "def main():\n",
    "    vidar_path = \"vidar_memory_machine_cover_2_prompt.json\"\n",
    "    knowledge_path = \"knowledge_vidar_machine_cover_2_prompt.json\"\n",
    "    faiss_path = \"faiss_index_vidar_machine_cover_2_prompt.pkl\"\n",
    "\n",
    "    print(\"Converteer VIDAR-output naar knowledge-formaat...\")\n",
    "    vidar_data = load_vidar_memory(vidar_path)\n",
    "    triplets = convert_to_knowledge_format(vidar_data)\n",
    "\n",
    "    save_json(triplets, knowledge_path)\n",
    "    build_faiss_index(triplets, model_name='all-MiniLM-L6-v2', index_path=faiss_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def84d41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdb7e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import threading\n",
    "from llama_cpp import Llama\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "from json import JSONDecodeError\n",
    "\n",
    "class LlamaSingleton:\n",
    "    _instance = None\n",
    "    _lock = threading.Lock()\n",
    "\n",
    "    def __new__(cls, model_path=\"models/Qwen2.5-7B-Instruct-Q4_K_M.gguf\", chat_format=\"chatml\"):\n",
    "        with cls._lock:\n",
    "            if cls._instance is None:\n",
    "                cls._instance = super(LlamaSingleton, cls).__new__(cls)\n",
    "                cls._instance.llm = Llama(model_path=model_path, chat_format=chat_format, n_ctx=2048)\n",
    "            return cls._instance\n",
    "\n",
    "class Chatbot:\n",
    "    def __init__(self, \n",
    "                 messages_file='messages.json', \n",
    "                 knowledge_file='knowledge.json', \n",
    "                 faiss_index_file='faiss_index.pkl',\n",
    "                 model_name='all-MiniLM-L6-v2'):\n",
    "        self.messages_file = messages_file\n",
    "        self.knowledge_file = knowledge_file\n",
    "        self.faiss_index_file = faiss_index_file\n",
    "        self.llm = LlamaSingleton().llm\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.index = None\n",
    "        self.knowledge_data = []\n",
    "        self.initialize_files()\n",
    "        self.load_faiss_index()\n",
    "\n",
    "    def initialize_files(self):\n",
    "        for file in [self.messages_file, self.knowledge_file]:\n",
    "            if not os.path.exists(file):\n",
    "                with open(file, 'w') as f:\n",
    "                    json.dump([], f)\n",
    "\n",
    "    def load_json_data(self, file_path):\n",
    "        with open(file_path, 'r') as f:\n",
    "            return json.load(f)\n",
    "\n",
    "    def save_json_data(self, file_path, data):\n",
    "        with open(file_path, 'w') as f:\n",
    "            json.dump(data, f, indent=4)\n",
    "\n",
    "    def extract_valuable_knowledge(self, message):\n",
    "        response = self.llm.create_chat_completion(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": (\n",
    "                        \"You are a knowledge extractor. Extract subject-predicate-object knowledge triplets \"\n",
    "                        \"from all the provided information: transcript, linked object-action pairs and hand-object interactions.\\n\"\n",
    "                        \"Correct example: { \\\"subject\\\": \\\"person\\\", \\\"predicate\\\": \\\"holds\\\", \\\"object\\\": \\\"cup\\\" }\\n\"\n",
    "                        \"Incorrect example: { \\\"subject\\\": \\\"he\\\", \\\"predicate\\\": \\\"does\\\", \\\"object\\\": \\\"it\\\" }\\n\"\n",
    "                        # \"Return ONLY a JSON object like: {\\\"valuable_knowledge\\\": [ ... ]}\\n\"\n",
    "                        \"If no knowledge can be extracted, return: {\\\"valuable_knowledge\\\": []}\"\n",
    "                        # \"You are a knowledge extractor. Extract subject-predicate-object knowledge triplets \\n\" # WEGHALEN\n",
    "                        # \"from all the provided information: transcript, linked object-action pairs and hand-object interactions.\\n\" # WEGHALEN\n",
    "                        # \"\"\"Correct example: { \"subject\": \"person\", \"predicate\": \"holds\", \"object\": \"cup\" }Incorrect example: { \"subject\": \"he\", \"predicate\": \"does\", \"object\": \"it\" }\"\"\"\n",
    "                        # # \"Return ONLY JSON with the following schema:\\n\"\n",
    "                        # # \"{\\n\"\n",
    "                        # # \"  \\\"valuable_knowledge\\\": [\\n\"\n",
    "                        # # \"    {\\n\"\n",
    "                        # # \"      \\\"subject\\\": \\\"...\\\",\\n\"\n",
    "                        # # \"      \\\"predicate\\\": \\\"...\\\",\\n\"\n",
    "                        # # \"      \\\"object\\\": \\\"...\\\"\\n\"\n",
    "                        # # \"    }\\n\"\n",
    "                        # # \"  ]\\n\"\n",
    "                        # # \"}\\n\"\n",
    "                        # \"If no knowledge can be extracted, return:\\n\"\n",
    "                        # \"{\\\"valuable_knowledge\\\": []}\"\n",
    "                    )\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": message},\n",
    "            ],\n",
    "            temperature=0.5,\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            response_content = response['choices'][0]['message']['content'].strip()\n",
    "\n",
    "            # Verwijder markdown-codeblokken\n",
    "            if response_content.startswith(\"```json\"):\n",
    "                response_content = response_content[7:]\n",
    "            if response_content.endswith(\"```\"):\n",
    "                response_content = response_content[:-3]\n",
    "\n",
    "            parsed = json.loads(response_content)\n",
    "\n",
    "            if isinstance(parsed, list):\n",
    "                print(\"Model returned a list instead of expected object. Wrapping it.\")\n",
    "                parsed = {\"valuable_knowledge\": parsed}\n",
    "\n",
    "            if \"valuable_knowledge\" not in parsed:\n",
    "                parsed[\"valuable_knowledge\"] = []\n",
    "\n",
    "            print(\"Extracted knowledge from a chunk:\", parsed)\n",
    "            return parsed[\"valuable_knowledge\"]\n",
    "\n",
    "        except (JSONDecodeError, KeyError, TypeError) as e:\n",
    "            print(f\"JSON parse error: {e}\")\n",
    "            print(\"🔍 Raw model response:\\n\", response)\n",
    "            return []\n",
    "\n",
    "    def save_knowledge(self, triplets):\n",
    "        if not triplets:\n",
    "            return\n",
    "        knowledge = self.load_json_data(self.knowledge_file)\n",
    "        existing_set = {(t['subject'], t['predicate'], t['object']) for t in knowledge}\n",
    "        new_triplets = []\n",
    "        for triplet in triplets:\n",
    "            key = (triplet['subject'], triplet['predicate'], triplet['object'])\n",
    "            if key not in existing_set:\n",
    "                knowledge.append(triplet)\n",
    "                new_triplets.append(triplet)\n",
    "                existing_set.add(key)\n",
    "        self.save_json_data(self.knowledge_file, knowledge)\n",
    "        if new_triplets:\n",
    "            self.update_faiss_index(new_triplets)\n",
    "\n",
    "    def update_faiss_index(self, triplets):\n",
    "        texts = [f\"{t['subject']} {t['predicate']} {t['object']}\" for t in triplets]\n",
    "        embeddings = self.model.encode(texts)\n",
    "        if self.index is None:\n",
    "            self.index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "        self.index.add(np.array(embeddings, dtype=np.float32))\n",
    "        self.knowledge_data.extend(triplets)\n",
    "        self.save_faiss_index()\n",
    "\n",
    "    def save_faiss_index(self):\n",
    "        with open(self.faiss_index_file, 'wb') as f:\n",
    "            pickle.dump((self.index, self.knowledge_data), f)\n",
    "\n",
    "    def load_faiss_index(self):\n",
    "        if os.path.exists(self.faiss_index_file):\n",
    "            with open(self.faiss_index_file, 'rb') as f:\n",
    "                self.index, self.knowledge_data = pickle.load(f)\n",
    "        else:\n",
    "            self.index = None\n",
    "            self.knowledge_data = []\n",
    "\n",
    "def main():\n",
    "    # enriched_links_path = \"enriched_filtered_captions_to_chunks_mapping_hands.json\"\n",
    "    # all_chunks_path = \"processed_json/stabilizer pressure control_chunks.json\"\n",
    "    enriched_links_path = \"enriched_filtered_captions_to_chunks_mapping_hands_stabilizer_pressure_control_2.json\"\n",
    "    all_chunks_path = \"processed_json_stabilizer_pressure_control_2/stabilizer_pressure_control_2_chunks.json\"\n",
    "\n",
    "    if not os.path.exists(enriched_links_path):\n",
    "        print(f\"Bestand '{enriched_links_path}' bestaat niet.\")\n",
    "        return\n",
    "    if not os.path.exists(all_chunks_path):\n",
    "        print(f\"Bestand '{all_chunks_path}' bestaat niet.\")\n",
    "        return\n",
    "\n",
    "    with open(enriched_links_path, 'r', encoding='utf-8') as f:\n",
    "        enriched_links = json.load(f)\n",
    "\n",
    "    with open(all_chunks_path, 'r', encoding='utf-8') as f:\n",
    "        chunk_data = json.load(f)\n",
    "    all_chunks = chunk_data.get(\"chunks\", [])\n",
    "\n",
    "    print(f\"{len(all_chunks)} chunks geladen.\")\n",
    "    print(f\"{len(enriched_links)} verrijkte caption-links geladen.\")\n",
    "\n",
    "    enrichment_map = {item.get(\"linked_chunk_id\", \"\"): item for item in enriched_links if item.get(\"linked_chunk_id\")}\n",
    "\n",
    "    chatbot = Chatbot()\n",
    "\n",
    "    for i, chunk in enumerate(all_chunks, start=1):\n",
    "        chunk_text = chunk.get(\"text\", \"\").strip()\n",
    "        start_time = chunk.get(\"start\")\n",
    "        end_time = chunk.get(\"end\")\n",
    "        chunk_id = f\"{start_time}_{end_time}\"\n",
    "\n",
    "        if not chunk_text:\n",
    "            print(f\"Skipping lege chunk {chunk_id}\")\n",
    "            continue\n",
    "\n",
    "        enrichment = enrichment_map.get(chunk_id)\n",
    "\n",
    "        if enrichment:\n",
    "            relations = [\n",
    "                f\"{l['class_name']} → {l['action_label']}\"\n",
    "                for l in enrichment.get(\"object_action_links\", [])\n",
    "            ]\n",
    "            unique_hand_contacts = set(\n",
    "                h.get(\"class_name\", \"\").strip()\n",
    "                for h in enrichment.get(\"hand_object_links\", [])\n",
    "                if h.get(\"class_name\", \"\").strip()\n",
    "            )\n",
    "            hand_object_contacts = sorted(unique_hand_contacts)\n",
    "\n",
    "            combined_input = (\n",
    "                f\"Transcript: {chunk_text}\\n\"\n",
    "                f\"Linked object-action pairs: {', '.join(relations)}\\n\"\n",
    "                f\"Hand-object interactions: {', '.join(hand_object_contacts)}\"\n",
    "            )\n",
    "        else:\n",
    "            combined_input = f\"Transcript: {chunk_text}\"\n",
    "\n",
    "        print(f\"\\n[{i}] Extracting knowledge for chunk {chunk_id}\")\n",
    "        print(combined_input)\n",
    "\n",
    "        extracted_knowledge = chatbot.extract_valuable_knowledge(combined_input)\n",
    "\n",
    "        if extracted_knowledge:\n",
    "            for triplet in extracted_knowledge:\n",
    "                triplet[\"start\"] = start_time\n",
    "                triplet[\"end\"] = end_time\n",
    "            chatbot.save_knowledge(extracted_knowledge)\n",
    "\n",
    "    print(\"\\nKennisextractie afgerond. Bekijk 'knowledge.json' voor de resultaten.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Cake_4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
