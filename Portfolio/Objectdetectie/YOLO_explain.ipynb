{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e6cae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c21d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8200c2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Laad afbeelding\n",
    "def load_image(path, size=640):\n",
    "    img = cv2.imread(path)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_resized = cv2.resize(img_rgb, (size, size))\n",
    "    img_tensor = torch.from_numpy(img_resized).permute(2, 0, 1).float() / 255.0\n",
    "    return img_rgb, img_tensor.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d42d1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Hook op attention-layer\n",
    "def register_attention_hook(model, layer_name=\"model.8.m.1.1.attn\"):\n",
    "    attn_maps = []\n",
    "\n",
    "    def hook_fn(module, input, output):\n",
    "        attn_maps.append(output)\n",
    "\n",
    "    target_layer = dict(model.named_modules())[layer_name]\n",
    "    handle = target_layer.register_forward_hook(hook_fn)\n",
    "    return attn_maps, handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491fcd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Visualiseer attention-map\n",
    "def visualize_attention(attn_map, original_img):\n",
    "    attn = attn_map.squeeze().detach().cpu().mean(0)\n",
    "    \n",
    "    # Veilige normalisatie\n",
    "    attn_min, attn_max = attn.min(), attn.max()\n",
    "    if (attn_max - attn_min) > 1e-6:\n",
    "        attn = (attn - attn_min) / (attn_max - attn_min)\n",
    "    else:\n",
    "        attn = torch.zeros_like(attn)\n",
    "\n",
    "    attn_resized = cv2.resize(attn.numpy(), (original_img.shape[1], original_img.shape[0]))\n",
    "\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * attn_resized), cv2.COLORMAP_JET)\n",
    "    overlay = cv2.addWeighted(original_img, 0.6, heatmap, 0.4, 0)\n",
    "    \n",
    "    plt.imshow(overlay)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"YOLOv12 Attention Map\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7301511c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Hoofdscript\n",
    "def run_attention_vis(img_path):\n",
    "    model = YOLO(\"YOLOv12mv8.pt\")  # Zorg dat dit pad klopt\n",
    "    model.eval()\n",
    "    img_rgb, img_tensor = load_image(img_path)\n",
    "    attn_maps, hook = register_attention_hook(model.model)\n",
    "\n",
    "    _ = model.predict(img_path, imgsz=640, verbose=False)\n",
    "\n",
    "    hook.remove()\n",
    "    visualize_attention(attn_maps[0][0], img_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a34564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run op afbeelding\n",
    "run_attention_vis(r\"C:\\Users\\maxim\\OneDrive\\01-Opleidingen\\03-MAAI\\Afstuderen\\Data\\Foto's\\IMG_1337.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f21e104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = YOLO(\"YOLOv12mv8.pt\")\n",
    "# for name, _ in model.model.named_modules():\n",
    "#     if \"attn\" in name:\n",
    "#         print(name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bc4aa1",
   "metadata": {},
   "source": [
    "## Gram-cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc01fac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"YOLOv12mv8.pt\")  # Vervang dit door het pad naar jouw model\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a189d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_layer = model.model.model[20].m[0].cv3.conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78b2007",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "img_path = r\"C:\\Users\\maxim\\OneDrive\\01-Opleidingen\\03-MAAI\\Afstuderen\\Data\\Foto's\\IMG_1337.jpg\"# Vervang dit door het pad naar jouw afbeelding\n",
    "img = cv2.imread(img_path)\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img_resized = cv2.resize(img_rgb, (640, 640))\n",
    "img_tensor = torch.from_numpy(img_resized).permute(2, 0, 1).float() / 255.0\n",
    "input_tensor = img_tensor.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85f5bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_grad_cam.base_cam import BaseCAM\n",
    "class YOLOBoxTarget:\n",
    "    def __init__(self, box_index: int):\n",
    "        self.box_index = box_index\n",
    "\n",
    "    def __call__(self, model_output):\n",
    "        # model_output is een tuple; we pakken de box scores (bijv. confidence)\n",
    "        return model_output[0][self.box_index, 4]  # 4 = confidence column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8a3a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(img_path, imgsz=640, verbose=False)\n",
    "boxes_tensor = results[0].boxes.data  # tensor van [n, 6] (x1, y1, x2, y2, conf, cls)\n",
    "print(boxes_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2412786",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = YOLOBoxTarget(box_index=0)  # kies eerste detectie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf12b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "\n",
    "input_tensor.requires_grad_()  # Zorg dat Grad-CAM een backward pass kan doen\n",
    "\n",
    "target = YOLOBoxTarget(box_index=0)\n",
    "\n",
    "cam = GradCAM(model=model.model, target_layers=[target_layer])\n",
    "grayscale_cam = cam(input_tensor=input_tensor, targets=[target])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1731ed83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "\n",
    "visualization = show_cam_on_image(img_resized / 255.0, grayscale_cam, use_rgb=True)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(visualization)\n",
    "plt.axis('off')\n",
    "plt.title('Grad-CAM uitleg voor YOLOv12')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c42c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from torch.nn import Conv2d\n",
    "\n",
    "# ------------------------\n",
    "# Afbeelding inladen\n",
    "# ------------------------\n",
    "def load_image(path, size=640):\n",
    "    img = cv2.imread(path)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_resized = cv2.resize(img_rgb, (size, size))\n",
    "    img_tensor = torch.from_numpy(img_resized).permute(2, 0, 1).float() / 255.0\n",
    "    return img_rgb, img_resized, img_tensor.unsqueeze(0)\n",
    "\n",
    "# ------------------------\n",
    "# Grad-CAM target op class score\n",
    "# ------------------------\n",
    "class ClassScoreTarget:\n",
    "    def __init__(self, class_index: int):\n",
    "        self.class_index = class_index\n",
    "\n",
    "    def __call__(self, model_output):\n",
    "        class_scores = model_output[0][:, 5:]  # [N, num_classes]\n",
    "        return class_scores[:, self.class_index].max()\n",
    "\n",
    "# ------------------------\n",
    "# Grad-CAM uitvoeren\n",
    "# ------------------------\n",
    "def run_grad_cam(img_path):\n",
    "    # 1. Laad model\n",
    "    model = YOLO(\"YOLOv12mv8.pt\")\n",
    "    model.eval()\n",
    "\n",
    "    # 2. Laad afbeelding\n",
    "    img_rgb, img_resized, input_tensor = load_image(img_path)\n",
    "    input_tensor = input_tensor.to(model.device)\n",
    "    input_tensor.requires_grad_()\n",
    "\n",
    "    # 3. Predictie uitvoeren om klasse te bepalen\n",
    "    results = model.predict(img_path, imgsz=640, verbose=False)\n",
    "    boxes = results[0].boxes.data\n",
    "    if boxes.shape[0] == 0:\n",
    "        print(\"Geen objecten gedetecteerd.\")\n",
    "        return\n",
    "\n",
    "    class_index = int(boxes[0, 5])\n",
    "    target = ClassScoreTarget(class_index)\n",
    "    print(f\"Geselecteerde klasse-index: {class_index}\")\n",
    "\n",
    "    # 4. Selecteer automatisch laatste Conv2d-laag\n",
    "    target_layer = None\n",
    "    for layer in reversed(model.model.model[:-1]):\n",
    "        for sublayer in layer.modules():\n",
    "            if isinstance(sublayer, Conv2d):\n",
    "                target_layer = sublayer\n",
    "                break\n",
    "        if target_layer:\n",
    "            break\n",
    "\n",
    "    if target_layer is None:\n",
    "        print(\"Geen geschikte Conv2d-layer gevonden.\")\n",
    "        return\n",
    "    else:\n",
    "        print(f\"Geselecteerde target layer: {target_layer}\")\n",
    "\n",
    "    # 5. Grad-CAM uitvoeren\n",
    "    cam = GradCAM(model=model.model, target_layers=[target_layer])\n",
    "    grayscale_cam = cam(input_tensor=input_tensor, targets=[target])[0]\n",
    "\n",
    "    print(\"CAM min:\", grayscale_cam.min())\n",
    "    print(\"CAM max:\", grayscale_cam.max())\n",
    "\n",
    "    # 6. Overlay visualiseren\n",
    "    cam_image = show_cam_on_image(img_resized / 255.0, grayscale_cam, use_rgb=True)\n",
    "    plt.imshow(cam_image)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Grad-CAM voor YOLOv12 (automatisch geselecteerde layer)\")\n",
    "    plt.show()\n",
    "\n",
    "# ------------------------\n",
    "# Startpunt\n",
    "# ------------------------\n",
    "run_grad_cam(r\"C:\\Users\\maxim\\OneDrive\\01-Opleidingen\\03-MAAI\\Afstuderen\\Data\\Foto's\\IMG_1337.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ee42cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "from torch.nn import Conv2d\n",
    "\n",
    "def load_image(path, size=640):\n",
    "    img = cv2.imread(path)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_resized = cv2.resize(img_rgb, (size, size))\n",
    "    img_tensor = torch.from_numpy(img_resized).permute(2, 0, 1).float() / 255.0\n",
    "    return img_rgb, img_resized, img_tensor.unsqueeze(0)\n",
    "\n",
    "def run_feature_map_vis(img_path):\n",
    "    model = YOLO(\"YOLOv12mv8.pt\")\n",
    "    model.eval()\n",
    "\n",
    "    img_rgb, img_resized, input_tensor = load_image(img_path)\n",
    "    input_tensor = input_tensor.to(model.device)\n",
    "\n",
    "    # 1. Zoek een diepe conv-laag\n",
    "    target_layer = None\n",
    "    for layer in reversed(model.model.model[:-1]):\n",
    "        for sublayer in layer.modules():\n",
    "            if isinstance(sublayer, Conv2d):\n",
    "                target_layer = sublayer\n",
    "                break\n",
    "        if target_layer:\n",
    "            break\n",
    "\n",
    "    if target_layer is None:\n",
    "        print(\"Geen geschikte Conv-layer gevonden.\")\n",
    "        return\n",
    "\n",
    "    # 2. Registreer hook\n",
    "    activations = []\n",
    "\n",
    "    def hook_fn(module, input, output):\n",
    "        activations.append(output.detach().cpu())\n",
    "\n",
    "    hook_handle = target_layer.register_forward_hook(hook_fn)\n",
    "\n",
    "    # 3. Run forward pass\n",
    "    with torch.no_grad():\n",
    "        _ = model.model(input_tensor)\n",
    "\n",
    "    hook_handle.remove()\n",
    "\n",
    "    if not activations:\n",
    "        print(\"Geen activaties vastgelegd.\")\n",
    "        return\n",
    "\n",
    "    # 4. Visualiseer gemiddelde feature map\n",
    "    fmap = activations[0].squeeze(0)  # shape: [C, H, W]\n",
    "    fmap_mean = fmap.mean(dim=0).numpy()\n",
    "    fmap_norm = (fmap_mean - fmap_mean.min()) / (fmap_mean.max() - fmap_mean.min() + 1e-8)\n",
    "    fmap_resized = cv2.resize(fmap_norm, (img_resized.shape[1], img_resized.shape[0]))\n",
    "    heatmap = cv2.applyColorMap(np.uint8(fmap_resized * 255), cv2.COLORMAP_JET)\n",
    "    overlay = cv2.addWeighted(img_resized, 0.6, heatmap, 0.4, 0)\n",
    "\n",
    "    plt.imshow(overlay)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Feature map activatie overlay\")\n",
    "    plt.show()\n",
    "\n",
    "# â–¶Start\n",
    "run_feature_map_vis(r\"C:\\Users\\maxim\\OneDrive\\01-Opleidingen\\03-MAAI\\Afstuderen\\Data\\Foto's\\IMG_1337.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa6b399",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"YOLOv12mv8.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792c0e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#  Voorspel (lage confidence threshold)\n",
    "results = model.predict(source=r\"C:\\Users\\maxim\\OneDrive\\01-Opleidingen\\03-MAAI\\Afstuderen\\Data\\Foto's\\IMG_1337.jpg\", conf=0.6, save=False, show=False)\n",
    "\n",
    "# Debug: zijn er boxes?\n",
    "if results[0].boxes:\n",
    "    print(f\"Gevonden: {len(results[0].boxes)} object(en)\")\n",
    "\n",
    "    # Annotated afbeelding ophalen\n",
    "    img = results[0].plot()\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Laat het zien\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Geen objecten gedetecteerd.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84365984",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_feature_map_vis(r\"C:\\Users\\maxim\\OneDrive\\01-Opleidingen\\03-MAAI\\Afstuderen\\Data\\Foto's\\IMG_1287.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2277becd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#  Voorspel (lage confidence threshold)\n",
    "results = model.predict(source=r\"C:\\Users\\maxim\\OneDrive\\01-Opleidingen\\03-MAAI\\Afstuderen\\Data\\Foto's\\IMG_1287.jpg\", conf=0.6, save=False, show=False)\n",
    "\n",
    "# Debug: zijn er boxes?\n",
    "if results[0].boxes:\n",
    "    print(f\"Gevonden: {len(results[0].boxes)} object(en)\")\n",
    "\n",
    "    # Annotated afbeelding ophalen\n",
    "    img = results[0].plot()\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Laat het zien\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Geen objecten gedetecteerd.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba0319e",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_feature_map_vis(r\"C:\\Users\\maxim\\OneDrive\\01-Opleidingen\\03-MAAI\\Afstuderen\\Data\\Foto's\\IMG_1353.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be63b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#  Voorspel (lage confidence threshold)\n",
    "results = model.predict(source=r\"C:\\Users\\maxim\\OneDrive\\01-Opleidingen\\03-MAAI\\Afstuderen\\Data\\Foto's\\IMG_1353.jpg\", conf=0.6, save=False, show=False)\n",
    "\n",
    "# Debug: zijn er boxes?\n",
    "if results[0].boxes:\n",
    "    print(f\"Gevonden: {len(results[0].boxes)} object(en)\")\n",
    "\n",
    "    # Annotated afbeelding ophalen\n",
    "    img = results[0].plot()\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Laat het zien\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Geen objecten gedetecteerd.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Afstuderen_MAAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
